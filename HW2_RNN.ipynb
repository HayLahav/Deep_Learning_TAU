{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ME2Qi8SVCP_w"},"outputs":[],"source":["import numpy as np\n","import torch\n","from torch import optim\n","import torch.nn as nn\n","import timeit\n","import matplotlib.pyplot as plt\n","import urllib.request\n","import pandas as pd"]},{"cell_type":"markdown","source":["Loading the data"],"metadata":{"id":"7gnGqCQRQ3Vl"}},{"cell_type":"code","source":["def data_init():\n","    URL = {\n","        'train': \"https://raw.githubusercontent.com/Nadavmarci/DataScience/master/ptb.train.txt\",\n","        'test': \"https://raw.githubusercontent.com/Nadavmarci/DataScience/master/ptb.test.txt\",\n","        'valid': \"https://raw.githubusercontent.com/Nadavmarci/DataScience/master/ptb.valid.txt\",\n","    }\n","    with urllib.request.urlopen(URL['train']) as f:\n","        file = f.read().decode('utf-8')\n","        trn = file[1:].split(' ')\n","    with urllib.request.urlopen(URL['valid']) as f:\n","        file = f.read().decode('utf-8')\n","        vld = file[1:].split(' ')\n","    with urllib.request.urlopen(URL['test']) as f:\n","        file = f.read().decode('utf-8')\n","        tst = file[1:].split(' ')\n","    words = sorted(set(trn))\n","    char2ind = {c: i for i, c in enumerate(words)}\n","    trn = [char2ind[c] for c in trn]\n","    vld = [char2ind[c] for c in vld]\n","    tst = [char2ind[c] for c in tst]\n","    return np.array(trn).reshape(-1, 1), np.array(vld).reshape(-1, 1), np.array(tst).reshape(-1, 1), len(words)"],"metadata":{"id":"5T7XWrSMQ1l3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["First checking if GPU is available"],"metadata":{"id":"QmWox-umRVc3"}},{"cell_type":"code","source":["train_on_gpu=torch.cuda.is_available()\n","if(train_on_gpu):\n","    print('Training on GPU.')\n","    torch.device('cuda')\n","else:\n","    print('No GPU available, training on CPU.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s3GdPQRTRRHc","executionInfo":{"status":"ok","timestamp":1684319655209,"user_tz":-180,"elapsed":15,"user":{"displayName":"nadav marciano","userId":"12525209232604832576"}},"outputId":"8d5f2333-321c-4a22-da93-ee3067ddd53c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training on GPU.\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TfSCP8PLCYE1"},"outputs":[],"source":["batch_size = 20\n","hidden_size = 200\n","layer_num = 2\n","\n","class Model(nn.Module):\n","    def __init__(self, vocab_size, hidden_size, layer_num, dropout, winit, rnn_type):\n","        super().__init__()\n","        self.vocab_size = vocab_size\n","        self.hidden_size = hidden_size\n","        self.layer_num = layer_num\n","        self.winit = winit\n","        self.embed = Embed(vocab_size, hidden_size)\n","        self.rnn_type = rnn_type\n","        if rnn_type == 'GRU':\n","            self.rnns = [nn.GRU(hidden_size, hidden_size) for i in range(layer_num)]\n","        else:\n","            self.rnns = [nn.LSTM(hidden_size, hidden_size) for i in range(layer_num)]\n","        self.rnns = nn.ModuleList(self.rnns)\n","        self.fc = Linear(hidden_size, vocab_size)\n","        self.dropout = nn.Dropout(p=dropout)\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        for param in self.parameters():\n","            nn.init.uniform_(param, -self.winit, self.winit)\n","\n","    def state_init(self, batch_size,rnn_type):\n","        dev = next(self.parameters()).device\n","        if rnn_type == 'LSTM':\n","            states = [(torch.zeros(1, batch_size, layer.hidden_size, device = dev), torch.zeros(1, batch_size, layer.hidden_size, device = dev)) for layer in self.rnns]\n","        else:\n","            states = [(torch.zeros(1, batch_size, layer.hidden_size, device = dev)) for layer in self.rnns]\n","        return states\n","\n","    def detach(self, states,rnn_type):\n","        if rnn_type =='GRU':\n","            return [h.detach() for h in states]\n","        else:\n","            return [(h.detach(), c.detach()) for (h,c) in states]\n","\n","    def forward(self, x, states):\n","        x = self.embed(x)\n","        x = self.dropout(x)\n","        for i, rnn in enumerate(self.rnns):\n","            x, states[i] = rnn(x, states[i])\n","            x = self.dropout(x)\n","        scores = self.fc(x)\n","        return scores, states"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z_xRO1QbCbVI"},"outputs":[],"source":["def minibatch(data, batch_size, seq_length):\n","    data = torch.tensor(data, dtype = torch.int64)\n","    num_batches = data.size(0)//batch_size\n","    data = data[:num_batches*batch_size]\n","    data=data.view(batch_size,-1)\n","    dataset = []\n","    for i in range(0,data.size(1)-1,seq_length):\n","        seqlen=int(np.min([seq_length,data.size(1)-1-i]))\n","        if seqlen<data.size(1)-1-i:\n","            x=data[:,i:i+seqlen].transpose(1, 0)\n","            y=data[:,i+1:i+seqlen+1].transpose(1, 0)\n","            dataset.append((x, y))\n","    return dataset\n","\n","class Linear(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super().__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.W = nn.Parameter(torch.Tensor(hidden_size, input_size))\n","        self.b = nn.Parameter(torch.Tensor(hidden_size))\n","\n","    def forward(self, x):\n","        z = torch.addmm(self.b, x.view(-1, x.size(2)), self.W.t())\n","        return z\n","\n","    def __repr__(self):\n","        return \"FC(input: {}, output: {})\".format(self.input_size, self.hidden_size)\n","\n","class Embed(nn.Module):\n","    def __init__(self, vocab_size, embed_size):\n","        super().__init__()\n","        self.vocab_size = vocab_size\n","        self.embed_size = embed_size\n","        self.W = nn.Parameter(torch.Tensor(vocab_size, embed_size))\n","\n","    def forward(self, x):\n","        return self.W[x]\n","\n","    def __repr__(self):\n","        return \"Embedding(vocab: {}, embedding: {})\".format(self.vocab_size, self.embed_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hPCOJTHjCf7K"},"outputs":[],"source":["def nll_loss(scores, y):\n","    batch_size = y.size(1)\n","    expscores = scores.exp()\n","    probabilities = expscores / expscores.sum(1, keepdim = True)\n","    answerprobs = probabilities[range(len(y.reshape(-1))), y.reshape(-1)]\n","    return torch.mean(-torch.log(answerprobs) * batch_size)\n","\n","def perplexity(data, model,rnn_type):\n","    with torch.no_grad():\n","        losses = []\n","        states = model.state_init(batch_size,rnn_type)\n","        for x, y in data:\n","            scores, states = model(x, states)\n","            loss = nll_loss(scores, y)\n","            losses.append(loss.data.item()/batch_size)\n","    return np.exp(np.mean(losses))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IoN1A5JWCipx"},"outputs":[],"source":["def train(data, model, epochs, epoch_threshold, lr, factor, max_norm,rnn_type):\n","    train_data, validation_data, test_data = data\n","    tic = timeit.default_timer()\n","    total_words = 0\n","    train_perplexity = []\n","    test_perplexity = []\n","    valid_perp_min = np.Inf\n","\n","    print(\"Starting training.\\n\")\n","    for epoch in range(epochs):\n","        states = model.state_init(batch_size,rnn_type)\n","        model.train()\n","        if epoch > epoch_threshold:\n","            lr = lr / factor\n","        for i, (x, y) in enumerate(train_data):\n","            total_words += x.numel()\n","            model.zero_grad()\n","            states = model.detach(states,rnn_type)\n","            scores, states = model(x, states)\n","            loss = nll_loss(scores, y)\n","            loss.backward()\n","            \n","            \n","            with torch.no_grad():\n","                norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n","                for param in model.parameters():\n","                    param -= lr * param.grad\n","\n","            if i % (len(train_data)//10) == 0:\n","                toc = timeit.default_timer()\n","\n","                print(\"batch no = {:d} / {:d}, \".format(i, len(train_data)) +\n","                      \"train loss = {:.3f}, \".format(loss.item()/batch_size) +\n","                      \"lr = {:.3f}, \".format(lr) +\n","                      \"since beginning = {:d} mins, \".format(round((toc-tic)/60)) \n","                      )\n","        model.eval()\n","        val_perp = perplexity(validation_data, model,rnn_type)\n","\n","        if val_perp <= valid_perp_min:\n","            torch.save(model.state_dict(), 'model_cifar.pt')\n","            valid_perp_min = val_perp\n","\n","        epoch_train_perplexity = perplexity(train_data, model, rnn_type)\n","        epoch_test_perplexity = perplexity(test_data, model, rnn_type)\n","        train_perplexity.append(epoch_train_perplexity)\n","        test_perplexity.append(epoch_test_perplexity)\n","        print(\"Epoch : {:d} || Validation set perplexity : {:.3f}\".format(epoch+1, val_perp))\n","        print(\"*************************************************\\n\")\n","    model.load_state_dict(torch.load('model_cifar.pt'))\n","    tst_perp = perplexity(test_data, model,rnn_type)\n","    print(\"validation preplexity : {:.3f}\".format(val_perp))\n","    print(\"Training is over.\")\n","    return train_perplexity, test_perplexity, val_perp"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xTh9Ih8fCl6i"},"outputs":[],"source":["def plot_convergence(n_epochs, test_perplexity, train_perplexity, title):\n","    plt.plot(range(n_epochs), test_perplexity, label = \"Test\")\n","    plt.plot(range(n_epochs), train_perplexity, label = \"Train\")\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Perplexity')\n","    plt.title(title)\n","    plt.legend()\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZXJCDokMCoiK"},"outputs":[],"source":["def test_model(dropout,rnn_type, total_epochs,learning_rate,winit,seq_length,factor_epoch,factor,max_grad_norm, title):\n","    trn, vld, tst, vocab_size = data_init()\n","    trn = minibatch(trn, batch_size, seq_length)\n","    vld = minibatch(vld, batch_size, seq_length)\n","    tst = minibatch(tst, batch_size, seq_length)\n","    model = Model(vocab_size, hidden_size, layer_num, dropout, winit, rnn_type)\n","    if torch.cuda.is_available(): model.to(\"cuda\") \n","    else: model.to(\"cpu\")\n","    final_title = title \n","    train_perplexity, test_perplexity,validation_preplexity = train((trn, vld, tst), model, total_epochs, factor_epoch, learning_rate, factor, max_grad_norm,rnn_type)\n","    plot_convergence(total_epochs, test_perplexity, train_perplexity, final_title)\n","    return (perplexity(tst,model,rnn_type), perplexity(trn,model,rnn_type), validation_preplexity), final_title"]},{"cell_type":"markdown","source":["# **LSTM:**"],"metadata":{"id":"OsWWBcIoZqam"}},{"cell_type":"markdown","source":["LSTM without droput"],"metadata":{"id":"JjX4_2L9Z84x"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":266592,"status":"ok","timestamp":1684320077375,"user":{"displayName":"nadav marciano","userId":"12525209232604832576"},"user_tz":-180},"id":"tNq8LynjNm3D","outputId":"b5d3f213-d658-4b0c-f319-16e7de6564ad"},"outputs":[{"output_type":"stream","name":"stdout","text":["Starting training.\n","\n","batch no = 0 / 1327, train loss = 9.212, lr = 0.950, since beginning = 0 mins, \n","batch no = 132 / 1327, train loss = 6.699, lr = 0.950, since beginning = 0 mins, \n","batch no = 264 / 1327, train loss = 6.402, lr = 0.950, since beginning = 0 mins, \n","batch no = 396 / 1327, train loss = 6.372, lr = 0.950, since beginning = 0 mins, \n","batch no = 528 / 1327, train loss = 6.109, lr = 0.950, since beginning = 0 mins, \n","batch no = 660 / 1327, train loss = 5.896, lr = 0.950, since beginning = 0 mins, \n","batch no = 792 / 1327, train loss = 5.742, lr = 0.950, since beginning = 0 mins, \n","batch no = 924 / 1327, train loss = 5.439, lr = 0.950, since beginning = 0 mins, \n","batch no = 1056 / 1327, train loss = 5.683, lr = 0.950, since beginning = 0 mins, \n","batch no = 1188 / 1327, train loss = 5.203, lr = 0.950, since beginning = 0 mins, \n","batch no = 1320 / 1327, train loss = 5.647, lr = 0.950, since beginning = 0 mins, \n","Epoch : 1 || Validation set perplexity : 240.490\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.700, lr = 0.950, since beginning = 0 mins, \n","batch no = 132 / 1327, train loss = 5.304, lr = 0.950, since beginning = 0 mins, \n","batch no = 264 / 1327, train loss = 5.381, lr = 0.950, since beginning = 0 mins, \n","batch no = 396 / 1327, train loss = 5.290, lr = 0.950, since beginning = 0 mins, \n","batch no = 528 / 1327, train loss = 5.334, lr = 0.950, since beginning = 0 mins, \n","batch no = 660 / 1327, train loss = 4.999, lr = 0.950, since beginning = 0 mins, \n","batch no = 792 / 1327, train loss = 5.117, lr = 0.950, since beginning = 0 mins, \n","batch no = 924 / 1327, train loss = 4.894, lr = 0.950, since beginning = 0 mins, \n","batch no = 1056 / 1327, train loss = 5.052, lr = 0.950, since beginning = 0 mins, \n","batch no = 1188 / 1327, train loss = 4.764, lr = 0.950, since beginning = 0 mins, \n","batch no = 1320 / 1327, train loss = 5.257, lr = 0.950, since beginning = 0 mins, \n","Epoch : 2 || Validation set perplexity : 171.397\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.365, lr = 0.950, since beginning = 1 mins, \n","batch no = 132 / 1327, train loss = 4.872, lr = 0.950, since beginning = 1 mins, \n","batch no = 264 / 1327, train loss = 5.087, lr = 0.950, since beginning = 1 mins, \n","batch no = 396 / 1327, train loss = 4.990, lr = 0.950, since beginning = 1 mins, \n","batch no = 528 / 1327, train loss = 5.094, lr = 0.950, since beginning = 1 mins, \n","batch no = 660 / 1327, train loss = 4.640, lr = 0.950, since beginning = 1 mins, \n","batch no = 792 / 1327, train loss = 4.830, lr = 0.950, since beginning = 1 mins, \n","batch no = 924 / 1327, train loss = 4.701, lr = 0.950, since beginning = 1 mins, \n","batch no = 1056 / 1327, train loss = 4.809, lr = 0.950, since beginning = 1 mins, \n","batch no = 1188 / 1327, train loss = 4.522, lr = 0.950, since beginning = 1 mins, \n","batch no = 1320 / 1327, train loss = 5.023, lr = 0.950, since beginning = 1 mins, \n","Epoch : 3 || Validation set perplexity : 148.542\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.179, lr = 0.950, since beginning = 1 mins, \n","batch no = 132 / 1327, train loss = 4.647, lr = 0.950, since beginning = 1 mins, \n","batch no = 264 / 1327, train loss = 4.887, lr = 0.950, since beginning = 1 mins, \n","batch no = 396 / 1327, train loss = 4.828, lr = 0.950, since beginning = 1 mins, \n","batch no = 528 / 1327, train loss = 4.906, lr = 0.950, since beginning = 1 mins, \n","batch no = 660 / 1327, train loss = 4.457, lr = 0.950, since beginning = 1 mins, \n","batch no = 792 / 1327, train loss = 4.685, lr = 0.950, since beginning = 1 mins, \n","batch no = 924 / 1327, train loss = 4.574, lr = 0.950, since beginning = 1 mins, \n","batch no = 1056 / 1327, train loss = 4.619, lr = 0.950, since beginning = 1 mins, \n","batch no = 1188 / 1327, train loss = 4.380, lr = 0.950, since beginning = 1 mins, \n","batch no = 1320 / 1327, train loss = 4.875, lr = 0.950, since beginning = 1 mins, \n","Epoch : 4 || Validation set perplexity : 138.934\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.046, lr = 0.950, since beginning = 1 mins, \n","batch no = 132 / 1327, train loss = 4.484, lr = 0.950, since beginning = 1 mins, \n","batch no = 264 / 1327, train loss = 4.776, lr = 0.950, since beginning = 1 mins, \n","batch no = 396 / 1327, train loss = 4.730, lr = 0.950, since beginning = 1 mins, \n","batch no = 528 / 1327, train loss = 4.768, lr = 0.950, since beginning = 1 mins, \n","batch no = 660 / 1327, train loss = 4.323, lr = 0.950, since beginning = 1 mins, \n","batch no = 792 / 1327, train loss = 4.562, lr = 0.950, since beginning = 1 mins, \n","batch no = 924 / 1327, train loss = 4.435, lr = 0.950, since beginning = 1 mins, \n","batch no = 1056 / 1327, train loss = 4.472, lr = 0.950, since beginning = 1 mins, \n","batch no = 1188 / 1327, train loss = 4.252, lr = 0.950, since beginning = 1 mins, \n","batch no = 1320 / 1327, train loss = 4.746, lr = 0.950, since beginning = 1 mins, \n","Epoch : 5 || Validation set perplexity : 135.563\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.961, lr = 0.950, since beginning = 1 mins, \n","batch no = 132 / 1327, train loss = 4.373, lr = 0.950, since beginning = 1 mins, \n","batch no = 264 / 1327, train loss = 4.645, lr = 0.950, since beginning = 1 mins, \n","batch no = 396 / 1327, train loss = 4.658, lr = 0.950, since beginning = 1 mins, \n","batch no = 528 / 1327, train loss = 4.683, lr = 0.950, since beginning = 1 mins, \n","batch no = 660 / 1327, train loss = 4.232, lr = 0.950, since beginning = 2 mins, \n","batch no = 792 / 1327, train loss = 4.456, lr = 0.950, since beginning = 2 mins, \n","batch no = 924 / 1327, train loss = 4.327, lr = 0.950, since beginning = 2 mins, \n","batch no = 1056 / 1327, train loss = 4.360, lr = 0.950, since beginning = 2 mins, \n","batch no = 1188 / 1327, train loss = 4.164, lr = 0.950, since beginning = 2 mins, \n","batch no = 1320 / 1327, train loss = 4.668, lr = 0.950, since beginning = 2 mins, \n","Epoch : 6 || Validation set perplexity : 133.134\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.878, lr = 0.475, since beginning = 2 mins, \n","batch no = 132 / 1327, train loss = 4.184, lr = 0.475, since beginning = 2 mins, \n","batch no = 264 / 1327, train loss = 4.467, lr = 0.475, since beginning = 2 mins, \n","batch no = 396 / 1327, train loss = 4.521, lr = 0.475, since beginning = 2 mins, \n","batch no = 528 / 1327, train loss = 4.417, lr = 0.475, since beginning = 2 mins, \n","batch no = 660 / 1327, train loss = 4.029, lr = 0.475, since beginning = 2 mins, \n","batch no = 792 / 1327, train loss = 4.240, lr = 0.475, since beginning = 2 mins, \n","batch no = 924 / 1327, train loss = 4.067, lr = 0.475, since beginning = 2 mins, \n","batch no = 1056 / 1327, train loss = 4.097, lr = 0.475, since beginning = 2 mins, \n","batch no = 1188 / 1327, train loss = 3.839, lr = 0.475, since beginning = 2 mins, \n","batch no = 1320 / 1327, train loss = 4.370, lr = 0.475, since beginning = 2 mins, \n","Epoch : 7 || Validation set perplexity : 124.261\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.738, lr = 0.237, since beginning = 2 mins, \n","batch no = 132 / 1327, train loss = 4.035, lr = 0.237, since beginning = 2 mins, \n","batch no = 264 / 1327, train loss = 4.320, lr = 0.237, since beginning = 2 mins, \n","batch no = 396 / 1327, train loss = 4.387, lr = 0.237, since beginning = 2 mins, \n","batch no = 528 / 1327, train loss = 4.256, lr = 0.237, since beginning = 2 mins, \n","batch no = 660 / 1327, train loss = 3.861, lr = 0.237, since beginning = 2 mins, \n","batch no = 792 / 1327, train loss = 4.072, lr = 0.237, since beginning = 2 mins, \n","batch no = 924 / 1327, train loss = 3.917, lr = 0.237, since beginning = 2 mins, \n","batch no = 1056 / 1327, train loss = 3.906, lr = 0.237, since beginning = 2 mins, \n","batch no = 1188 / 1327, train loss = 3.642, lr = 0.237, since beginning = 2 mins, \n","batch no = 1320 / 1327, train loss = 4.198, lr = 0.237, since beginning = 2 mins, \n","Epoch : 8 || Validation set perplexity : 122.186\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.663, lr = 0.119, since beginning = 2 mins, \n","batch no = 132 / 1327, train loss = 3.962, lr = 0.119, since beginning = 2 mins, \n","batch no = 264 / 1327, train loss = 4.234, lr = 0.119, since beginning = 2 mins, \n","batch no = 396 / 1327, train loss = 4.314, lr = 0.119, since beginning = 2 mins, \n","batch no = 528 / 1327, train loss = 4.162, lr = 0.119, since beginning = 2 mins, \n","batch no = 660 / 1327, train loss = 3.768, lr = 0.119, since beginning = 2 mins, \n","batch no = 792 / 1327, train loss = 3.981, lr = 0.119, since beginning = 2 mins, \n","batch no = 924 / 1327, train loss = 3.820, lr = 0.119, since beginning = 2 mins, \n","batch no = 1056 / 1327, train loss = 3.802, lr = 0.119, since beginning = 2 mins, \n","batch no = 1188 / 1327, train loss = 3.541, lr = 0.119, since beginning = 2 mins, \n","batch no = 1320 / 1327, train loss = 4.087, lr = 0.119, since beginning = 2 mins, \n","Epoch : 9 || Validation set perplexity : 121.903\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.615, lr = 0.059, since beginning = 3 mins, \n","batch no = 132 / 1327, train loss = 3.916, lr = 0.059, since beginning = 3 mins, \n","batch no = 264 / 1327, train loss = 4.191, lr = 0.059, since beginning = 3 mins, \n","batch no = 396 / 1327, train loss = 4.268, lr = 0.059, since beginning = 3 mins, \n","batch no = 528 / 1327, train loss = 4.105, lr = 0.059, since beginning = 3 mins, \n","batch no = 660 / 1327, train loss = 3.723, lr = 0.059, since beginning = 3 mins, \n","batch no = 792 / 1327, train loss = 3.917, lr = 0.059, since beginning = 3 mins, \n","batch no = 924 / 1327, train loss = 3.774, lr = 0.059, since beginning = 3 mins, \n","batch no = 1056 / 1327, train loss = 3.757, lr = 0.059, since beginning = 3 mins, \n","batch no = 1188 / 1327, train loss = 3.489, lr = 0.059, since beginning = 3 mins, \n","batch no = 1320 / 1327, train loss = 4.033, lr = 0.059, since beginning = 3 mins, \n","Epoch : 10 || Validation set perplexity : 121.714\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.587, lr = 0.030, since beginning = 3 mins, \n","batch no = 132 / 1327, train loss = 3.888, lr = 0.030, since beginning = 3 mins, \n","batch no = 264 / 1327, train loss = 4.168, lr = 0.030, since beginning = 3 mins, \n","batch no = 396 / 1327, train loss = 4.248, lr = 0.030, since beginning = 3 mins, \n","batch no = 528 / 1327, train loss = 4.072, lr = 0.030, since beginning = 3 mins, \n","batch no = 660 / 1327, train loss = 3.697, lr = 0.030, since beginning = 3 mins, \n","batch no = 792 / 1327, train loss = 3.883, lr = 0.030, since beginning = 3 mins, \n","batch no = 924 / 1327, train loss = 3.751, lr = 0.030, since beginning = 3 mins, \n","batch no = 1056 / 1327, train loss = 3.733, lr = 0.030, since beginning = 3 mins, \n","batch no = 1188 / 1327, train loss = 3.461, lr = 0.030, since beginning = 3 mins, \n","batch no = 1320 / 1327, train loss = 4.008, lr = 0.030, since beginning = 3 mins, \n","Epoch : 11 || Validation set perplexity : 121.251\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.569, lr = 0.015, since beginning = 3 mins, \n","batch no = 132 / 1327, train loss = 3.864, lr = 0.015, since beginning = 3 mins, \n","batch no = 264 / 1327, train loss = 4.152, lr = 0.015, since beginning = 3 mins, \n","batch no = 396 / 1327, train loss = 4.241, lr = 0.015, since beginning = 3 mins, \n","batch no = 528 / 1327, train loss = 4.052, lr = 0.015, since beginning = 3 mins, \n","batch no = 660 / 1327, train loss = 3.682, lr = 0.015, since beginning = 3 mins, \n","batch no = 792 / 1327, train loss = 3.865, lr = 0.015, since beginning = 3 mins, \n","batch no = 924 / 1327, train loss = 3.738, lr = 0.015, since beginning = 3 mins, \n","batch no = 1056 / 1327, train loss = 3.719, lr = 0.015, since beginning = 3 mins, \n","batch no = 1188 / 1327, train loss = 3.443, lr = 0.015, since beginning = 3 mins, \n","batch no = 1320 / 1327, train loss = 3.993, lr = 0.015, since beginning = 3 mins, \n","Epoch : 12 || Validation set perplexity : 120.772\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.559, lr = 0.007, since beginning = 3 mins, \n","batch no = 132 / 1327, train loss = 3.848, lr = 0.007, since beginning = 3 mins, \n","batch no = 264 / 1327, train loss = 4.144, lr = 0.007, since beginning = 3 mins, \n","batch no = 396 / 1327, train loss = 4.235, lr = 0.007, since beginning = 3 mins, \n","batch no = 528 / 1327, train loss = 4.041, lr = 0.007, since beginning = 3 mins, \n","batch no = 660 / 1327, train loss = 3.675, lr = 0.007, since beginning = 3 mins, \n","batch no = 792 / 1327, train loss = 3.854, lr = 0.007, since beginning = 4 mins, \n","batch no = 924 / 1327, train loss = 3.729, lr = 0.007, since beginning = 4 mins, \n","batch no = 1056 / 1327, train loss = 3.712, lr = 0.007, since beginning = 4 mins, \n","batch no = 1188 / 1327, train loss = 3.431, lr = 0.007, since beginning = 4 mins, \n","batch no = 1320 / 1327, train loss = 3.983, lr = 0.007, since beginning = 4 mins, \n","Epoch : 13 || Validation set perplexity : 120.399\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.555, lr = 0.004, since beginning = 4 mins, \n","batch no = 132 / 1327, train loss = 3.840, lr = 0.004, since beginning = 4 mins, \n","batch no = 264 / 1327, train loss = 4.140, lr = 0.004, since beginning = 4 mins, \n","batch no = 396 / 1327, train loss = 4.230, lr = 0.004, since beginning = 4 mins, \n","batch no = 528 / 1327, train loss = 4.035, lr = 0.004, since beginning = 4 mins, \n","batch no = 660 / 1327, train loss = 3.672, lr = 0.004, since beginning = 4 mins, \n","batch no = 792 / 1327, train loss = 3.849, lr = 0.004, since beginning = 4 mins, \n","batch no = 924 / 1327, train loss = 3.723, lr = 0.004, since beginning = 4 mins, \n","batch no = 1056 / 1327, train loss = 3.707, lr = 0.004, since beginning = 4 mins, \n","batch no = 1188 / 1327, train loss = 3.424, lr = 0.004, since beginning = 4 mins, \n","batch no = 1320 / 1327, train loss = 3.978, lr = 0.004, since beginning = 4 mins, \n","Epoch : 14 || Validation set perplexity : 120.182\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.552, lr = 0.002, since beginning = 4 mins, \n","batch no = 132 / 1327, train loss = 3.837, lr = 0.002, since beginning = 4 mins, \n","batch no = 264 / 1327, train loss = 4.137, lr = 0.002, since beginning = 4 mins, \n","batch no = 396 / 1327, train loss = 4.227, lr = 0.002, since beginning = 4 mins, \n","batch no = 528 / 1327, train loss = 4.031, lr = 0.002, since beginning = 4 mins, \n","batch no = 660 / 1327, train loss = 3.670, lr = 0.002, since beginning = 4 mins, \n","batch no = 792 / 1327, train loss = 3.847, lr = 0.002, since beginning = 4 mins, \n","batch no = 924 / 1327, train loss = 3.721, lr = 0.002, since beginning = 4 mins, \n","batch no = 1056 / 1327, train loss = 3.704, lr = 0.002, since beginning = 4 mins, \n","batch no = 1188 / 1327, train loss = 3.421, lr = 0.002, since beginning = 4 mins, \n","batch no = 1320 / 1327, train loss = 3.975, lr = 0.002, since beginning = 4 mins, \n","Epoch : 15 || Validation set perplexity : 120.068\n","*************************************************\n","\n","validation preplexity : 120.068\n","Training is over.\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["LSTM_NoDrop = test_model(dropout=0,rnn_type='LSTM', total_epochs=15,learning_rate=0.95,winit=0.05,seq_length=35,factor_epoch=5,factor=2,max_grad_norm=5, title=\"No dropout LSTM\")"]},{"cell_type":"markdown","source":["LSTM with dropout"],"metadata":{"id":"2dQ2nh2QaOVP"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"bGHqFlZJOL-T","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1684321529115,"user_tz":-180,"elapsed":1373440,"user":{"displayName":"nadav marciano","userId":"12525209232604832576"}},"outputId":"04567b8d-7b29-4324-fad9-cfc91b530d3e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Starting training.\n","\n","batch no = 0 / 1327, train loss = 9.212, lr = 0.220, since beginning = 0 mins, \n","batch no = 132 / 1327, train loss = 6.817, lr = 0.220, since beginning = 0 mins, \n","batch no = 264 / 1327, train loss = 6.700, lr = 0.220, since beginning = 0 mins, \n","batch no = 396 / 1327, train loss = 6.635, lr = 0.220, since beginning = 0 mins, \n","batch no = 528 / 1327, train loss = 6.763, lr = 0.220, since beginning = 0 mins, \n","batch no = 660 / 1327, train loss = 6.674, lr = 0.220, since beginning = 0 mins, \n","batch no = 792 / 1327, train loss = 6.439, lr = 0.220, since beginning = 0 mins, \n","batch no = 924 / 1327, train loss = 6.185, lr = 0.220, since beginning = 0 mins, \n","batch no = 1056 / 1327, train loss = 6.450, lr = 0.220, since beginning = 0 mins, \n","batch no = 1188 / 1327, train loss = 6.011, lr = 0.220, since beginning = 0 mins, \n","batch no = 1320 / 1327, train loss = 6.301, lr = 0.220, since beginning = 0 mins, \n","Epoch : 1 || Validation set perplexity : 485.088\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 6.442, lr = 0.220, since beginning = 0 mins, \n","batch no = 132 / 1327, train loss = 6.219, lr = 0.220, since beginning = 0 mins, \n","batch no = 264 / 1327, train loss = 6.201, lr = 0.220, since beginning = 0 mins, \n","batch no = 396 / 1327, train loss = 6.129, lr = 0.220, since beginning = 0 mins, \n","batch no = 528 / 1327, train loss = 6.149, lr = 0.220, since beginning = 0 mins, \n","batch no = 660 / 1327, train loss = 5.970, lr = 0.220, since beginning = 0 mins, \n","batch no = 792 / 1327, train loss = 5.945, lr = 0.220, since beginning = 0 mins, \n","batch no = 924 / 1327, train loss = 5.689, lr = 0.220, since beginning = 0 mins, \n","batch no = 1056 / 1327, train loss = 6.145, lr = 0.220, since beginning = 0 mins, \n","batch no = 1188 / 1327, train loss = 5.698, lr = 0.220, since beginning = 0 mins, \n","batch no = 1320 / 1327, train loss = 5.971, lr = 0.220, since beginning = 1 mins, \n","Epoch : 2 || Validation set perplexity : 336.197\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 6.176, lr = 0.220, since beginning = 1 mins, \n","batch no = 132 / 1327, train loss = 5.857, lr = 0.220, since beginning = 1 mins, \n","batch no = 264 / 1327, train loss = 5.927, lr = 0.220, since beginning = 1 mins, \n","batch no = 396 / 1327, train loss = 5.837, lr = 0.220, since beginning = 1 mins, \n","batch no = 528 / 1327, train loss = 5.821, lr = 0.220, since beginning = 1 mins, \n","batch no = 660 / 1327, train loss = 5.642, lr = 0.220, since beginning = 1 mins, \n","batch no = 792 / 1327, train loss = 5.715, lr = 0.220, since beginning = 1 mins, \n","batch no = 924 / 1327, train loss = 5.408, lr = 0.220, since beginning = 1 mins, \n","batch no = 1056 / 1327, train loss = 5.822, lr = 0.220, since beginning = 1 mins, \n","batch no = 1188 / 1327, train loss = 5.439, lr = 0.220, since beginning = 1 mins, \n","batch no = 1320 / 1327, train loss = 5.737, lr = 0.220, since beginning = 1 mins, \n","Epoch : 3 || Validation set perplexity : 256.154\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.952, lr = 0.220, since beginning = 1 mins, \n","batch no = 132 / 1327, train loss = 5.571, lr = 0.220, since beginning = 1 mins, \n","batch no = 264 / 1327, train loss = 5.675, lr = 0.220, since beginning = 1 mins, \n","batch no = 396 / 1327, train loss = 5.646, lr = 0.220, since beginning = 1 mins, \n","batch no = 528 / 1327, train loss = 5.665, lr = 0.220, since beginning = 1 mins, \n","batch no = 660 / 1327, train loss = 5.454, lr = 0.220, since beginning = 1 mins, \n","batch no = 792 / 1327, train loss = 5.518, lr = 0.220, since beginning = 1 mins, \n","batch no = 924 / 1327, train loss = 5.290, lr = 0.220, since beginning = 1 mins, \n","batch no = 1056 / 1327, train loss = 5.610, lr = 0.220, since beginning = 1 mins, \n","batch no = 1188 / 1327, train loss = 5.220, lr = 0.220, since beginning = 1 mins, \n","batch no = 1320 / 1327, train loss = 5.625, lr = 0.220, since beginning = 1 mins, \n","Epoch : 4 || Validation set perplexity : 220.744\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.767, lr = 0.220, since beginning = 1 mins, \n","batch no = 132 / 1327, train loss = 5.415, lr = 0.220, since beginning = 1 mins, \n","batch no = 264 / 1327, train loss = 5.503, lr = 0.220, since beginning = 1 mins, \n","batch no = 396 / 1327, train loss = 5.516, lr = 0.220, since beginning = 1 mins, \n","batch no = 528 / 1327, train loss = 5.498, lr = 0.220, since beginning = 1 mins, \n","batch no = 660 / 1327, train loss = 5.294, lr = 0.220, since beginning = 1 mins, \n","batch no = 792 / 1327, train loss = 5.400, lr = 0.220, since beginning = 1 mins, \n","batch no = 924 / 1327, train loss = 5.153, lr = 0.220, since beginning = 1 mins, \n","batch no = 1056 / 1327, train loss = 5.475, lr = 0.220, since beginning = 1 mins, \n","batch no = 1188 / 1327, train loss = 5.118, lr = 0.220, since beginning = 1 mins, \n","batch no = 1320 / 1327, train loss = 5.444, lr = 0.220, since beginning = 1 mins, \n","Epoch : 5 || Validation set perplexity : 198.588\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.705, lr = 0.220, since beginning = 1 mins, \n","batch no = 132 / 1327, train loss = 5.291, lr = 0.220, since beginning = 1 mins, \n","batch no = 264 / 1327, train loss = 5.396, lr = 0.220, since beginning = 1 mins, \n","batch no = 396 / 1327, train loss = 5.420, lr = 0.220, since beginning = 1 mins, \n","batch no = 528 / 1327, train loss = 5.423, lr = 0.220, since beginning = 2 mins, \n","batch no = 660 / 1327, train loss = 5.198, lr = 0.220, since beginning = 2 mins, \n","batch no = 792 / 1327, train loss = 5.316, lr = 0.220, since beginning = 2 mins, \n","batch no = 924 / 1327, train loss = 5.086, lr = 0.220, since beginning = 2 mins, \n","batch no = 1056 / 1327, train loss = 5.332, lr = 0.220, since beginning = 2 mins, \n","batch no = 1188 / 1327, train loss = 5.017, lr = 0.220, since beginning = 2 mins, \n","batch no = 1320 / 1327, train loss = 5.418, lr = 0.220, since beginning = 2 mins, \n","Epoch : 6 || Validation set perplexity : 182.665\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.595, lr = 0.220, since beginning = 2 mins, \n","batch no = 132 / 1327, train loss = 5.231, lr = 0.220, since beginning = 2 mins, \n","batch no = 264 / 1327, train loss = 5.304, lr = 0.220, since beginning = 2 mins, \n","batch no = 396 / 1327, train loss = 5.387, lr = 0.220, since beginning = 2 mins, \n","batch no = 528 / 1327, train loss = 5.358, lr = 0.220, since beginning = 2 mins, \n","batch no = 660 / 1327, train loss = 5.073, lr = 0.220, since beginning = 2 mins, \n","batch no = 792 / 1327, train loss = 5.243, lr = 0.220, since beginning = 2 mins, \n","batch no = 924 / 1327, train loss = 5.047, lr = 0.220, since beginning = 2 mins, \n","batch no = 1056 / 1327, train loss = 5.285, lr = 0.220, since beginning = 2 mins, \n","batch no = 1188 / 1327, train loss = 4.967, lr = 0.220, since beginning = 2 mins, \n","batch no = 1320 / 1327, train loss = 5.371, lr = 0.220, since beginning = 2 mins, \n","Epoch : 7 || Validation set perplexity : 171.636\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.527, lr = 0.220, since beginning = 2 mins, \n","batch no = 132 / 1327, train loss = 5.166, lr = 0.220, since beginning = 2 mins, \n","batch no = 264 / 1327, train loss = 5.284, lr = 0.220, since beginning = 2 mins, \n","batch no = 396 / 1327, train loss = 5.327, lr = 0.220, since beginning = 2 mins, \n","batch no = 528 / 1327, train loss = 5.273, lr = 0.220, since beginning = 2 mins, \n","batch no = 660 / 1327, train loss = 5.030, lr = 0.220, since beginning = 2 mins, \n","batch no = 792 / 1327, train loss = 5.147, lr = 0.220, since beginning = 2 mins, \n","batch no = 924 / 1327, train loss = 4.950, lr = 0.220, since beginning = 2 mins, \n","batch no = 1056 / 1327, train loss = 5.219, lr = 0.220, since beginning = 2 mins, \n","batch no = 1188 / 1327, train loss = 4.878, lr = 0.220, since beginning = 2 mins, \n","batch no = 1320 / 1327, train loss = 5.324, lr = 0.220, since beginning = 2 mins, \n","Epoch : 8 || Validation set perplexity : 163.458\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.486, lr = 0.220, since beginning = 2 mins, \n","batch no = 132 / 1327, train loss = 5.068, lr = 0.220, since beginning = 2 mins, \n","batch no = 264 / 1327, train loss = 5.256, lr = 0.220, since beginning = 2 mins, \n","batch no = 396 / 1327, train loss = 5.225, lr = 0.220, since beginning = 2 mins, \n","batch no = 528 / 1327, train loss = 5.227, lr = 0.220, since beginning = 2 mins, \n","batch no = 660 / 1327, train loss = 5.014, lr = 0.220, since beginning = 2 mins, \n","batch no = 792 / 1327, train loss = 5.132, lr = 0.220, since beginning = 2 mins, \n","batch no = 924 / 1327, train loss = 4.932, lr = 0.220, since beginning = 2 mins, \n","batch no = 1056 / 1327, train loss = 5.102, lr = 0.220, since beginning = 2 mins, \n","batch no = 1188 / 1327, train loss = 4.865, lr = 0.220, since beginning = 2 mins, \n","batch no = 1320 / 1327, train loss = 5.228, lr = 0.220, since beginning = 2 mins, \n","Epoch : 9 || Validation set perplexity : 156.455\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.473, lr = 0.220, since beginning = 3 mins, \n","batch no = 132 / 1327, train loss = 4.998, lr = 0.220, since beginning = 3 mins, \n","batch no = 264 / 1327, train loss = 5.195, lr = 0.220, since beginning = 3 mins, \n","batch no = 396 / 1327, train loss = 5.220, lr = 0.220, since beginning = 3 mins, \n","batch no = 528 / 1327, train loss = 5.163, lr = 0.220, since beginning = 3 mins, \n","batch no = 660 / 1327, train loss = 4.909, lr = 0.220, since beginning = 3 mins, \n","batch no = 792 / 1327, train loss = 5.098, lr = 0.220, since beginning = 3 mins, \n","batch no = 924 / 1327, train loss = 4.834, lr = 0.220, since beginning = 3 mins, \n","batch no = 1056 / 1327, train loss = 5.090, lr = 0.220, since beginning = 3 mins, \n","batch no = 1188 / 1327, train loss = 4.827, lr = 0.220, since beginning = 3 mins, \n","batch no = 1320 / 1327, train loss = 5.220, lr = 0.220, since beginning = 3 mins, \n","Epoch : 10 || Validation set perplexity : 150.128\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.497, lr = 0.220, since beginning = 3 mins, \n","batch no = 132 / 1327, train loss = 4.966, lr = 0.220, since beginning = 3 mins, \n","batch no = 264 / 1327, train loss = 5.168, lr = 0.220, since beginning = 3 mins, \n","batch no = 396 / 1327, train loss = 5.152, lr = 0.220, since beginning = 3 mins, \n","batch no = 528 / 1327, train loss = 5.181, lr = 0.220, since beginning = 3 mins, \n","batch no = 660 / 1327, train loss = 4.896, lr = 0.220, since beginning = 3 mins, \n","batch no = 792 / 1327, train loss = 5.058, lr = 0.220, since beginning = 3 mins, \n","batch no = 924 / 1327, train loss = 4.807, lr = 0.220, since beginning = 3 mins, \n","batch no = 1056 / 1327, train loss = 5.076, lr = 0.220, since beginning = 3 mins, \n","batch no = 1188 / 1327, train loss = 4.808, lr = 0.220, since beginning = 3 mins, \n","batch no = 1320 / 1327, train loss = 5.200, lr = 0.220, since beginning = 3 mins, \n","Epoch : 11 || Validation set perplexity : 145.017\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.378, lr = 0.220, since beginning = 3 mins, \n","batch no = 132 / 1327, train loss = 4.976, lr = 0.220, since beginning = 3 mins, \n","batch no = 264 / 1327, train loss = 5.141, lr = 0.220, since beginning = 3 mins, \n","batch no = 396 / 1327, train loss = 5.176, lr = 0.220, since beginning = 3 mins, \n","batch no = 528 / 1327, train loss = 5.133, lr = 0.220, since beginning = 3 mins, \n","batch no = 660 / 1327, train loss = 4.868, lr = 0.220, since beginning = 3 mins, \n","batch no = 792 / 1327, train loss = 5.071, lr = 0.220, since beginning = 3 mins, \n","batch no = 924 / 1327, train loss = 4.779, lr = 0.220, since beginning = 3 mins, \n","batch no = 1056 / 1327, train loss = 5.040, lr = 0.220, since beginning = 3 mins, \n","batch no = 1188 / 1327, train loss = 4.822, lr = 0.220, since beginning = 3 mins, \n","batch no = 1320 / 1327, train loss = 5.155, lr = 0.220, since beginning = 3 mins, \n","Epoch : 12 || Validation set perplexity : 140.932\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.389, lr = 0.220, since beginning = 3 mins, \n","batch no = 132 / 1327, train loss = 4.865, lr = 0.220, since beginning = 3 mins, \n","batch no = 264 / 1327, train loss = 5.110, lr = 0.220, since beginning = 3 mins, \n","batch no = 396 / 1327, train loss = 5.132, lr = 0.220, since beginning = 3 mins, \n","batch no = 528 / 1327, train loss = 5.068, lr = 0.220, since beginning = 3 mins, \n","batch no = 660 / 1327, train loss = 4.804, lr = 0.220, since beginning = 4 mins, \n","batch no = 792 / 1327, train loss = 5.022, lr = 0.220, since beginning = 4 mins, \n","batch no = 924 / 1327, train loss = 4.754, lr = 0.220, since beginning = 4 mins, \n","batch no = 1056 / 1327, train loss = 4.979, lr = 0.220, since beginning = 4 mins, \n","batch no = 1188 / 1327, train loss = 4.715, lr = 0.220, since beginning = 4 mins, \n","batch no = 1320 / 1327, train loss = 5.145, lr = 0.220, since beginning = 4 mins, \n","Epoch : 13 || Validation set perplexity : 137.959\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.358, lr = 0.220, since beginning = 4 mins, \n","batch no = 132 / 1327, train loss = 4.870, lr = 0.220, since beginning = 4 mins, \n","batch no = 264 / 1327, train loss = 5.062, lr = 0.220, since beginning = 4 mins, \n","batch no = 396 / 1327, train loss = 5.137, lr = 0.220, since beginning = 4 mins, \n","batch no = 528 / 1327, train loss = 5.077, lr = 0.220, since beginning = 4 mins, \n","batch no = 660 / 1327, train loss = 4.767, lr = 0.220, since beginning = 4 mins, \n","batch no = 792 / 1327, train loss = 4.976, lr = 0.220, since beginning = 4 mins, \n","batch no = 924 / 1327, train loss = 4.756, lr = 0.220, since beginning = 4 mins, \n","batch no = 1056 / 1327, train loss = 4.943, lr = 0.220, since beginning = 4 mins, \n","batch no = 1188 / 1327, train loss = 4.726, lr = 0.220, since beginning = 4 mins, \n","batch no = 1320 / 1327, train loss = 5.119, lr = 0.220, since beginning = 4 mins, \n","Epoch : 14 || Validation set perplexity : 134.063\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.350, lr = 0.220, since beginning = 4 mins, \n","batch no = 132 / 1327, train loss = 4.818, lr = 0.220, since beginning = 4 mins, \n","batch no = 264 / 1327, train loss = 5.032, lr = 0.220, since beginning = 4 mins, \n","batch no = 396 / 1327, train loss = 5.076, lr = 0.220, since beginning = 4 mins, \n","batch no = 528 / 1327, train loss = 5.048, lr = 0.220, since beginning = 4 mins, \n","batch no = 660 / 1327, train loss = 4.823, lr = 0.220, since beginning = 4 mins, \n","batch no = 792 / 1327, train loss = 4.947, lr = 0.220, since beginning = 4 mins, \n","batch no = 924 / 1327, train loss = 4.760, lr = 0.220, since beginning = 4 mins, \n","batch no = 1056 / 1327, train loss = 4.923, lr = 0.220, since beginning = 4 mins, \n","batch no = 1188 / 1327, train loss = 4.634, lr = 0.220, since beginning = 4 mins, \n","batch no = 1320 / 1327, train loss = 5.054, lr = 0.220, since beginning = 4 mins, \n","Epoch : 15 || Validation set perplexity : 132.104\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.319, lr = 0.220, since beginning = 4 mins, \n","batch no = 132 / 1327, train loss = 4.773, lr = 0.220, since beginning = 4 mins, \n","batch no = 264 / 1327, train loss = 4.962, lr = 0.220, since beginning = 4 mins, \n","batch no = 396 / 1327, train loss = 5.036, lr = 0.220, since beginning = 4 mins, \n","batch no = 528 / 1327, train loss = 4.975, lr = 0.220, since beginning = 4 mins, \n","batch no = 660 / 1327, train loss = 4.714, lr = 0.220, since beginning = 4 mins, \n","batch no = 792 / 1327, train loss = 4.954, lr = 0.220, since beginning = 4 mins, \n","batch no = 924 / 1327, train loss = 4.759, lr = 0.220, since beginning = 4 mins, \n","batch no = 1056 / 1327, train loss = 4.931, lr = 0.220, since beginning = 4 mins, \n","batch no = 1188 / 1327, train loss = 4.659, lr = 0.220, since beginning = 4 mins, \n","batch no = 1320 / 1327, train loss = 5.063, lr = 0.220, since beginning = 4 mins, \n","Epoch : 16 || Validation set perplexity : 129.282\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.236, lr = 0.220, since beginning = 5 mins, \n","batch no = 132 / 1327, train loss = 4.767, lr = 0.220, since beginning = 5 mins, \n","batch no = 264 / 1327, train loss = 5.037, lr = 0.220, since beginning = 5 mins, \n","batch no = 396 / 1327, train loss = 5.068, lr = 0.220, since beginning = 5 mins, \n","batch no = 528 / 1327, train loss = 5.000, lr = 0.220, since beginning = 5 mins, \n","batch no = 660 / 1327, train loss = 4.836, lr = 0.220, since beginning = 5 mins, \n","batch no = 792 / 1327, train loss = 4.958, lr = 0.220, since beginning = 5 mins, \n","batch no = 924 / 1327, train loss = 4.760, lr = 0.220, since beginning = 5 mins, \n","batch no = 1056 / 1327, train loss = 4.842, lr = 0.220, since beginning = 5 mins, \n","batch no = 1188 / 1327, train loss = 4.642, lr = 0.220, since beginning = 5 mins, \n","batch no = 1320 / 1327, train loss = 5.026, lr = 0.220, since beginning = 5 mins, \n","Epoch : 17 || Validation set perplexity : 127.093\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.246, lr = 0.220, since beginning = 5 mins, \n","batch no = 132 / 1327, train loss = 4.747, lr = 0.220, since beginning = 5 mins, \n","batch no = 264 / 1327, train loss = 5.012, lr = 0.220, since beginning = 5 mins, \n","batch no = 396 / 1327, train loss = 5.039, lr = 0.220, since beginning = 5 mins, \n","batch no = 528 / 1327, train loss = 4.970, lr = 0.220, since beginning = 5 mins, \n","batch no = 660 / 1327, train loss = 4.667, lr = 0.220, since beginning = 5 mins, \n","batch no = 792 / 1327, train loss = 4.880, lr = 0.220, since beginning = 5 mins, \n","batch no = 924 / 1327, train loss = 4.720, lr = 0.220, since beginning = 5 mins, \n","batch no = 1056 / 1327, train loss = 4.836, lr = 0.220, since beginning = 5 mins, \n","batch no = 1188 / 1327, train loss = 4.610, lr = 0.220, since beginning = 5 mins, \n","batch no = 1320 / 1327, train loss = 5.062, lr = 0.220, since beginning = 5 mins, \n","Epoch : 18 || Validation set perplexity : 125.723\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.265, lr = 0.220, since beginning = 5 mins, \n","batch no = 132 / 1327, train loss = 4.721, lr = 0.220, since beginning = 5 mins, \n","batch no = 264 / 1327, train loss = 4.970, lr = 0.220, since beginning = 5 mins, \n","batch no = 396 / 1327, train loss = 5.003, lr = 0.220, since beginning = 5 mins, \n","batch no = 528 / 1327, train loss = 4.962, lr = 0.220, since beginning = 5 mins, \n","batch no = 660 / 1327, train loss = 4.675, lr = 0.220, since beginning = 5 mins, \n","batch no = 792 / 1327, train loss = 4.898, lr = 0.220, since beginning = 5 mins, \n","batch no = 924 / 1327, train loss = 4.681, lr = 0.220, since beginning = 5 mins, \n","batch no = 1056 / 1327, train loss = 4.897, lr = 0.220, since beginning = 5 mins, \n","batch no = 1188 / 1327, train loss = 4.582, lr = 0.220, since beginning = 5 mins, \n","batch no = 1320 / 1327, train loss = 4.987, lr = 0.220, since beginning = 5 mins, \n","Epoch : 19 || Validation set perplexity : 123.971\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.250, lr = 0.220, since beginning = 5 mins, \n","batch no = 132 / 1327, train loss = 4.705, lr = 0.220, since beginning = 5 mins, \n","batch no = 264 / 1327, train loss = 4.953, lr = 0.220, since beginning = 5 mins, \n","batch no = 396 / 1327, train loss = 4.959, lr = 0.220, since beginning = 5 mins, \n","batch no = 528 / 1327, train loss = 4.945, lr = 0.220, since beginning = 5 mins, \n","batch no = 660 / 1327, train loss = 4.691, lr = 0.220, since beginning = 5 mins, \n","batch no = 792 / 1327, train loss = 4.816, lr = 0.220, since beginning = 6 mins, \n","batch no = 924 / 1327, train loss = 4.674, lr = 0.220, since beginning = 6 mins, \n","batch no = 1056 / 1327, train loss = 4.864, lr = 0.220, since beginning = 6 mins, \n","batch no = 1188 / 1327, train loss = 4.619, lr = 0.220, since beginning = 6 mins, \n","batch no = 1320 / 1327, train loss = 5.019, lr = 0.220, since beginning = 6 mins, \n","Epoch : 20 || Validation set perplexity : 122.297\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.180, lr = 0.220, since beginning = 6 mins, \n","batch no = 132 / 1327, train loss = 4.666, lr = 0.220, since beginning = 6 mins, \n","batch no = 264 / 1327, train loss = 4.940, lr = 0.220, since beginning = 6 mins, \n","batch no = 396 / 1327, train loss = 4.986, lr = 0.220, since beginning = 6 mins, \n","batch no = 528 / 1327, train loss = 4.951, lr = 0.220, since beginning = 6 mins, \n","batch no = 660 / 1327, train loss = 4.702, lr = 0.220, since beginning = 6 mins, \n","batch no = 792 / 1327, train loss = 4.872, lr = 0.220, since beginning = 6 mins, \n","batch no = 924 / 1327, train loss = 4.617, lr = 0.220, since beginning = 6 mins, \n","batch no = 1056 / 1327, train loss = 4.789, lr = 0.220, since beginning = 6 mins, \n","batch no = 1188 / 1327, train loss = 4.537, lr = 0.220, since beginning = 6 mins, \n","batch no = 1320 / 1327, train loss = 4.967, lr = 0.220, since beginning = 6 mins, \n","Epoch : 21 || Validation set perplexity : 121.202\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.183, lr = 0.220, since beginning = 6 mins, \n","batch no = 132 / 1327, train loss = 4.695, lr = 0.220, since beginning = 6 mins, \n","batch no = 264 / 1327, train loss = 4.988, lr = 0.220, since beginning = 6 mins, \n","batch no = 396 / 1327, train loss = 4.944, lr = 0.220, since beginning = 6 mins, \n","batch no = 528 / 1327, train loss = 4.979, lr = 0.220, since beginning = 6 mins, \n","batch no = 660 / 1327, train loss = 4.713, lr = 0.220, since beginning = 6 mins, \n","batch no = 792 / 1327, train loss = 4.850, lr = 0.220, since beginning = 6 mins, \n","batch no = 924 / 1327, train loss = 4.552, lr = 0.220, since beginning = 6 mins, \n","batch no = 1056 / 1327, train loss = 4.782, lr = 0.220, since beginning = 6 mins, \n","batch no = 1188 / 1327, train loss = 4.504, lr = 0.220, since beginning = 6 mins, \n","batch no = 1320 / 1327, train loss = 4.976, lr = 0.220, since beginning = 6 mins, \n","Epoch : 22 || Validation set perplexity : 120.091\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.173, lr = 0.220, since beginning = 6 mins, \n","batch no = 132 / 1327, train loss = 4.670, lr = 0.220, since beginning = 6 mins, \n","batch no = 264 / 1327, train loss = 4.906, lr = 0.220, since beginning = 6 mins, \n","batch no = 396 / 1327, train loss = 4.982, lr = 0.220, since beginning = 6 mins, \n","batch no = 528 / 1327, train loss = 4.959, lr = 0.220, since beginning = 6 mins, \n","batch no = 660 / 1327, train loss = 4.628, lr = 0.220, since beginning = 6 mins, \n","batch no = 792 / 1327, train loss = 4.818, lr = 0.220, since beginning = 6 mins, \n","batch no = 924 / 1327, train loss = 4.615, lr = 0.220, since beginning = 6 mins, \n","batch no = 1056 / 1327, train loss = 4.792, lr = 0.220, since beginning = 6 mins, \n","batch no = 1188 / 1327, train loss = 4.504, lr = 0.220, since beginning = 6 mins, \n","batch no = 1320 / 1327, train loss = 4.950, lr = 0.220, since beginning = 6 mins, \n","Epoch : 23 || Validation set perplexity : 118.721\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.173, lr = 0.220, since beginning = 7 mins, \n","batch no = 132 / 1327, train loss = 4.633, lr = 0.220, since beginning = 7 mins, \n","batch no = 264 / 1327, train loss = 4.939, lr = 0.220, since beginning = 7 mins, \n","batch no = 396 / 1327, train loss = 4.928, lr = 0.220, since beginning = 7 mins, \n","batch no = 528 / 1327, train loss = 4.970, lr = 0.220, since beginning = 7 mins, \n","batch no = 660 / 1327, train loss = 4.647, lr = 0.220, since beginning = 7 mins, \n","batch no = 792 / 1327, train loss = 4.752, lr = 0.220, since beginning = 7 mins, \n","batch no = 924 / 1327, train loss = 4.602, lr = 0.220, since beginning = 7 mins, \n","batch no = 1056 / 1327, train loss = 4.741, lr = 0.220, since beginning = 7 mins, \n","batch no = 1188 / 1327, train loss = 4.503, lr = 0.220, since beginning = 7 mins, \n","batch no = 1320 / 1327, train loss = 4.902, lr = 0.220, since beginning = 7 mins, \n","Epoch : 24 || Validation set perplexity : 117.477\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.198, lr = 0.220, since beginning = 7 mins, \n","batch no = 132 / 1327, train loss = 4.685, lr = 0.220, since beginning = 7 mins, \n","batch no = 264 / 1327, train loss = 4.836, lr = 0.220, since beginning = 7 mins, \n","batch no = 396 / 1327, train loss = 4.931, lr = 0.220, since beginning = 7 mins, \n","batch no = 528 / 1327, train loss = 4.841, lr = 0.220, since beginning = 7 mins, \n","batch no = 660 / 1327, train loss = 4.655, lr = 0.220, since beginning = 7 mins, \n","batch no = 792 / 1327, train loss = 4.774, lr = 0.220, since beginning = 7 mins, \n","batch no = 924 / 1327, train loss = 4.610, lr = 0.220, since beginning = 7 mins, \n","batch no = 1056 / 1327, train loss = 4.732, lr = 0.220, since beginning = 7 mins, \n","batch no = 1188 / 1327, train loss = 4.490, lr = 0.220, since beginning = 7 mins, \n","batch no = 1320 / 1327, train loss = 4.880, lr = 0.220, since beginning = 7 mins, \n","Epoch : 25 || Validation set perplexity : 116.899\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.123, lr = 0.220, since beginning = 7 mins, \n","batch no = 132 / 1327, train loss = 4.612, lr = 0.220, since beginning = 7 mins, \n","batch no = 264 / 1327, train loss = 4.853, lr = 0.220, since beginning = 7 mins, \n","batch no = 396 / 1327, train loss = 4.918, lr = 0.220, since beginning = 7 mins, \n","batch no = 528 / 1327, train loss = 4.854, lr = 0.220, since beginning = 7 mins, \n","batch no = 660 / 1327, train loss = 4.606, lr = 0.220, since beginning = 7 mins, \n","batch no = 792 / 1327, train loss = 4.772, lr = 0.220, since beginning = 7 mins, \n","batch no = 924 / 1327, train loss = 4.569, lr = 0.220, since beginning = 7 mins, \n","batch no = 1056 / 1327, train loss = 4.729, lr = 0.220, since beginning = 7 mins, \n","batch no = 1188 / 1327, train loss = 4.487, lr = 0.220, since beginning = 7 mins, \n","batch no = 1320 / 1327, train loss = 4.882, lr = 0.220, since beginning = 7 mins, \n","Epoch : 26 || Validation set perplexity : 115.667\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.163, lr = 0.220, since beginning = 7 mins, \n","batch no = 132 / 1327, train loss = 4.648, lr = 0.220, since beginning = 7 mins, \n","batch no = 264 / 1327, train loss = 4.889, lr = 0.220, since beginning = 7 mins, \n","batch no = 396 / 1327, train loss = 4.886, lr = 0.220, since beginning = 7 mins, \n","batch no = 528 / 1327, train loss = 4.865, lr = 0.220, since beginning = 7 mins, \n","batch no = 660 / 1327, train loss = 4.594, lr = 0.220, since beginning = 7 mins, \n","batch no = 792 / 1327, train loss = 4.710, lr = 0.220, since beginning = 7 mins, \n","batch no = 924 / 1327, train loss = 4.596, lr = 0.220, since beginning = 8 mins, \n","batch no = 1056 / 1327, train loss = 4.735, lr = 0.220, since beginning = 8 mins, \n","batch no = 1188 / 1327, train loss = 4.413, lr = 0.220, since beginning = 8 mins, \n","batch no = 1320 / 1327, train loss = 4.880, lr = 0.220, since beginning = 8 mins, \n","Epoch : 27 || Validation set perplexity : 115.048\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.164, lr = 0.220, since beginning = 8 mins, \n","batch no = 132 / 1327, train loss = 4.545, lr = 0.220, since beginning = 8 mins, \n","batch no = 264 / 1327, train loss = 4.881, lr = 0.220, since beginning = 8 mins, \n","batch no = 396 / 1327, train loss = 4.913, lr = 0.220, since beginning = 8 mins, \n","batch no = 528 / 1327, train loss = 4.815, lr = 0.220, since beginning = 8 mins, \n","batch no = 660 / 1327, train loss = 4.565, lr = 0.220, since beginning = 8 mins, \n","batch no = 792 / 1327, train loss = 4.754, lr = 0.220, since beginning = 8 mins, \n","batch no = 924 / 1327, train loss = 4.533, lr = 0.220, since beginning = 8 mins, \n","batch no = 1056 / 1327, train loss = 4.736, lr = 0.220, since beginning = 8 mins, \n","batch no = 1188 / 1327, train loss = 4.418, lr = 0.220, since beginning = 8 mins, \n","batch no = 1320 / 1327, train loss = 4.922, lr = 0.220, since beginning = 8 mins, \n","Epoch : 28 || Validation set perplexity : 114.621\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.106, lr = 0.220, since beginning = 8 mins, \n","batch no = 132 / 1327, train loss = 4.615, lr = 0.220, since beginning = 8 mins, \n","batch no = 264 / 1327, train loss = 4.826, lr = 0.220, since beginning = 8 mins, \n","batch no = 396 / 1327, train loss = 4.886, lr = 0.220, since beginning = 8 mins, \n","batch no = 528 / 1327, train loss = 4.845, lr = 0.220, since beginning = 8 mins, \n","batch no = 660 / 1327, train loss = 4.612, lr = 0.220, since beginning = 8 mins, \n","batch no = 792 / 1327, train loss = 4.750, lr = 0.220, since beginning = 8 mins, \n","batch no = 924 / 1327, train loss = 4.582, lr = 0.220, since beginning = 8 mins, \n","batch no = 1056 / 1327, train loss = 4.714, lr = 0.220, since beginning = 8 mins, \n","batch no = 1188 / 1327, train loss = 4.486, lr = 0.220, since beginning = 8 mins, \n","batch no = 1320 / 1327, train loss = 4.825, lr = 0.220, since beginning = 8 mins, \n","Epoch : 29 || Validation set perplexity : 113.754\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.100, lr = 0.220, since beginning = 8 mins, \n","batch no = 132 / 1327, train loss = 4.570, lr = 0.220, since beginning = 8 mins, \n","batch no = 264 / 1327, train loss = 4.845, lr = 0.220, since beginning = 8 mins, \n","batch no = 396 / 1327, train loss = 4.930, lr = 0.220, since beginning = 8 mins, \n","batch no = 528 / 1327, train loss = 4.823, lr = 0.220, since beginning = 8 mins, \n","batch no = 660 / 1327, train loss = 4.620, lr = 0.220, since beginning = 8 mins, \n","batch no = 792 / 1327, train loss = 4.676, lr = 0.220, since beginning = 8 mins, \n","batch no = 924 / 1327, train loss = 4.598, lr = 0.220, since beginning = 8 mins, \n","batch no = 1056 / 1327, train loss = 4.674, lr = 0.220, since beginning = 8 mins, \n","batch no = 1188 / 1327, train loss = 4.413, lr = 0.220, since beginning = 8 mins, \n","batch no = 1320 / 1327, train loss = 4.912, lr = 0.220, since beginning = 8 mins, \n","Epoch : 30 || Validation set perplexity : 113.181\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.076, lr = 0.220, since beginning = 9 mins, \n","batch no = 132 / 1327, train loss = 4.531, lr = 0.220, since beginning = 9 mins, \n","batch no = 264 / 1327, train loss = 4.837, lr = 0.220, since beginning = 9 mins, \n","batch no = 396 / 1327, train loss = 4.886, lr = 0.220, since beginning = 9 mins, \n","batch no = 528 / 1327, train loss = 4.772, lr = 0.220, since beginning = 9 mins, \n","batch no = 660 / 1327, train loss = 4.564, lr = 0.220, since beginning = 9 mins, \n","batch no = 792 / 1327, train loss = 4.748, lr = 0.220, since beginning = 9 mins, \n","batch no = 924 / 1327, train loss = 4.559, lr = 0.220, since beginning = 9 mins, \n","batch no = 1056 / 1327, train loss = 4.672, lr = 0.220, since beginning = 9 mins, \n","batch no = 1188 / 1327, train loss = 4.479, lr = 0.220, since beginning = 9 mins, \n","batch no = 1320 / 1327, train loss = 4.902, lr = 0.220, since beginning = 9 mins, \n","Epoch : 31 || Validation set perplexity : 112.513\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.080, lr = 0.220, since beginning = 9 mins, \n","batch no = 132 / 1327, train loss = 4.492, lr = 0.220, since beginning = 9 mins, \n","batch no = 264 / 1327, train loss = 4.824, lr = 0.220, since beginning = 9 mins, \n","batch no = 396 / 1327, train loss = 4.874, lr = 0.220, since beginning = 9 mins, \n","batch no = 528 / 1327, train loss = 4.818, lr = 0.220, since beginning = 9 mins, \n","batch no = 660 / 1327, train loss = 4.554, lr = 0.220, since beginning = 9 mins, \n","batch no = 792 / 1327, train loss = 4.725, lr = 0.220, since beginning = 9 mins, \n","batch no = 924 / 1327, train loss = 4.539, lr = 0.220, since beginning = 9 mins, \n","batch no = 1056 / 1327, train loss = 4.668, lr = 0.220, since beginning = 9 mins, \n","batch no = 1188 / 1327, train loss = 4.380, lr = 0.220, since beginning = 9 mins, \n","batch no = 1320 / 1327, train loss = 4.812, lr = 0.220, since beginning = 9 mins, \n","Epoch : 32 || Validation set perplexity : 112.047\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.074, lr = 0.220, since beginning = 9 mins, \n","batch no = 132 / 1327, train loss = 4.482, lr = 0.220, since beginning = 9 mins, \n","batch no = 264 / 1327, train loss = 4.838, lr = 0.220, since beginning = 9 mins, \n","batch no = 396 / 1327, train loss = 4.895, lr = 0.220, since beginning = 9 mins, \n","batch no = 528 / 1327, train loss = 4.844, lr = 0.220, since beginning = 9 mins, \n","batch no = 660 / 1327, train loss = 4.546, lr = 0.220, since beginning = 9 mins, \n","batch no = 792 / 1327, train loss = 4.706, lr = 0.220, since beginning = 9 mins, \n","batch no = 924 / 1327, train loss = 4.573, lr = 0.220, since beginning = 9 mins, \n","batch no = 1056 / 1327, train loss = 4.631, lr = 0.220, since beginning = 9 mins, \n","batch no = 1188 / 1327, train loss = 4.402, lr = 0.220, since beginning = 9 mins, \n","batch no = 1320 / 1327, train loss = 4.816, lr = 0.220, since beginning = 9 mins, \n","Epoch : 33 || Validation set perplexity : 111.467\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.106, lr = 0.220, since beginning = 9 mins, \n","batch no = 132 / 1327, train loss = 4.529, lr = 0.220, since beginning = 9 mins, \n","batch no = 264 / 1327, train loss = 4.787, lr = 0.220, since beginning = 9 mins, \n","batch no = 396 / 1327, train loss = 4.845, lr = 0.220, since beginning = 9 mins, \n","batch no = 528 / 1327, train loss = 4.794, lr = 0.220, since beginning = 9 mins, \n","batch no = 660 / 1327, train loss = 4.534, lr = 0.220, since beginning = 9 mins, \n","batch no = 792 / 1327, train loss = 4.733, lr = 0.220, since beginning = 9 mins, \n","batch no = 924 / 1327, train loss = 4.535, lr = 0.220, since beginning = 10 mins, \n","batch no = 1056 / 1327, train loss = 4.674, lr = 0.220, since beginning = 10 mins, \n","batch no = 1188 / 1327, train loss = 4.412, lr = 0.220, since beginning = 10 mins, \n","batch no = 1320 / 1327, train loss = 4.850, lr = 0.220, since beginning = 10 mins, \n","Epoch : 34 || Validation set perplexity : 110.882\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.042, lr = 0.220, since beginning = 10 mins, \n","batch no = 132 / 1327, train loss = 4.508, lr = 0.220, since beginning = 10 mins, \n","batch no = 264 / 1327, train loss = 4.800, lr = 0.220, since beginning = 10 mins, \n","batch no = 396 / 1327, train loss = 4.809, lr = 0.220, since beginning = 10 mins, \n","batch no = 528 / 1327, train loss = 4.811, lr = 0.220, since beginning = 10 mins, \n","batch no = 660 / 1327, train loss = 4.511, lr = 0.220, since beginning = 10 mins, \n","batch no = 792 / 1327, train loss = 4.665, lr = 0.220, since beginning = 10 mins, \n","batch no = 924 / 1327, train loss = 4.493, lr = 0.220, since beginning = 10 mins, \n","batch no = 1056 / 1327, train loss = 4.626, lr = 0.220, since beginning = 10 mins, \n","batch no = 1188 / 1327, train loss = 4.423, lr = 0.220, since beginning = 10 mins, \n","batch no = 1320 / 1327, train loss = 4.813, lr = 0.220, since beginning = 10 mins, \n","Epoch : 35 || Validation set perplexity : 110.505\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.129, lr = 0.220, since beginning = 10 mins, \n","batch no = 132 / 1327, train loss = 4.501, lr = 0.220, since beginning = 10 mins, \n","batch no = 264 / 1327, train loss = 4.732, lr = 0.220, since beginning = 10 mins, \n","batch no = 396 / 1327, train loss = 4.855, lr = 0.220, since beginning = 10 mins, \n","batch no = 528 / 1327, train loss = 4.805, lr = 0.220, since beginning = 10 mins, \n","batch no = 660 / 1327, train loss = 4.486, lr = 0.220, since beginning = 10 mins, \n","batch no = 792 / 1327, train loss = 4.695, lr = 0.220, since beginning = 10 mins, \n","batch no = 924 / 1327, train loss = 4.536, lr = 0.220, since beginning = 10 mins, \n","batch no = 1056 / 1327, train loss = 4.598, lr = 0.220, since beginning = 10 mins, \n","batch no = 1188 / 1327, train loss = 4.403, lr = 0.220, since beginning = 10 mins, \n","batch no = 1320 / 1327, train loss = 4.815, lr = 0.220, since beginning = 10 mins, \n","Epoch : 36 || Validation set perplexity : 110.182\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.108, lr = 0.220, since beginning = 10 mins, \n","batch no = 132 / 1327, train loss = 4.521, lr = 0.220, since beginning = 10 mins, \n","batch no = 264 / 1327, train loss = 4.789, lr = 0.220, since beginning = 10 mins, \n","batch no = 396 / 1327, train loss = 4.866, lr = 0.220, since beginning = 10 mins, \n","batch no = 528 / 1327, train loss = 4.799, lr = 0.220, since beginning = 10 mins, \n","batch no = 660 / 1327, train loss = 4.581, lr = 0.220, since beginning = 10 mins, \n","batch no = 792 / 1327, train loss = 4.724, lr = 0.220, since beginning = 10 mins, \n","batch no = 924 / 1327, train loss = 4.535, lr = 0.220, since beginning = 10 mins, \n","batch no = 1056 / 1327, train loss = 4.622, lr = 0.220, since beginning = 10 mins, \n","batch no = 1188 / 1327, train loss = 4.367, lr = 0.220, since beginning = 10 mins, \n","batch no = 1320 / 1327, train loss = 4.803, lr = 0.220, since beginning = 10 mins, \n","Epoch : 37 || Validation set perplexity : 109.811\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.074, lr = 0.220, since beginning = 11 mins, \n","batch no = 132 / 1327, train loss = 4.462, lr = 0.220, since beginning = 11 mins, \n","batch no = 264 / 1327, train loss = 4.805, lr = 0.220, since beginning = 11 mins, \n","batch no = 396 / 1327, train loss = 4.823, lr = 0.220, since beginning = 11 mins, \n","batch no = 528 / 1327, train loss = 4.791, lr = 0.220, since beginning = 11 mins, \n","batch no = 660 / 1327, train loss = 4.553, lr = 0.220, since beginning = 11 mins, \n","batch no = 792 / 1327, train loss = 4.682, lr = 0.220, since beginning = 11 mins, \n","batch no = 924 / 1327, train loss = 4.558, lr = 0.220, since beginning = 11 mins, \n","batch no = 1056 / 1327, train loss = 4.644, lr = 0.220, since beginning = 11 mins, \n","batch no = 1188 / 1327, train loss = 4.356, lr = 0.220, since beginning = 11 mins, \n","batch no = 1320 / 1327, train loss = 4.847, lr = 0.220, since beginning = 11 mins, \n","Epoch : 38 || Validation set perplexity : 109.232\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.030, lr = 0.220, since beginning = 11 mins, \n","batch no = 132 / 1327, train loss = 4.506, lr = 0.220, since beginning = 11 mins, \n","batch no = 264 / 1327, train loss = 4.779, lr = 0.220, since beginning = 11 mins, \n","batch no = 396 / 1327, train loss = 4.878, lr = 0.220, since beginning = 11 mins, \n","batch no = 528 / 1327, train loss = 4.762, lr = 0.220, since beginning = 11 mins, \n","batch no = 660 / 1327, train loss = 4.562, lr = 0.220, since beginning = 11 mins, \n","batch no = 792 / 1327, train loss = 4.637, lr = 0.220, since beginning = 11 mins, \n","batch no = 924 / 1327, train loss = 4.539, lr = 0.220, since beginning = 11 mins, \n","batch no = 1056 / 1327, train loss = 4.715, lr = 0.220, since beginning = 11 mins, \n","batch no = 1188 / 1327, train loss = 4.433, lr = 0.220, since beginning = 11 mins, \n","batch no = 1320 / 1327, train loss = 4.770, lr = 0.220, since beginning = 11 mins, \n","Epoch : 39 || Validation set perplexity : 108.533\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.009, lr = 0.220, since beginning = 11 mins, \n","batch no = 132 / 1327, train loss = 4.549, lr = 0.220, since beginning = 11 mins, \n","batch no = 264 / 1327, train loss = 4.734, lr = 0.220, since beginning = 11 mins, \n","batch no = 396 / 1327, train loss = 4.865, lr = 0.220, since beginning = 11 mins, \n","batch no = 528 / 1327, train loss = 4.767, lr = 0.220, since beginning = 11 mins, \n","batch no = 660 / 1327, train loss = 4.550, lr = 0.220, since beginning = 11 mins, \n","batch no = 792 / 1327, train loss = 4.614, lr = 0.220, since beginning = 11 mins, \n","batch no = 924 / 1327, train loss = 4.418, lr = 0.220, since beginning = 11 mins, \n","batch no = 1056 / 1327, train loss = 4.590, lr = 0.220, since beginning = 11 mins, \n","batch no = 1188 / 1327, train loss = 4.364, lr = 0.220, since beginning = 11 mins, \n","batch no = 1320 / 1327, train loss = 4.793, lr = 0.220, since beginning = 11 mins, \n","Epoch : 40 || Validation set perplexity : 108.186\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.077, lr = 0.220, since beginning = 11 mins, \n","batch no = 132 / 1327, train loss = 4.444, lr = 0.220, since beginning = 11 mins, \n","batch no = 264 / 1327, train loss = 4.748, lr = 0.220, since beginning = 11 mins, \n","batch no = 396 / 1327, train loss = 4.813, lr = 0.220, since beginning = 11 mins, \n","batch no = 528 / 1327, train loss = 4.777, lr = 0.220, since beginning = 11 mins, \n","batch no = 660 / 1327, train loss = 4.499, lr = 0.220, since beginning = 12 mins, \n","batch no = 792 / 1327, train loss = 4.642, lr = 0.220, since beginning = 12 mins, \n","batch no = 924 / 1327, train loss = 4.466, lr = 0.220, since beginning = 12 mins, \n","batch no = 1056 / 1327, train loss = 4.641, lr = 0.220, since beginning = 12 mins, \n","batch no = 1188 / 1327, train loss = 4.420, lr = 0.220, since beginning = 12 mins, \n","batch no = 1320 / 1327, train loss = 4.794, lr = 0.220, since beginning = 12 mins, \n","Epoch : 41 || Validation set perplexity : 107.626\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.053, lr = 0.220, since beginning = 12 mins, \n","batch no = 132 / 1327, train loss = 4.471, lr = 0.220, since beginning = 12 mins, \n","batch no = 264 / 1327, train loss = 4.713, lr = 0.220, since beginning = 12 mins, \n","batch no = 396 / 1327, train loss = 4.838, lr = 0.220, since beginning = 12 mins, \n","batch no = 528 / 1327, train loss = 4.722, lr = 0.220, since beginning = 12 mins, \n","batch no = 660 / 1327, train loss = 4.496, lr = 0.220, since beginning = 12 mins, \n","batch no = 792 / 1327, train loss = 4.649, lr = 0.220, since beginning = 12 mins, \n","batch no = 924 / 1327, train loss = 4.468, lr = 0.220, since beginning = 12 mins, \n","batch no = 1056 / 1327, train loss = 4.629, lr = 0.220, since beginning = 12 mins, \n","batch no = 1188 / 1327, train loss = 4.360, lr = 0.220, since beginning = 12 mins, \n","batch no = 1320 / 1327, train loss = 4.773, lr = 0.220, since beginning = 12 mins, \n","Epoch : 42 || Validation set perplexity : 107.682\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.987, lr = 0.220, since beginning = 12 mins, \n","batch no = 132 / 1327, train loss = 4.482, lr = 0.220, since beginning = 12 mins, \n","batch no = 264 / 1327, train loss = 4.731, lr = 0.220, since beginning = 12 mins, \n","batch no = 396 / 1327, train loss = 4.822, lr = 0.220, since beginning = 12 mins, \n","batch no = 528 / 1327, train loss = 4.795, lr = 0.220, since beginning = 12 mins, \n","batch no = 660 / 1327, train loss = 4.507, lr = 0.220, since beginning = 12 mins, \n","batch no = 792 / 1327, train loss = 4.716, lr = 0.220, since beginning = 12 mins, \n","batch no = 924 / 1327, train loss = 4.456, lr = 0.220, since beginning = 12 mins, \n","batch no = 1056 / 1327, train loss = 4.593, lr = 0.220, since beginning = 12 mins, \n","batch no = 1188 / 1327, train loss = 4.356, lr = 0.220, since beginning = 12 mins, \n","batch no = 1320 / 1327, train loss = 4.775, lr = 0.220, since beginning = 12 mins, \n","Epoch : 43 || Validation set perplexity : 107.033\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.997, lr = 0.220, since beginning = 12 mins, \n","batch no = 132 / 1327, train loss = 4.451, lr = 0.220, since beginning = 12 mins, \n","batch no = 264 / 1327, train loss = 4.767, lr = 0.220, since beginning = 12 mins, \n","batch no = 396 / 1327, train loss = 4.794, lr = 0.220, since beginning = 12 mins, \n","batch no = 528 / 1327, train loss = 4.755, lr = 0.220, since beginning = 12 mins, \n","batch no = 660 / 1327, train loss = 4.539, lr = 0.220, since beginning = 12 mins, \n","batch no = 792 / 1327, train loss = 4.642, lr = 0.220, since beginning = 12 mins, \n","batch no = 924 / 1327, train loss = 4.502, lr = 0.220, since beginning = 12 mins, \n","batch no = 1056 / 1327, train loss = 4.598, lr = 0.220, since beginning = 12 mins, \n","batch no = 1188 / 1327, train loss = 4.343, lr = 0.220, since beginning = 12 mins, \n","batch no = 1320 / 1327, train loss = 4.775, lr = 0.220, since beginning = 12 mins, \n","Epoch : 44 || Validation set perplexity : 106.884\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.043, lr = 0.220, since beginning = 13 mins, \n","batch no = 132 / 1327, train loss = 4.452, lr = 0.220, since beginning = 13 mins, \n","batch no = 264 / 1327, train loss = 4.722, lr = 0.220, since beginning = 13 mins, \n","batch no = 396 / 1327, train loss = 4.826, lr = 0.220, since beginning = 13 mins, \n","batch no = 528 / 1327, train loss = 4.760, lr = 0.220, since beginning = 13 mins, \n","batch no = 660 / 1327, train loss = 4.520, lr = 0.220, since beginning = 13 mins, \n","batch no = 792 / 1327, train loss = 4.667, lr = 0.220, since beginning = 13 mins, \n","batch no = 924 / 1327, train loss = 4.414, lr = 0.220, since beginning = 13 mins, \n","batch no = 1056 / 1327, train loss = 4.629, lr = 0.220, since beginning = 13 mins, \n","batch no = 1188 / 1327, train loss = 4.340, lr = 0.220, since beginning = 13 mins, \n","batch no = 1320 / 1327, train loss = 4.743, lr = 0.220, since beginning = 13 mins, \n","Epoch : 45 || Validation set perplexity : 106.699\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.023, lr = 0.220, since beginning = 13 mins, \n","batch no = 132 / 1327, train loss = 4.432, lr = 0.220, since beginning = 13 mins, \n","batch no = 264 / 1327, train loss = 4.749, lr = 0.220, since beginning = 13 mins, \n","batch no = 396 / 1327, train loss = 4.786, lr = 0.220, since beginning = 13 mins, \n","batch no = 528 / 1327, train loss = 4.777, lr = 0.220, since beginning = 13 mins, \n","batch no = 660 / 1327, train loss = 4.490, lr = 0.220, since beginning = 13 mins, \n","batch no = 792 / 1327, train loss = 4.588, lr = 0.220, since beginning = 13 mins, \n","batch no = 924 / 1327, train loss = 4.468, lr = 0.220, since beginning = 13 mins, \n","batch no = 1056 / 1327, train loss = 4.553, lr = 0.220, since beginning = 13 mins, \n","batch no = 1188 / 1327, train loss = 4.321, lr = 0.220, since beginning = 13 mins, \n","batch no = 1320 / 1327, train loss = 4.736, lr = 0.220, since beginning = 13 mins, \n","Epoch : 46 || Validation set perplexity : 106.050\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.973, lr = 0.220, since beginning = 13 mins, \n","batch no = 132 / 1327, train loss = 4.457, lr = 0.220, since beginning = 13 mins, \n","batch no = 264 / 1327, train loss = 4.736, lr = 0.220, since beginning = 13 mins, \n","batch no = 396 / 1327, train loss = 4.772, lr = 0.220, since beginning = 13 mins, \n","batch no = 528 / 1327, train loss = 4.716, lr = 0.220, since beginning = 13 mins, \n","batch no = 660 / 1327, train loss = 4.502, lr = 0.220, since beginning = 13 mins, \n","batch no = 792 / 1327, train loss = 4.588, lr = 0.220, since beginning = 13 mins, \n","batch no = 924 / 1327, train loss = 4.445, lr = 0.220, since beginning = 13 mins, \n","batch no = 1056 / 1327, train loss = 4.573, lr = 0.220, since beginning = 13 mins, \n","batch no = 1188 / 1327, train loss = 4.365, lr = 0.220, since beginning = 13 mins, \n","batch no = 1320 / 1327, train loss = 4.740, lr = 0.220, since beginning = 13 mins, \n","Epoch : 47 || Validation set perplexity : 106.026\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.967, lr = 0.220, since beginning = 13 mins, \n","batch no = 132 / 1327, train loss = 4.395, lr = 0.220, since beginning = 13 mins, \n","batch no = 264 / 1327, train loss = 4.670, lr = 0.220, since beginning = 13 mins, \n","batch no = 396 / 1327, train loss = 4.783, lr = 0.220, since beginning = 13 mins, \n","batch no = 528 / 1327, train loss = 4.749, lr = 0.220, since beginning = 13 mins, \n","batch no = 660 / 1327, train loss = 4.456, lr = 0.220, since beginning = 14 mins, \n","batch no = 792 / 1327, train loss = 4.606, lr = 0.220, since beginning = 14 mins, \n","batch no = 924 / 1327, train loss = 4.444, lr = 0.220, since beginning = 14 mins, \n","batch no = 1056 / 1327, train loss = 4.578, lr = 0.220, since beginning = 14 mins, \n","batch no = 1188 / 1327, train loss = 4.325, lr = 0.220, since beginning = 14 mins, \n","batch no = 1320 / 1327, train loss = 4.736, lr = 0.220, since beginning = 14 mins, \n","Epoch : 48 || Validation set perplexity : 105.722\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.027, lr = 0.220, since beginning = 14 mins, \n","batch no = 132 / 1327, train loss = 4.427, lr = 0.220, since beginning = 14 mins, \n","batch no = 264 / 1327, train loss = 4.717, lr = 0.220, since beginning = 14 mins, \n","batch no = 396 / 1327, train loss = 4.725, lr = 0.220, since beginning = 14 mins, \n","batch no = 528 / 1327, train loss = 4.721, lr = 0.220, since beginning = 14 mins, \n","batch no = 660 / 1327, train loss = 4.477, lr = 0.220, since beginning = 14 mins, \n","batch no = 792 / 1327, train loss = 4.632, lr = 0.220, since beginning = 14 mins, \n","batch no = 924 / 1327, train loss = 4.428, lr = 0.220, since beginning = 14 mins, \n","batch no = 1056 / 1327, train loss = 4.540, lr = 0.220, since beginning = 14 mins, \n","batch no = 1188 / 1327, train loss = 4.296, lr = 0.220, since beginning = 14 mins, \n","batch no = 1320 / 1327, train loss = 4.698, lr = 0.220, since beginning = 14 mins, \n","Epoch : 49 || Validation set perplexity : 105.575\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.930, lr = 0.220, since beginning = 14 mins, \n","batch no = 132 / 1327, train loss = 4.431, lr = 0.220, since beginning = 14 mins, \n","batch no = 264 / 1327, train loss = 4.817, lr = 0.220, since beginning = 14 mins, \n","batch no = 396 / 1327, train loss = 4.788, lr = 0.220, since beginning = 14 mins, \n","batch no = 528 / 1327, train loss = 4.738, lr = 0.220, since beginning = 14 mins, \n","batch no = 660 / 1327, train loss = 4.452, lr = 0.220, since beginning = 14 mins, \n","batch no = 792 / 1327, train loss = 4.631, lr = 0.220, since beginning = 14 mins, \n","batch no = 924 / 1327, train loss = 4.506, lr = 0.220, since beginning = 14 mins, \n","batch no = 1056 / 1327, train loss = 4.553, lr = 0.220, since beginning = 14 mins, \n","batch no = 1188 / 1327, train loss = 4.277, lr = 0.220, since beginning = 14 mins, \n","batch no = 1320 / 1327, train loss = 4.740, lr = 0.220, since beginning = 14 mins, \n","Epoch : 50 || Validation set perplexity : 105.385\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.997, lr = 0.220, since beginning = 14 mins, \n","batch no = 132 / 1327, train loss = 4.381, lr = 0.220, since beginning = 14 mins, \n","batch no = 264 / 1327, train loss = 4.725, lr = 0.220, since beginning = 14 mins, \n","batch no = 396 / 1327, train loss = 4.759, lr = 0.220, since beginning = 14 mins, \n","batch no = 528 / 1327, train loss = 4.698, lr = 0.220, since beginning = 14 mins, \n","batch no = 660 / 1327, train loss = 4.444, lr = 0.220, since beginning = 14 mins, \n","batch no = 792 / 1327, train loss = 4.577, lr = 0.220, since beginning = 14 mins, \n","batch no = 924 / 1327, train loss = 4.437, lr = 0.220, since beginning = 14 mins, \n","batch no = 1056 / 1327, train loss = 4.565, lr = 0.220, since beginning = 14 mins, \n","batch no = 1188 / 1327, train loss = 4.321, lr = 0.220, since beginning = 14 mins, \n","batch no = 1320 / 1327, train loss = 4.732, lr = 0.220, since beginning = 14 mins, \n","Epoch : 51 || Validation set perplexity : 105.366\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.972, lr = 0.220, since beginning = 15 mins, \n","batch no = 132 / 1327, train loss = 4.436, lr = 0.220, since beginning = 15 mins, \n","batch no = 264 / 1327, train loss = 4.731, lr = 0.220, since beginning = 15 mins, \n","batch no = 396 / 1327, train loss = 4.818, lr = 0.220, since beginning = 15 mins, \n","batch no = 528 / 1327, train loss = 4.757, lr = 0.220, since beginning = 15 mins, \n","batch no = 660 / 1327, train loss = 4.458, lr = 0.220, since beginning = 15 mins, \n","batch no = 792 / 1327, train loss = 4.550, lr = 0.220, since beginning = 15 mins, \n","batch no = 924 / 1327, train loss = 4.438, lr = 0.220, since beginning = 15 mins, \n","batch no = 1056 / 1327, train loss = 4.512, lr = 0.220, since beginning = 15 mins, \n","batch no = 1188 / 1327, train loss = 4.264, lr = 0.220, since beginning = 15 mins, \n","batch no = 1320 / 1327, train loss = 4.760, lr = 0.220, since beginning = 15 mins, \n","Epoch : 52 || Validation set perplexity : 104.860\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.977, lr = 0.220, since beginning = 15 mins, \n","batch no = 132 / 1327, train loss = 4.360, lr = 0.220, since beginning = 15 mins, \n","batch no = 264 / 1327, train loss = 4.667, lr = 0.220, since beginning = 15 mins, \n","batch no = 396 / 1327, train loss = 4.790, lr = 0.220, since beginning = 15 mins, \n","batch no = 528 / 1327, train loss = 4.708, lr = 0.220, since beginning = 15 mins, \n","batch no = 660 / 1327, train loss = 4.488, lr = 0.220, since beginning = 15 mins, \n","batch no = 792 / 1327, train loss = 4.653, lr = 0.220, since beginning = 15 mins, \n","batch no = 924 / 1327, train loss = 4.427, lr = 0.220, since beginning = 15 mins, \n","batch no = 1056 / 1327, train loss = 4.577, lr = 0.220, since beginning = 15 mins, \n","batch no = 1188 / 1327, train loss = 4.226, lr = 0.220, since beginning = 15 mins, \n","batch no = 1320 / 1327, train loss = 4.725, lr = 0.220, since beginning = 15 mins, \n","Epoch : 53 || Validation set perplexity : 104.652\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.922, lr = 0.220, since beginning = 15 mins, \n","batch no = 132 / 1327, train loss = 4.377, lr = 0.220, since beginning = 15 mins, \n","batch no = 264 / 1327, train loss = 4.703, lr = 0.220, since beginning = 15 mins, \n","batch no = 396 / 1327, train loss = 4.782, lr = 0.220, since beginning = 15 mins, \n","batch no = 528 / 1327, train loss = 4.726, lr = 0.220, since beginning = 15 mins, \n","batch no = 660 / 1327, train loss = 4.496, lr = 0.220, since beginning = 15 mins, \n","batch no = 792 / 1327, train loss = 4.541, lr = 0.220, since beginning = 15 mins, \n","batch no = 924 / 1327, train loss = 4.447, lr = 0.220, since beginning = 15 mins, \n","batch no = 1056 / 1327, train loss = 4.573, lr = 0.220, since beginning = 15 mins, \n","batch no = 1188 / 1327, train loss = 4.305, lr = 0.220, since beginning = 15 mins, \n","batch no = 1320 / 1327, train loss = 4.732, lr = 0.220, since beginning = 15 mins, \n","Epoch : 54 || Validation set perplexity : 104.416\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.953, lr = 0.220, since beginning = 15 mins, \n","batch no = 132 / 1327, train loss = 4.423, lr = 0.220, since beginning = 15 mins, \n","batch no = 264 / 1327, train loss = 4.749, lr = 0.220, since beginning = 15 mins, \n","batch no = 396 / 1327, train loss = 4.749, lr = 0.220, since beginning = 15 mins, \n","batch no = 528 / 1327, train loss = 4.687, lr = 0.220, since beginning = 15 mins, \n","batch no = 660 / 1327, train loss = 4.383, lr = 0.220, since beginning = 15 mins, \n","batch no = 792 / 1327, train loss = 4.584, lr = 0.220, since beginning = 16 mins, \n","batch no = 924 / 1327, train loss = 4.382, lr = 0.220, since beginning = 16 mins, \n","batch no = 1056 / 1327, train loss = 4.522, lr = 0.220, since beginning = 16 mins, \n","batch no = 1188 / 1327, train loss = 4.312, lr = 0.220, since beginning = 16 mins, \n","batch no = 1320 / 1327, train loss = 4.729, lr = 0.220, since beginning = 16 mins, \n","Epoch : 55 || Validation set perplexity : 104.047\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.905, lr = 0.220, since beginning = 16 mins, \n","batch no = 132 / 1327, train loss = 4.445, lr = 0.220, since beginning = 16 mins, \n","batch no = 264 / 1327, train loss = 4.691, lr = 0.220, since beginning = 16 mins, \n","batch no = 396 / 1327, train loss = 4.721, lr = 0.220, since beginning = 16 mins, \n","batch no = 528 / 1327, train loss = 4.616, lr = 0.220, since beginning = 16 mins, \n","batch no = 660 / 1327, train loss = 4.434, lr = 0.220, since beginning = 16 mins, \n","batch no = 792 / 1327, train loss = 4.572, lr = 0.220, since beginning = 16 mins, \n","batch no = 924 / 1327, train loss = 4.450, lr = 0.220, since beginning = 16 mins, \n","batch no = 1056 / 1327, train loss = 4.561, lr = 0.220, since beginning = 16 mins, \n","batch no = 1188 / 1327, train loss = 4.282, lr = 0.220, since beginning = 16 mins, \n","batch no = 1320 / 1327, train loss = 4.726, lr = 0.220, since beginning = 16 mins, \n","Epoch : 56 || Validation set perplexity : 103.862\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.009, lr = 0.220, since beginning = 16 mins, \n","batch no = 132 / 1327, train loss = 4.470, lr = 0.220, since beginning = 16 mins, \n","batch no = 264 / 1327, train loss = 4.705, lr = 0.220, since beginning = 16 mins, \n","batch no = 396 / 1327, train loss = 4.736, lr = 0.220, since beginning = 16 mins, \n","batch no = 528 / 1327, train loss = 4.768, lr = 0.220, since beginning = 16 mins, \n","batch no = 660 / 1327, train loss = 4.461, lr = 0.220, since beginning = 16 mins, \n","batch no = 792 / 1327, train loss = 4.558, lr = 0.220, since beginning = 16 mins, \n","batch no = 924 / 1327, train loss = 4.467, lr = 0.220, since beginning = 16 mins, \n","batch no = 1056 / 1327, train loss = 4.527, lr = 0.220, since beginning = 16 mins, \n","batch no = 1188 / 1327, train loss = 4.271, lr = 0.220, since beginning = 16 mins, \n","batch no = 1320 / 1327, train loss = 4.694, lr = 0.220, since beginning = 16 mins, \n","Epoch : 57 || Validation set perplexity : 103.851\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.930, lr = 0.220, since beginning = 16 mins, \n","batch no = 132 / 1327, train loss = 4.417, lr = 0.220, since beginning = 16 mins, \n","batch no = 264 / 1327, train loss = 4.736, lr = 0.220, since beginning = 16 mins, \n","batch no = 396 / 1327, train loss = 4.703, lr = 0.220, since beginning = 16 mins, \n","batch no = 528 / 1327, train loss = 4.681, lr = 0.220, since beginning = 16 mins, \n","batch no = 660 / 1327, train loss = 4.424, lr = 0.220, since beginning = 16 mins, \n","batch no = 792 / 1327, train loss = 4.576, lr = 0.220, since beginning = 16 mins, \n","batch no = 924 / 1327, train loss = 4.376, lr = 0.220, since beginning = 16 mins, \n","batch no = 1056 / 1327, train loss = 4.561, lr = 0.220, since beginning = 16 mins, \n","batch no = 1188 / 1327, train loss = 4.247, lr = 0.220, since beginning = 16 mins, \n","batch no = 1320 / 1327, train loss = 4.736, lr = 0.220, since beginning = 16 mins, \n","Epoch : 58 || Validation set perplexity : 103.653\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.900, lr = 0.220, since beginning = 17 mins, \n","batch no = 132 / 1327, train loss = 4.418, lr = 0.220, since beginning = 17 mins, \n","batch no = 264 / 1327, train loss = 4.645, lr = 0.220, since beginning = 17 mins, \n","batch no = 396 / 1327, train loss = 4.725, lr = 0.220, since beginning = 17 mins, \n","batch no = 528 / 1327, train loss = 4.654, lr = 0.220, since beginning = 17 mins, \n","batch no = 660 / 1327, train loss = 4.412, lr = 0.220, since beginning = 17 mins, \n","batch no = 792 / 1327, train loss = 4.574, lr = 0.220, since beginning = 17 mins, \n","batch no = 924 / 1327, train loss = 4.420, lr = 0.220, since beginning = 17 mins, \n","batch no = 1056 / 1327, train loss = 4.508, lr = 0.220, since beginning = 17 mins, \n","batch no = 1188 / 1327, train loss = 4.305, lr = 0.220, since beginning = 17 mins, \n","batch no = 1320 / 1327, train loss = 4.713, lr = 0.220, since beginning = 17 mins, \n","Epoch : 59 || Validation set perplexity : 103.297\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.920, lr = 0.220, since beginning = 17 mins, \n","batch no = 132 / 1327, train loss = 4.354, lr = 0.220, since beginning = 17 mins, \n","batch no = 264 / 1327, train loss = 4.698, lr = 0.220, since beginning = 17 mins, \n","batch no = 396 / 1327, train loss = 4.761, lr = 0.220, since beginning = 17 mins, \n","batch no = 528 / 1327, train loss = 4.748, lr = 0.220, since beginning = 17 mins, \n","batch no = 660 / 1327, train loss = 4.429, lr = 0.220, since beginning = 17 mins, \n","batch no = 792 / 1327, train loss = 4.565, lr = 0.220, since beginning = 17 mins, \n","batch no = 924 / 1327, train loss = 4.498, lr = 0.220, since beginning = 17 mins, \n","batch no = 1056 / 1327, train loss = 4.458, lr = 0.220, since beginning = 17 mins, \n","batch no = 1188 / 1327, train loss = 4.306, lr = 0.220, since beginning = 17 mins, \n","batch no = 1320 / 1327, train loss = 4.746, lr = 0.220, since beginning = 17 mins, \n","Epoch : 60 || Validation set perplexity : 103.426\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.908, lr = 0.220, since beginning = 17 mins, \n","batch no = 132 / 1327, train loss = 4.393, lr = 0.220, since beginning = 17 mins, \n","batch no = 264 / 1327, train loss = 4.675, lr = 0.220, since beginning = 17 mins, \n","batch no = 396 / 1327, train loss = 4.739, lr = 0.220, since beginning = 17 mins, \n","batch no = 528 / 1327, train loss = 4.678, lr = 0.220, since beginning = 17 mins, \n","batch no = 660 / 1327, train loss = 4.364, lr = 0.220, since beginning = 17 mins, \n","batch no = 792 / 1327, train loss = 4.538, lr = 0.220, since beginning = 17 mins, \n","batch no = 924 / 1327, train loss = 4.423, lr = 0.220, since beginning = 17 mins, \n","batch no = 1056 / 1327, train loss = 4.515, lr = 0.220, since beginning = 17 mins, \n","batch no = 1188 / 1327, train loss = 4.295, lr = 0.220, since beginning = 17 mins, \n","batch no = 1320 / 1327, train loss = 4.746, lr = 0.220, since beginning = 17 mins, \n","Epoch : 61 || Validation set perplexity : 103.095\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.919, lr = 0.183, since beginning = 17 mins, \n","batch no = 132 / 1327, train loss = 4.386, lr = 0.183, since beginning = 17 mins, \n","batch no = 264 / 1327, train loss = 4.679, lr = 0.183, since beginning = 17 mins, \n","batch no = 396 / 1327, train loss = 4.722, lr = 0.183, since beginning = 17 mins, \n","batch no = 528 / 1327, train loss = 4.644, lr = 0.183, since beginning = 17 mins, \n","batch no = 660 / 1327, train loss = 4.424, lr = 0.183, since beginning = 17 mins, \n","batch no = 792 / 1327, train loss = 4.542, lr = 0.183, since beginning = 18 mins, \n","batch no = 924 / 1327, train loss = 4.370, lr = 0.183, since beginning = 18 mins, \n","batch no = 1056 / 1327, train loss = 4.510, lr = 0.183, since beginning = 18 mins, \n","batch no = 1188 / 1327, train loss = 4.218, lr = 0.183, since beginning = 18 mins, \n","batch no = 1320 / 1327, train loss = 4.743, lr = 0.183, since beginning = 18 mins, \n","Epoch : 62 || Validation set perplexity : 102.585\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.853, lr = 0.153, since beginning = 18 mins, \n","batch no = 132 / 1327, train loss = 4.328, lr = 0.153, since beginning = 18 mins, \n","batch no = 264 / 1327, train loss = 4.682, lr = 0.153, since beginning = 18 mins, \n","batch no = 396 / 1327, train loss = 4.712, lr = 0.153, since beginning = 18 mins, \n","batch no = 528 / 1327, train loss = 4.558, lr = 0.153, since beginning = 18 mins, \n","batch no = 660 / 1327, train loss = 4.371, lr = 0.153, since beginning = 18 mins, \n","batch no = 792 / 1327, train loss = 4.590, lr = 0.153, since beginning = 18 mins, \n","batch no = 924 / 1327, train loss = 4.363, lr = 0.153, since beginning = 18 mins, \n","batch no = 1056 / 1327, train loss = 4.441, lr = 0.153, since beginning = 18 mins, \n","batch no = 1188 / 1327, train loss = 4.227, lr = 0.153, since beginning = 18 mins, \n","batch no = 1320 / 1327, train loss = 4.675, lr = 0.153, since beginning = 18 mins, \n","Epoch : 63 || Validation set perplexity : 101.948\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.912, lr = 0.127, since beginning = 18 mins, \n","batch no = 132 / 1327, train loss = 4.410, lr = 0.127, since beginning = 18 mins, \n","batch no = 264 / 1327, train loss = 4.657, lr = 0.127, since beginning = 18 mins, \n","batch no = 396 / 1327, train loss = 4.708, lr = 0.127, since beginning = 18 mins, \n","batch no = 528 / 1327, train loss = 4.572, lr = 0.127, since beginning = 18 mins, \n","batch no = 660 / 1327, train loss = 4.357, lr = 0.127, since beginning = 18 mins, \n","batch no = 792 / 1327, train loss = 4.483, lr = 0.127, since beginning = 18 mins, \n","batch no = 924 / 1327, train loss = 4.397, lr = 0.127, since beginning = 18 mins, \n","batch no = 1056 / 1327, train loss = 4.409, lr = 0.127, since beginning = 18 mins, \n","batch no = 1188 / 1327, train loss = 4.220, lr = 0.127, since beginning = 18 mins, \n","batch no = 1320 / 1327, train loss = 4.636, lr = 0.127, since beginning = 18 mins, \n","Epoch : 64 || Validation set perplexity : 101.456\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.817, lr = 0.106, since beginning = 18 mins, \n","batch no = 132 / 1327, train loss = 4.378, lr = 0.106, since beginning = 18 mins, \n","batch no = 264 / 1327, train loss = 4.682, lr = 0.106, since beginning = 18 mins, \n","batch no = 396 / 1327, train loss = 4.673, lr = 0.106, since beginning = 18 mins, \n","batch no = 528 / 1327, train loss = 4.525, lr = 0.106, since beginning = 18 mins, \n","batch no = 660 / 1327, train loss = 4.298, lr = 0.106, since beginning = 18 mins, \n","batch no = 792 / 1327, train loss = 4.555, lr = 0.106, since beginning = 18 mins, \n","batch no = 924 / 1327, train loss = 4.390, lr = 0.106, since beginning = 18 mins, \n","batch no = 1056 / 1327, train loss = 4.448, lr = 0.106, since beginning = 18 mins, \n","batch no = 1188 / 1327, train loss = 4.210, lr = 0.106, since beginning = 18 mins, \n","batch no = 1320 / 1327, train loss = 4.673, lr = 0.106, since beginning = 18 mins, \n","Epoch : 65 || Validation set perplexity : 101.446\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.853, lr = 0.088, since beginning = 19 mins, \n","batch no = 132 / 1327, train loss = 4.350, lr = 0.088, since beginning = 19 mins, \n","batch no = 264 / 1327, train loss = 4.696, lr = 0.088, since beginning = 19 mins, \n","batch no = 396 / 1327, train loss = 4.684, lr = 0.088, since beginning = 19 mins, \n","batch no = 528 / 1327, train loss = 4.546, lr = 0.088, since beginning = 19 mins, \n","batch no = 660 / 1327, train loss = 4.350, lr = 0.088, since beginning = 19 mins, \n","batch no = 792 / 1327, train loss = 4.514, lr = 0.088, since beginning = 19 mins, \n","batch no = 924 / 1327, train loss = 4.356, lr = 0.088, since beginning = 19 mins, \n","batch no = 1056 / 1327, train loss = 4.434, lr = 0.088, since beginning = 19 mins, \n","batch no = 1188 / 1327, train loss = 4.192, lr = 0.088, since beginning = 19 mins, \n","batch no = 1320 / 1327, train loss = 4.656, lr = 0.088, since beginning = 19 mins, \n","Epoch : 66 || Validation set perplexity : 100.835\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.895, lr = 0.074, since beginning = 19 mins, \n","batch no = 132 / 1327, train loss = 4.365, lr = 0.074, since beginning = 19 mins, \n","batch no = 264 / 1327, train loss = 4.677, lr = 0.074, since beginning = 19 mins, \n","batch no = 396 / 1327, train loss = 4.626, lr = 0.074, since beginning = 19 mins, \n","batch no = 528 / 1327, train loss = 4.580, lr = 0.074, since beginning = 19 mins, \n","batch no = 660 / 1327, train loss = 4.387, lr = 0.074, since beginning = 19 mins, \n","batch no = 792 / 1327, train loss = 4.475, lr = 0.074, since beginning = 19 mins, \n","batch no = 924 / 1327, train loss = 4.363, lr = 0.074, since beginning = 19 mins, \n","batch no = 1056 / 1327, train loss = 4.497, lr = 0.074, since beginning = 19 mins, \n","batch no = 1188 / 1327, train loss = 4.210, lr = 0.074, since beginning = 19 mins, \n","batch no = 1320 / 1327, train loss = 4.631, lr = 0.074, since beginning = 19 mins, \n","Epoch : 67 || Validation set perplexity : 100.492\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.835, lr = 0.061, since beginning = 19 mins, \n","batch no = 132 / 1327, train loss = 4.340, lr = 0.061, since beginning = 19 mins, \n","batch no = 264 / 1327, train loss = 4.654, lr = 0.061, since beginning = 19 mins, \n","batch no = 396 / 1327, train loss = 4.647, lr = 0.061, since beginning = 19 mins, \n","batch no = 528 / 1327, train loss = 4.611, lr = 0.061, since beginning = 19 mins, \n","batch no = 660 / 1327, train loss = 4.328, lr = 0.061, since beginning = 19 mins, \n","batch no = 792 / 1327, train loss = 4.571, lr = 0.061, since beginning = 19 mins, \n","batch no = 924 / 1327, train loss = 4.348, lr = 0.061, since beginning = 19 mins, \n","batch no = 1056 / 1327, train loss = 4.435, lr = 0.061, since beginning = 19 mins, \n","batch no = 1188 / 1327, train loss = 4.181, lr = 0.061, since beginning = 19 mins, \n","batch no = 1320 / 1327, train loss = 4.600, lr = 0.061, since beginning = 19 mins, \n","Epoch : 68 || Validation set perplexity : 100.314\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.821, lr = 0.051, since beginning = 19 mins, \n","batch no = 132 / 1327, train loss = 4.327, lr = 0.051, since beginning = 19 mins, \n","batch no = 264 / 1327, train loss = 4.645, lr = 0.051, since beginning = 19 mins, \n","batch no = 396 / 1327, train loss = 4.639, lr = 0.051, since beginning = 19 mins, \n","batch no = 528 / 1327, train loss = 4.582, lr = 0.051, since beginning = 19 mins, \n","batch no = 660 / 1327, train loss = 4.281, lr = 0.051, since beginning = 19 mins, \n","batch no = 792 / 1327, train loss = 4.518, lr = 0.051, since beginning = 19 mins, \n","batch no = 924 / 1327, train loss = 4.352, lr = 0.051, since beginning = 20 mins, \n","batch no = 1056 / 1327, train loss = 4.472, lr = 0.051, since beginning = 20 mins, \n","batch no = 1188 / 1327, train loss = 4.119, lr = 0.051, since beginning = 20 mins, \n","batch no = 1320 / 1327, train loss = 4.627, lr = 0.051, since beginning = 20 mins, \n","Epoch : 69 || Validation set perplexity : 100.063\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.821, lr = 0.043, since beginning = 20 mins, \n","batch no = 132 / 1327, train loss = 4.320, lr = 0.043, since beginning = 20 mins, \n","batch no = 264 / 1327, train loss = 4.550, lr = 0.043, since beginning = 20 mins, \n","batch no = 396 / 1327, train loss = 4.627, lr = 0.043, since beginning = 20 mins, \n","batch no = 528 / 1327, train loss = 4.586, lr = 0.043, since beginning = 20 mins, \n","batch no = 660 / 1327, train loss = 4.325, lr = 0.043, since beginning = 20 mins, \n","batch no = 792 / 1327, train loss = 4.538, lr = 0.043, since beginning = 20 mins, \n","batch no = 924 / 1327, train loss = 4.332, lr = 0.043, since beginning = 20 mins, \n","batch no = 1056 / 1327, train loss = 4.452, lr = 0.043, since beginning = 20 mins, \n","batch no = 1188 / 1327, train loss = 4.152, lr = 0.043, since beginning = 20 mins, \n","batch no = 1320 / 1327, train loss = 4.555, lr = 0.043, since beginning = 20 mins, \n","Epoch : 70 || Validation set perplexity : 99.727\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.798, lr = 0.036, since beginning = 20 mins, \n","batch no = 132 / 1327, train loss = 4.277, lr = 0.036, since beginning = 20 mins, \n","batch no = 264 / 1327, train loss = 4.641, lr = 0.036, since beginning = 20 mins, \n","batch no = 396 / 1327, train loss = 4.634, lr = 0.036, since beginning = 20 mins, \n","batch no = 528 / 1327, train loss = 4.568, lr = 0.036, since beginning = 20 mins, \n","batch no = 660 / 1327, train loss = 4.318, lr = 0.036, since beginning = 20 mins, \n","batch no = 792 / 1327, train loss = 4.476, lr = 0.036, since beginning = 20 mins, \n","batch no = 924 / 1327, train loss = 4.345, lr = 0.036, since beginning = 20 mins, \n","batch no = 1056 / 1327, train loss = 4.375, lr = 0.036, since beginning = 20 mins, \n","batch no = 1188 / 1327, train loss = 4.129, lr = 0.036, since beginning = 20 mins, \n","batch no = 1320 / 1327, train loss = 4.601, lr = 0.036, since beginning = 20 mins, \n","Epoch : 71 || Validation set perplexity : 99.752\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.835, lr = 0.030, since beginning = 20 mins, \n","batch no = 132 / 1327, train loss = 4.332, lr = 0.030, since beginning = 20 mins, \n","batch no = 264 / 1327, train loss = 4.588, lr = 0.030, since beginning = 20 mins, \n","batch no = 396 / 1327, train loss = 4.632, lr = 0.030, since beginning = 20 mins, \n","batch no = 528 / 1327, train loss = 4.554, lr = 0.030, since beginning = 20 mins, \n","batch no = 660 / 1327, train loss = 4.349, lr = 0.030, since beginning = 20 mins, \n","batch no = 792 / 1327, train loss = 4.441, lr = 0.030, since beginning = 20 mins, \n","batch no = 924 / 1327, train loss = 4.334, lr = 0.030, since beginning = 20 mins, \n","batch no = 1056 / 1327, train loss = 4.408, lr = 0.030, since beginning = 20 mins, \n","batch no = 1188 / 1327, train loss = 4.200, lr = 0.030, since beginning = 20 mins, \n","batch no = 1320 / 1327, train loss = 4.667, lr = 0.030, since beginning = 20 mins, \n","Epoch : 72 || Validation set perplexity : 99.599\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.774, lr = 0.025, since beginning = 21 mins, \n","batch no = 132 / 1327, train loss = 4.301, lr = 0.025, since beginning = 21 mins, \n","batch no = 264 / 1327, train loss = 4.629, lr = 0.025, since beginning = 21 mins, \n","batch no = 396 / 1327, train loss = 4.690, lr = 0.025, since beginning = 21 mins, \n","batch no = 528 / 1327, train loss = 4.530, lr = 0.025, since beginning = 21 mins, \n","batch no = 660 / 1327, train loss = 4.335, lr = 0.025, since beginning = 21 mins, \n","batch no = 792 / 1327, train loss = 4.449, lr = 0.025, since beginning = 21 mins, \n","batch no = 924 / 1327, train loss = 4.341, lr = 0.025, since beginning = 21 mins, \n","batch no = 1056 / 1327, train loss = 4.391, lr = 0.025, since beginning = 21 mins, \n","batch no = 1188 / 1327, train loss = 4.130, lr = 0.025, since beginning = 21 mins, \n","batch no = 1320 / 1327, train loss = 4.607, lr = 0.025, since beginning = 21 mins, \n","Epoch : 73 || Validation set perplexity : 99.564\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.771, lr = 0.021, since beginning = 21 mins, \n","batch no = 132 / 1327, train loss = 4.316, lr = 0.021, since beginning = 21 mins, \n","batch no = 264 / 1327, train loss = 4.601, lr = 0.021, since beginning = 21 mins, \n","batch no = 396 / 1327, train loss = 4.684, lr = 0.021, since beginning = 21 mins, \n","batch no = 528 / 1327, train loss = 4.556, lr = 0.021, since beginning = 21 mins, \n","batch no = 660 / 1327, train loss = 4.366, lr = 0.021, since beginning = 21 mins, \n","batch no = 792 / 1327, train loss = 4.481, lr = 0.021, since beginning = 21 mins, \n","batch no = 924 / 1327, train loss = 4.293, lr = 0.021, since beginning = 21 mins, \n","batch no = 1056 / 1327, train loss = 4.405, lr = 0.021, since beginning = 21 mins, \n","batch no = 1188 / 1327, train loss = 4.108, lr = 0.021, since beginning = 21 mins, \n","batch no = 1320 / 1327, train loss = 4.610, lr = 0.021, since beginning = 21 mins, \n","Epoch : 74 || Validation set perplexity : 99.440\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.790, lr = 0.017, since beginning = 21 mins, \n","batch no = 132 / 1327, train loss = 4.250, lr = 0.017, since beginning = 21 mins, \n","batch no = 264 / 1327, train loss = 4.587, lr = 0.017, since beginning = 21 mins, \n","batch no = 396 / 1327, train loss = 4.682, lr = 0.017, since beginning = 21 mins, \n","batch no = 528 / 1327, train loss = 4.612, lr = 0.017, since beginning = 21 mins, \n","batch no = 660 / 1327, train loss = 4.249, lr = 0.017, since beginning = 21 mins, \n","batch no = 792 / 1327, train loss = 4.463, lr = 0.017, since beginning = 21 mins, \n","batch no = 924 / 1327, train loss = 4.378, lr = 0.017, since beginning = 21 mins, \n","batch no = 1056 / 1327, train loss = 4.411, lr = 0.017, since beginning = 21 mins, \n","batch no = 1188 / 1327, train loss = 4.138, lr = 0.017, since beginning = 21 mins, \n","batch no = 1320 / 1327, train loss = 4.604, lr = 0.017, since beginning = 21 mins, \n","Epoch : 75 || Validation set perplexity : 99.398\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.765, lr = 0.014, since beginning = 21 mins, \n","batch no = 132 / 1327, train loss = 4.355, lr = 0.014, since beginning = 21 mins, \n","batch no = 264 / 1327, train loss = 4.622, lr = 0.014, since beginning = 21 mins, \n","batch no = 396 / 1327, train loss = 4.648, lr = 0.014, since beginning = 21 mins, \n","batch no = 528 / 1327, train loss = 4.563, lr = 0.014, since beginning = 21 mins, \n","batch no = 660 / 1327, train loss = 4.306, lr = 0.014, since beginning = 21 mins, \n","batch no = 792 / 1327, train loss = 4.426, lr = 0.014, since beginning = 21 mins, \n","batch no = 924 / 1327, train loss = 4.329, lr = 0.014, since beginning = 22 mins, \n","batch no = 1056 / 1327, train loss = 4.401, lr = 0.014, since beginning = 22 mins, \n","batch no = 1188 / 1327, train loss = 4.148, lr = 0.014, since beginning = 22 mins, \n","batch no = 1320 / 1327, train loss = 4.597, lr = 0.014, since beginning = 22 mins, \n","Epoch : 76 || Validation set perplexity : 99.295\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.813, lr = 0.012, since beginning = 22 mins, \n","batch no = 132 / 1327, train loss = 4.321, lr = 0.012, since beginning = 22 mins, \n","batch no = 264 / 1327, train loss = 4.589, lr = 0.012, since beginning = 22 mins, \n","batch no = 396 / 1327, train loss = 4.656, lr = 0.012, since beginning = 22 mins, \n","batch no = 528 / 1327, train loss = 4.594, lr = 0.012, since beginning = 22 mins, \n","batch no = 660 / 1327, train loss = 4.293, lr = 0.012, since beginning = 22 mins, \n","batch no = 792 / 1327, train loss = 4.467, lr = 0.012, since beginning = 22 mins, \n","batch no = 924 / 1327, train loss = 4.324, lr = 0.012, since beginning = 22 mins, \n","batch no = 1056 / 1327, train loss = 4.461, lr = 0.012, since beginning = 22 mins, \n","batch no = 1188 / 1327, train loss = 4.203, lr = 0.012, since beginning = 22 mins, \n","batch no = 1320 / 1327, train loss = 4.584, lr = 0.012, since beginning = 22 mins, \n","Epoch : 77 || Validation set perplexity : 99.218\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.837, lr = 0.010, since beginning = 22 mins, \n","batch no = 132 / 1327, train loss = 4.309, lr = 0.010, since beginning = 22 mins, \n","batch no = 264 / 1327, train loss = 4.614, lr = 0.010, since beginning = 22 mins, \n","batch no = 396 / 1327, train loss = 4.660, lr = 0.010, since beginning = 22 mins, \n","batch no = 528 / 1327, train loss = 4.518, lr = 0.010, since beginning = 22 mins, \n","batch no = 660 / 1327, train loss = 4.311, lr = 0.010, since beginning = 22 mins, \n","batch no = 792 / 1327, train loss = 4.446, lr = 0.010, since beginning = 22 mins, \n","batch no = 924 / 1327, train loss = 4.344, lr = 0.010, since beginning = 22 mins, \n","batch no = 1056 / 1327, train loss = 4.415, lr = 0.010, since beginning = 22 mins, \n","batch no = 1188 / 1327, train loss = 4.073, lr = 0.010, since beginning = 22 mins, \n","batch no = 1320 / 1327, train loss = 4.644, lr = 0.010, since beginning = 22 mins, \n","Epoch : 78 || Validation set perplexity : 99.161\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.843, lr = 0.008, since beginning = 22 mins, \n","batch no = 132 / 1327, train loss = 4.321, lr = 0.008, since beginning = 22 mins, \n","batch no = 264 / 1327, train loss = 4.573, lr = 0.008, since beginning = 22 mins, \n","batch no = 396 / 1327, train loss = 4.663, lr = 0.008, since beginning = 22 mins, \n","batch no = 528 / 1327, train loss = 4.582, lr = 0.008, since beginning = 22 mins, \n","batch no = 660 / 1327, train loss = 4.321, lr = 0.008, since beginning = 22 mins, \n","batch no = 792 / 1327, train loss = 4.441, lr = 0.008, since beginning = 22 mins, \n","batch no = 924 / 1327, train loss = 4.327, lr = 0.008, since beginning = 22 mins, \n","batch no = 1056 / 1327, train loss = 4.406, lr = 0.008, since beginning = 22 mins, \n","batch no = 1188 / 1327, train loss = 4.151, lr = 0.008, since beginning = 22 mins, \n","batch no = 1320 / 1327, train loss = 4.644, lr = 0.008, since beginning = 22 mins, \n","Epoch : 79 || Validation set perplexity : 99.147\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.797, lr = 0.007, since beginning = 23 mins, \n","batch no = 132 / 1327, train loss = 4.344, lr = 0.007, since beginning = 23 mins, \n","batch no = 264 / 1327, train loss = 4.602, lr = 0.007, since beginning = 23 mins, \n","batch no = 396 / 1327, train loss = 4.685, lr = 0.007, since beginning = 23 mins, \n","batch no = 528 / 1327, train loss = 4.554, lr = 0.007, since beginning = 23 mins, \n","batch no = 660 / 1327, train loss = 4.340, lr = 0.007, since beginning = 23 mins, \n","batch no = 792 / 1327, train loss = 4.496, lr = 0.007, since beginning = 23 mins, \n","batch no = 924 / 1327, train loss = 4.333, lr = 0.007, since beginning = 23 mins, \n","batch no = 1056 / 1327, train loss = 4.436, lr = 0.007, since beginning = 23 mins, \n","batch no = 1188 / 1327, train loss = 4.112, lr = 0.007, since beginning = 23 mins, \n","batch no = 1320 / 1327, train loss = 4.627, lr = 0.007, since beginning = 23 mins, \n","Epoch : 80 || Validation set perplexity : 99.108\n","*************************************************\n","\n","validation preplexity : 99.108\n","Training is over.\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["LSTM_Drop = test_model(dropout=0.5, rnn_type='LSTM',total_epochs=80, learning_rate=0.22,winit=0.05,seq_length=35,factor_epoch=60,factor=1.2,max_grad_norm=5, title=\"with dropout LSTM\")"]},{"cell_type":"markdown","source":["# **GRU:**"],"metadata":{"id":"xUaV-M9YaZt_"}},{"cell_type":"markdown","source":["GRU without dropout"],"metadata":{"id":"IfGx99XTaaDB"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ErDGCwxvOMQs","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"096f4b08-e72d-4709-c914-7448875ed8e4","executionInfo":{"status":"ok","timestamp":1684225562308,"user_tz":-180,"elapsed":341785,"user":{"displayName":"nadav marciano","userId":"12525209232604832576"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Starting training.\n","\n","batch no = 0 / 1327, train loss = 9.209, lr = 0.380, since beginning = 0 mins, \n","batch no = 132 / 1327, train loss = 6.953, lr = 0.380, since beginning = 0 mins, \n","batch no = 264 / 1327, train loss = 6.664, lr = 0.380, since beginning = 0 mins, \n","batch no = 396 / 1327, train loss = 6.337, lr = 0.380, since beginning = 0 mins, \n","batch no = 528 / 1327, train loss = 6.281, lr = 0.380, since beginning = 0 mins, \n","batch no = 660 / 1327, train loss = 5.939, lr = 0.380, since beginning = 0 mins, \n","batch no = 792 / 1327, train loss = 5.823, lr = 0.380, since beginning = 0 mins, \n","batch no = 924 / 1327, train loss = 5.459, lr = 0.380, since beginning = 0 mins, \n","batch no = 1056 / 1327, train loss = 5.865, lr = 0.380, since beginning = 0 mins, \n","batch no = 1188 / 1327, train loss = 5.332, lr = 0.380, since beginning = 0 mins, \n","batch no = 1320 / 1327, train loss = 5.713, lr = 0.380, since beginning = 0 mins, \n","Epoch : 1 || Validation set perplexity : 271.258\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.853, lr = 0.380, since beginning = 0 mins, \n","batch no = 132 / 1327, train loss = 5.422, lr = 0.380, since beginning = 0 mins, \n","batch no = 264 / 1327, train loss = 5.530, lr = 0.380, since beginning = 0 mins, \n","batch no = 396 / 1327, train loss = 5.430, lr = 0.380, since beginning = 0 mins, \n","batch no = 528 / 1327, train loss = 5.518, lr = 0.380, since beginning = 0 mins, \n","batch no = 660 / 1327, train loss = 5.154, lr = 0.380, since beginning = 0 mins, \n","batch no = 792 / 1327, train loss = 5.248, lr = 0.380, since beginning = 0 mins, \n","batch no = 924 / 1327, train loss = 5.002, lr = 0.380, since beginning = 0 mins, \n","batch no = 1056 / 1327, train loss = 5.246, lr = 0.380, since beginning = 0 mins, \n","batch no = 1188 / 1327, train loss = 4.893, lr = 0.380, since beginning = 0 mins, \n","batch no = 1320 / 1327, train loss = 5.291, lr = 0.380, since beginning = 1 mins, \n","Epoch : 2 || Validation set perplexity : 191.597\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.501, lr = 0.380, since beginning = 1 mins, \n","batch no = 132 / 1327, train loss = 4.996, lr = 0.380, since beginning = 1 mins, \n","batch no = 264 / 1327, train loss = 5.187, lr = 0.380, since beginning = 1 mins, \n","batch no = 396 / 1327, train loss = 5.121, lr = 0.380, since beginning = 1 mins, \n","batch no = 528 / 1327, train loss = 5.248, lr = 0.380, since beginning = 1 mins, \n","batch no = 660 / 1327, train loss = 4.815, lr = 0.380, since beginning = 1 mins, \n","batch no = 792 / 1327, train loss = 4.990, lr = 0.380, since beginning = 1 mins, \n","batch no = 924 / 1327, train loss = 4.781, lr = 0.380, since beginning = 1 mins, \n","batch no = 1056 / 1327, train loss = 4.945, lr = 0.380, since beginning = 1 mins, \n","batch no = 1188 / 1327, train loss = 4.619, lr = 0.380, since beginning = 1 mins, \n","batch no = 1320 / 1327, train loss = 5.058, lr = 0.380, since beginning = 1 mins, \n","Epoch : 3 || Validation set perplexity : 165.544\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.286, lr = 0.380, since beginning = 1 mins, \n","batch no = 132 / 1327, train loss = 4.729, lr = 0.380, since beginning = 1 mins, \n","batch no = 264 / 1327, train loss = 4.971, lr = 0.380, since beginning = 1 mins, \n","batch no = 396 / 1327, train loss = 4.949, lr = 0.380, since beginning = 1 mins, \n","batch no = 528 / 1327, train loss = 5.042, lr = 0.380, since beginning = 1 mins, \n","batch no = 660 / 1327, train loss = 4.627, lr = 0.380, since beginning = 1 mins, \n","batch no = 792 / 1327, train loss = 4.766, lr = 0.380, since beginning = 1 mins, \n","batch no = 924 / 1327, train loss = 4.630, lr = 0.380, since beginning = 1 mins, \n","batch no = 1056 / 1327, train loss = 4.727, lr = 0.380, since beginning = 1 mins, \n","batch no = 1188 / 1327, train loss = 4.438, lr = 0.380, since beginning = 1 mins, \n","batch no = 1320 / 1327, train loss = 4.910, lr = 0.380, since beginning = 1 mins, \n","Epoch : 4 || Validation set perplexity : 153.702\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 5.111, lr = 0.380, since beginning = 1 mins, \n","batch no = 132 / 1327, train loss = 4.506, lr = 0.380, since beginning = 1 mins, \n","batch no = 264 / 1327, train loss = 4.815, lr = 0.380, since beginning = 1 mins, \n","batch no = 396 / 1327, train loss = 4.800, lr = 0.380, since beginning = 1 mins, \n","batch no = 528 / 1327, train loss = 4.882, lr = 0.380, since beginning = 1 mins, \n","batch no = 660 / 1327, train loss = 4.486, lr = 0.380, since beginning = 1 mins, \n","batch no = 792 / 1327, train loss = 4.610, lr = 0.380, since beginning = 1 mins, \n","batch no = 924 / 1327, train loss = 4.525, lr = 0.380, since beginning = 1 mins, \n","batch no = 1056 / 1327, train loss = 4.551, lr = 0.380, since beginning = 1 mins, \n","batch no = 1188 / 1327, train loss = 4.280, lr = 0.380, since beginning = 1 mins, \n","batch no = 1320 / 1327, train loss = 4.809, lr = 0.380, since beginning = 1 mins, \n","Epoch : 5 || Validation set perplexity : 149.138\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.965, lr = 0.380, since beginning = 1 mins, \n","batch no = 132 / 1327, train loss = 4.325, lr = 0.380, since beginning = 1 mins, \n","batch no = 264 / 1327, train loss = 4.682, lr = 0.380, since beginning = 1 mins, \n","batch no = 396 / 1327, train loss = 4.699, lr = 0.380, since beginning = 1 mins, \n","batch no = 528 / 1327, train loss = 4.749, lr = 0.380, since beginning = 1 mins, \n","batch no = 660 / 1327, train loss = 4.362, lr = 0.380, since beginning = 2 mins, \n","batch no = 792 / 1327, train loss = 4.476, lr = 0.380, since beginning = 2 mins, \n","batch no = 924 / 1327, train loss = 4.412, lr = 0.380, since beginning = 2 mins, \n","batch no = 1056 / 1327, train loss = 4.398, lr = 0.380, since beginning = 2 mins, \n","batch no = 1188 / 1327, train loss = 4.161, lr = 0.380, since beginning = 2 mins, \n","batch no = 1320 / 1327, train loss = 4.693, lr = 0.380, since beginning = 2 mins, \n","Epoch : 6 || Validation set perplexity : 147.313\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.831, lr = 0.190, since beginning = 2 mins, \n","batch no = 132 / 1327, train loss = 4.145, lr = 0.190, since beginning = 2 mins, \n","batch no = 264 / 1327, train loss = 4.508, lr = 0.190, since beginning = 2 mins, \n","batch no = 396 / 1327, train loss = 4.519, lr = 0.190, since beginning = 2 mins, \n","batch no = 528 / 1327, train loss = 4.527, lr = 0.190, since beginning = 2 mins, \n","batch no = 660 / 1327, train loss = 4.164, lr = 0.190, since beginning = 2 mins, \n","batch no = 792 / 1327, train loss = 4.246, lr = 0.190, since beginning = 2 mins, \n","batch no = 924 / 1327, train loss = 4.146, lr = 0.190, since beginning = 2 mins, \n","batch no = 1056 / 1327, train loss = 4.130, lr = 0.190, since beginning = 2 mins, \n","batch no = 1188 / 1327, train loss = 3.921, lr = 0.190, since beginning = 2 mins, \n","batch no = 1320 / 1327, train loss = 4.423, lr = 0.190, since beginning = 2 mins, \n","Epoch : 7 || Validation set perplexity : 135.111\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.714, lr = 0.095, since beginning = 2 mins, \n","batch no = 132 / 1327, train loss = 4.033, lr = 0.095, since beginning = 2 mins, \n","batch no = 264 / 1327, train loss = 4.389, lr = 0.095, since beginning = 2 mins, \n","batch no = 396 / 1327, train loss = 4.412, lr = 0.095, since beginning = 2 mins, \n","batch no = 528 / 1327, train loss = 4.411, lr = 0.095, since beginning = 2 mins, \n","batch no = 660 / 1327, train loss = 4.058, lr = 0.095, since beginning = 2 mins, \n","batch no = 792 / 1327, train loss = 4.141, lr = 0.095, since beginning = 2 mins, \n","batch no = 924 / 1327, train loss = 4.036, lr = 0.095, since beginning = 2 mins, \n","batch no = 1056 / 1327, train loss = 3.997, lr = 0.095, since beginning = 2 mins, \n","batch no = 1188 / 1327, train loss = 3.797, lr = 0.095, since beginning = 2 mins, \n","batch no = 1320 / 1327, train loss = 4.291, lr = 0.095, since beginning = 2 mins, \n","Epoch : 8 || Validation set perplexity : 130.009\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.647, lr = 0.048, since beginning = 2 mins, \n","batch no = 132 / 1327, train loss = 3.979, lr = 0.048, since beginning = 2 mins, \n","batch no = 264 / 1327, train loss = 4.332, lr = 0.048, since beginning = 2 mins, \n","batch no = 396 / 1327, train loss = 4.369, lr = 0.048, since beginning = 2 mins, \n","batch no = 528 / 1327, train loss = 4.355, lr = 0.048, since beginning = 2 mins, \n","batch no = 660 / 1327, train loss = 4.000, lr = 0.048, since beginning = 2 mins, \n","batch no = 792 / 1327, train loss = 4.086, lr = 0.048, since beginning = 2 mins, \n","batch no = 924 / 1327, train loss = 3.984, lr = 0.048, since beginning = 2 mins, \n","batch no = 1056 / 1327, train loss = 3.933, lr = 0.048, since beginning = 2 mins, \n","batch no = 1188 / 1327, train loss = 3.722, lr = 0.048, since beginning = 2 mins, \n","batch no = 1320 / 1327, train loss = 4.221, lr = 0.048, since beginning = 2 mins, \n","Epoch : 9 || Validation set perplexity : 127.777\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.613, lr = 0.024, since beginning = 3 mins, \n","batch no = 132 / 1327, train loss = 3.958, lr = 0.024, since beginning = 3 mins, \n","batch no = 264 / 1327, train loss = 4.306, lr = 0.024, since beginning = 3 mins, \n","batch no = 396 / 1327, train loss = 4.342, lr = 0.024, since beginning = 3 mins, \n","batch no = 528 / 1327, train loss = 4.324, lr = 0.024, since beginning = 3 mins, \n","batch no = 660 / 1327, train loss = 3.966, lr = 0.024, since beginning = 3 mins, \n","batch no = 792 / 1327, train loss = 4.049, lr = 0.024, since beginning = 3 mins, \n","batch no = 924 / 1327, train loss = 3.959, lr = 0.024, since beginning = 3 mins, \n","batch no = 1056 / 1327, train loss = 3.896, lr = 0.024, since beginning = 3 mins, \n","batch no = 1188 / 1327, train loss = 3.678, lr = 0.024, since beginning = 3 mins, \n","batch no = 1320 / 1327, train loss = 4.185, lr = 0.024, since beginning = 3 mins, \n","Epoch : 10 || Validation set perplexity : 126.486\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.597, lr = 0.012, since beginning = 3 mins, \n","batch no = 132 / 1327, train loss = 3.940, lr = 0.012, since beginning = 3 mins, \n","batch no = 264 / 1327, train loss = 4.290, lr = 0.012, since beginning = 3 mins, \n","batch no = 396 / 1327, train loss = 4.330, lr = 0.012, since beginning = 3 mins, \n","batch no = 528 / 1327, train loss = 4.306, lr = 0.012, since beginning = 3 mins, \n","batch no = 660 / 1327, train loss = 3.947, lr = 0.012, since beginning = 3 mins, \n","batch no = 792 / 1327, train loss = 4.026, lr = 0.012, since beginning = 3 mins, \n","batch no = 924 / 1327, train loss = 3.946, lr = 0.012, since beginning = 3 mins, \n","batch no = 1056 / 1327, train loss = 3.873, lr = 0.012, since beginning = 3 mins, \n","batch no = 1188 / 1327, train loss = 3.654, lr = 0.012, since beginning = 3 mins, \n","batch no = 1320 / 1327, train loss = 4.166, lr = 0.012, since beginning = 3 mins, \n","Epoch : 11 || Validation set perplexity : 125.704\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.590, lr = 0.006, since beginning = 3 mins, \n","batch no = 132 / 1327, train loss = 3.926, lr = 0.006, since beginning = 3 mins, \n","batch no = 264 / 1327, train loss = 4.279, lr = 0.006, since beginning = 3 mins, \n","batch no = 396 / 1327, train loss = 4.325, lr = 0.006, since beginning = 3 mins, \n","batch no = 528 / 1327, train loss = 4.294, lr = 0.006, since beginning = 3 mins, \n","batch no = 660 / 1327, train loss = 3.936, lr = 0.006, since beginning = 3 mins, \n","batch no = 792 / 1327, train loss = 4.013, lr = 0.006, since beginning = 3 mins, \n","batch no = 924 / 1327, train loss = 3.939, lr = 0.006, since beginning = 3 mins, \n","batch no = 1056 / 1327, train loss = 3.860, lr = 0.006, since beginning = 3 mins, \n","batch no = 1188 / 1327, train loss = 3.641, lr = 0.006, since beginning = 3 mins, \n","batch no = 1320 / 1327, train loss = 4.154, lr = 0.006, since beginning = 3 mins, \n","Epoch : 12 || Validation set perplexity : 125.271\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.586, lr = 0.003, since beginning = 3 mins, \n","batch no = 132 / 1327, train loss = 3.919, lr = 0.003, since beginning = 3 mins, \n","batch no = 264 / 1327, train loss = 4.274, lr = 0.003, since beginning = 3 mins, \n","batch no = 396 / 1327, train loss = 4.322, lr = 0.003, since beginning = 3 mins, \n","batch no = 528 / 1327, train loss = 4.287, lr = 0.003, since beginning = 3 mins, \n","batch no = 660 / 1327, train loss = 3.929, lr = 0.003, since beginning = 3 mins, \n","batch no = 792 / 1327, train loss = 4.006, lr = 0.003, since beginning = 3 mins, \n","batch no = 924 / 1327, train loss = 3.935, lr = 0.003, since beginning = 4 mins, \n","batch no = 1056 / 1327, train loss = 3.854, lr = 0.003, since beginning = 4 mins, \n","batch no = 1188 / 1327, train loss = 3.632, lr = 0.003, since beginning = 4 mins, \n","batch no = 1320 / 1327, train loss = 4.147, lr = 0.003, since beginning = 4 mins, \n","Epoch : 13 || Validation set perplexity : 125.067\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.584, lr = 0.001, since beginning = 4 mins, \n","batch no = 132 / 1327, train loss = 3.915, lr = 0.001, since beginning = 4 mins, \n","batch no = 264 / 1327, train loss = 4.272, lr = 0.001, since beginning = 4 mins, \n","batch no = 396 / 1327, train loss = 4.320, lr = 0.001, since beginning = 4 mins, \n","batch no = 528 / 1327, train loss = 4.284, lr = 0.001, since beginning = 4 mins, \n","batch no = 660 / 1327, train loss = 3.925, lr = 0.001, since beginning = 4 mins, \n","batch no = 792 / 1327, train loss = 4.003, lr = 0.001, since beginning = 4 mins, \n","batch no = 924 / 1327, train loss = 3.931, lr = 0.001, since beginning = 4 mins, \n","batch no = 1056 / 1327, train loss = 3.850, lr = 0.001, since beginning = 4 mins, \n","batch no = 1188 / 1327, train loss = 3.627, lr = 0.001, since beginning = 4 mins, \n","batch no = 1320 / 1327, train loss = 4.145, lr = 0.001, since beginning = 4 mins, \n","Epoch : 14 || Validation set perplexity : 124.976\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.581, lr = 0.001, since beginning = 4 mins, \n","batch no = 132 / 1327, train loss = 3.912, lr = 0.001, since beginning = 4 mins, \n","batch no = 264 / 1327, train loss = 4.271, lr = 0.001, since beginning = 4 mins, \n","batch no = 396 / 1327, train loss = 4.319, lr = 0.001, since beginning = 4 mins, \n","batch no = 528 / 1327, train loss = 4.283, lr = 0.001, since beginning = 4 mins, \n","batch no = 660 / 1327, train loss = 3.922, lr = 0.001, since beginning = 4 mins, \n","batch no = 792 / 1327, train loss = 4.002, lr = 0.001, since beginning = 4 mins, \n","batch no = 924 / 1327, train loss = 3.930, lr = 0.001, since beginning = 4 mins, \n","batch no = 1056 / 1327, train loss = 3.848, lr = 0.001, since beginning = 4 mins, \n","batch no = 1188 / 1327, train loss = 3.625, lr = 0.001, since beginning = 4 mins, \n","batch no = 1320 / 1327, train loss = 4.144, lr = 0.001, since beginning = 4 mins, \n","Epoch : 15 || Validation set perplexity : 124.947\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.580, lr = 0.000, since beginning = 4 mins, \n","batch no = 132 / 1327, train loss = 3.911, lr = 0.000, since beginning = 4 mins, \n","batch no = 264 / 1327, train loss = 4.270, lr = 0.000, since beginning = 4 mins, \n","batch no = 396 / 1327, train loss = 4.319, lr = 0.000, since beginning = 4 mins, \n","batch no = 528 / 1327, train loss = 4.282, lr = 0.000, since beginning = 4 mins, \n","batch no = 660 / 1327, train loss = 3.922, lr = 0.000, since beginning = 4 mins, \n","batch no = 792 / 1327, train loss = 4.001, lr = 0.000, since beginning = 4 mins, \n","batch no = 924 / 1327, train loss = 3.929, lr = 0.000, since beginning = 4 mins, \n","batch no = 1056 / 1327, train loss = 3.847, lr = 0.000, since beginning = 4 mins, \n","batch no = 1188 / 1327, train loss = 3.624, lr = 0.000, since beginning = 4 mins, \n","batch no = 1320 / 1327, train loss = 4.143, lr = 0.000, since beginning = 4 mins, \n","Epoch : 16 || Validation set perplexity : 124.939\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.580, lr = 0.000, since beginning = 4 mins, \n","batch no = 132 / 1327, train loss = 3.911, lr = 0.000, since beginning = 5 mins, \n","batch no = 264 / 1327, train loss = 4.269, lr = 0.000, since beginning = 5 mins, \n","batch no = 396 / 1327, train loss = 4.318, lr = 0.000, since beginning = 5 mins, \n","batch no = 528 / 1327, train loss = 4.282, lr = 0.000, since beginning = 5 mins, \n","batch no = 660 / 1327, train loss = 3.921, lr = 0.000, since beginning = 5 mins, \n","batch no = 792 / 1327, train loss = 4.001, lr = 0.000, since beginning = 5 mins, \n","batch no = 924 / 1327, train loss = 3.928, lr = 0.000, since beginning = 5 mins, \n","batch no = 1056 / 1327, train loss = 3.847, lr = 0.000, since beginning = 5 mins, \n","batch no = 1188 / 1327, train loss = 3.623, lr = 0.000, since beginning = 5 mins, \n","batch no = 1320 / 1327, train loss = 4.143, lr = 0.000, since beginning = 5 mins, \n","Epoch : 17 || Validation set perplexity : 124.937\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.579, lr = 0.000, since beginning = 5 mins, \n","batch no = 132 / 1327, train loss = 3.910, lr = 0.000, since beginning = 5 mins, \n","batch no = 264 / 1327, train loss = 4.269, lr = 0.000, since beginning = 5 mins, \n","batch no = 396 / 1327, train loss = 4.318, lr = 0.000, since beginning = 5 mins, \n","batch no = 528 / 1327, train loss = 4.281, lr = 0.000, since beginning = 5 mins, \n","batch no = 660 / 1327, train loss = 3.921, lr = 0.000, since beginning = 5 mins, \n","batch no = 792 / 1327, train loss = 4.001, lr = 0.000, since beginning = 5 mins, \n","batch no = 924 / 1327, train loss = 3.928, lr = 0.000, since beginning = 5 mins, \n","batch no = 1056 / 1327, train loss = 3.847, lr = 0.000, since beginning = 5 mins, \n","batch no = 1188 / 1327, train loss = 3.623, lr = 0.000, since beginning = 5 mins, \n","batch no = 1320 / 1327, train loss = 4.142, lr = 0.000, since beginning = 5 mins, \n","Epoch : 18 || Validation set perplexity : 124.936\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.579, lr = 0.000, since beginning = 5 mins, \n","batch no = 132 / 1327, train loss = 3.910, lr = 0.000, since beginning = 5 mins, \n","batch no = 264 / 1327, train loss = 4.269, lr = 0.000, since beginning = 5 mins, \n","batch no = 396 / 1327, train loss = 4.318, lr = 0.000, since beginning = 5 mins, \n","batch no = 528 / 1327, train loss = 4.281, lr = 0.000, since beginning = 5 mins, \n","batch no = 660 / 1327, train loss = 3.921, lr = 0.000, since beginning = 5 mins, \n","batch no = 792 / 1327, train loss = 4.000, lr = 0.000, since beginning = 5 mins, \n","batch no = 924 / 1327, train loss = 3.928, lr = 0.000, since beginning = 5 mins, \n","batch no = 1056 / 1327, train loss = 3.846, lr = 0.000, since beginning = 5 mins, \n","batch no = 1188 / 1327, train loss = 3.623, lr = 0.000, since beginning = 5 mins, \n","batch no = 1320 / 1327, train loss = 4.142, lr = 0.000, since beginning = 5 mins, \n","Epoch : 19 || Validation set perplexity : 124.936\n","*************************************************\n","\n","batch no = 0 / 1327, train loss = 4.579, lr = 0.000, since beginning = 5 mins, \n","batch no = 132 / 1327, train loss = 3.910, lr = 0.000, since beginning = 5 mins, \n","batch no = 264 / 1327, train loss = 4.269, lr = 0.000, since beginning = 5 mins, \n","batch no = 396 / 1327, train loss = 4.318, lr = 0.000, since beginning = 5 mins, \n","batch no = 528 / 1327, train loss = 4.281, lr = 0.000, since beginning = 5 mins, \n","batch no = 660 / 1327, train loss = 3.921, lr = 0.000, since beginning = 5 mins, \n","batch no = 792 / 1327, train loss = 4.000, lr = 0.000, since beginning = 5 mins, \n","batch no = 924 / 1327, train loss = 3.928, lr = 0.000, since beginning = 5 mins, \n","batch no = 1056 / 1327, train loss = 3.846, lr = 0.000, since beginning = 5 mins, \n","batch no = 1188 / 1327, train loss = 3.623, lr = 0.000, since beginning = 6 mins, \n","batch no = 1320 / 1327, train loss = 4.142, lr = 0.000, since beginning = 6 mins, \n","Epoch : 20 || Validation set perplexity : 124.936\n","*************************************************\n","\n","validation preplexity : 124.936\n","Training is over.\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["GRU_NoDrop = test_model(dropout=0,rnn_type='GRU',total_epochs=20, learning_rate=0.38,winit=0.05,seq_length=35,factor_epoch=5,factor=2,max_grad_norm=5,title=\"No dropout GRU\")"]},{"cell_type":"markdown","source":["GRU with dropout"],"metadata":{"id":"jHKkPbe3alja"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"3R1Rf7KgOMa1","outputId":"a1da4e15-010a-4cdb-c85d-ed04dd1094de","executionInfo":{"status":"ok","timestamp":1684252840570,"user_tz":-180,"elapsed":1652696,"user":{"displayName":"nadav marciano","userId":"12525209232604832576"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Starting training.\n","\n","batch no = 0 / 1256, train loss = 9.209, lr = 0.300, since beginning = 0 mins, \n","batch no = 125 / 1256, train loss = 6.882, lr = 0.300, since beginning = 0 mins, \n","batch no = 250 / 1256, train loss = 6.461, lr = 0.300, since beginning = 0 mins, \n","batch no = 375 / 1256, train loss = 6.428, lr = 0.300, since beginning = 0 mins, \n","batch no = 500 / 1256, train loss = 6.348, lr = 0.300, since beginning = 0 mins, \n","batch no = 625 / 1256, train loss = 6.097, lr = 0.300, since beginning = 0 mins, \n","batch no = 750 / 1256, train loss = 6.092, lr = 0.300, since beginning = 0 mins, \n","batch no = 875 / 1256, train loss = 6.115, lr = 0.300, since beginning = 0 mins, \n","batch no = 1000 / 1256, train loss = 5.945, lr = 0.300, since beginning = 0 mins, \n","batch no = 1125 / 1256, train loss = 5.642, lr = 0.300, since beginning = 0 mins, \n","batch no = 1250 / 1256, train loss = 5.919, lr = 0.300, since beginning = 0 mins, \n","Epoch : 1 || Validation set perplexity : 300.843\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 6.069, lr = 0.300, since beginning = 0 mins, \n","batch no = 125 / 1256, train loss = 5.826, lr = 0.300, since beginning = 0 mins, \n","batch no = 250 / 1256, train loss = 5.695, lr = 0.300, since beginning = 0 mins, \n","batch no = 375 / 1256, train loss = 5.746, lr = 0.300, since beginning = 0 mins, \n","batch no = 500 / 1256, train loss = 5.637, lr = 0.300, since beginning = 0 mins, \n","batch no = 625 / 1256, train loss = 5.488, lr = 0.300, since beginning = 0 mins, \n","batch no = 750 / 1256, train loss = 5.593, lr = 0.300, since beginning = 0 mins, \n","batch no = 875 / 1256, train loss = 5.673, lr = 0.300, since beginning = 0 mins, \n","batch no = 1000 / 1256, train loss = 5.470, lr = 0.300, since beginning = 0 mins, \n","batch no = 1125 / 1256, train loss = 5.301, lr = 0.300, since beginning = 0 mins, \n","batch no = 1250 / 1256, train loss = 5.626, lr = 0.300, since beginning = 1 mins, \n","Epoch : 2 || Validation set perplexity : 218.018\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.813, lr = 0.300, since beginning = 1 mins, \n","batch no = 125 / 1256, train loss = 5.480, lr = 0.300, since beginning = 1 mins, \n","batch no = 250 / 1256, train loss = 5.473, lr = 0.300, since beginning = 1 mins, \n","batch no = 375 / 1256, train loss = 5.530, lr = 0.300, since beginning = 1 mins, \n","batch no = 500 / 1256, train loss = 5.423, lr = 0.300, since beginning = 1 mins, \n","batch no = 625 / 1256, train loss = 5.333, lr = 0.300, since beginning = 1 mins, \n","batch no = 750 / 1256, train loss = 5.445, lr = 0.300, since beginning = 1 mins, \n","batch no = 875 / 1256, train loss = 5.507, lr = 0.300, since beginning = 1 mins, \n","batch no = 1000 / 1256, train loss = 5.322, lr = 0.300, since beginning = 1 mins, \n","batch no = 1125 / 1256, train loss = 5.122, lr = 0.300, since beginning = 1 mins, \n","batch no = 1250 / 1256, train loss = 5.476, lr = 0.300, since beginning = 1 mins, \n","Epoch : 3 || Validation set perplexity : 189.559\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.662, lr = 0.300, since beginning = 1 mins, \n","batch no = 125 / 1256, train loss = 5.325, lr = 0.300, since beginning = 1 mins, \n","batch no = 250 / 1256, train loss = 5.335, lr = 0.300, since beginning = 1 mins, \n","batch no = 375 / 1256, train loss = 5.403, lr = 0.300, since beginning = 1 mins, \n","batch no = 500 / 1256, train loss = 5.222, lr = 0.300, since beginning = 1 mins, \n","batch no = 625 / 1256, train loss = 5.154, lr = 0.300, since beginning = 1 mins, \n","batch no = 750 / 1256, train loss = 5.279, lr = 0.300, since beginning = 1 mins, \n","batch no = 875 / 1256, train loss = 5.361, lr = 0.300, since beginning = 1 mins, \n","batch no = 1000 / 1256, train loss = 5.194, lr = 0.300, since beginning = 1 mins, \n","batch no = 1125 / 1256, train loss = 5.036, lr = 0.300, since beginning = 1 mins, \n","batch no = 1250 / 1256, train loss = 5.453, lr = 0.300, since beginning = 1 mins, \n","Epoch : 4 || Validation set perplexity : 174.040\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.628, lr = 0.300, since beginning = 1 mins, \n","batch no = 125 / 1256, train loss = 5.243, lr = 0.300, since beginning = 1 mins, \n","batch no = 250 / 1256, train loss = 5.256, lr = 0.300, since beginning = 1 mins, \n","batch no = 375 / 1256, train loss = 5.324, lr = 0.300, since beginning = 1 mins, \n","batch no = 500 / 1256, train loss = 5.244, lr = 0.300, since beginning = 1 mins, \n","batch no = 625 / 1256, train loss = 5.027, lr = 0.300, since beginning = 1 mins, \n","batch no = 750 / 1256, train loss = 5.247, lr = 0.300, since beginning = 1 mins, \n","batch no = 875 / 1256, train loss = 5.282, lr = 0.300, since beginning = 1 mins, \n","batch no = 1000 / 1256, train loss = 5.113, lr = 0.300, since beginning = 1 mins, \n","batch no = 1125 / 1256, train loss = 4.940, lr = 0.300, since beginning = 1 mins, \n","batch no = 1250 / 1256, train loss = 5.356, lr = 0.300, since beginning = 1 mins, \n","Epoch : 5 || Validation set perplexity : 161.562\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.497, lr = 0.300, since beginning = 1 mins, \n","batch no = 125 / 1256, train loss = 5.175, lr = 0.300, since beginning = 1 mins, \n","batch no = 250 / 1256, train loss = 5.207, lr = 0.300, since beginning = 1 mins, \n","batch no = 375 / 1256, train loss = 5.259, lr = 0.300, since beginning = 1 mins, \n","batch no = 500 / 1256, train loss = 5.159, lr = 0.300, since beginning = 1 mins, \n","batch no = 625 / 1256, train loss = 4.951, lr = 0.300, since beginning = 2 mins, \n","batch no = 750 / 1256, train loss = 5.173, lr = 0.300, since beginning = 2 mins, \n","batch no = 875 / 1256, train loss = 5.208, lr = 0.300, since beginning = 2 mins, \n","batch no = 1000 / 1256, train loss = 5.113, lr = 0.300, since beginning = 2 mins, \n","batch no = 1125 / 1256, train loss = 4.871, lr = 0.300, since beginning = 2 mins, \n","batch no = 1250 / 1256, train loss = 5.301, lr = 0.300, since beginning = 2 mins, \n","Epoch : 6 || Validation set perplexity : 154.102\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.516, lr = 0.300, since beginning = 2 mins, \n","batch no = 125 / 1256, train loss = 5.080, lr = 0.300, since beginning = 2 mins, \n","batch no = 250 / 1256, train loss = 5.151, lr = 0.300, since beginning = 2 mins, \n","batch no = 375 / 1256, train loss = 5.233, lr = 0.300, since beginning = 2 mins, \n","batch no = 500 / 1256, train loss = 5.138, lr = 0.300, since beginning = 2 mins, \n","batch no = 625 / 1256, train loss = 4.923, lr = 0.300, since beginning = 2 mins, \n","batch no = 750 / 1256, train loss = 5.035, lr = 0.300, since beginning = 2 mins, \n","batch no = 875 / 1256, train loss = 5.192, lr = 0.300, since beginning = 2 mins, \n","batch no = 1000 / 1256, train loss = 5.053, lr = 0.300, since beginning = 2 mins, \n","batch no = 1125 / 1256, train loss = 4.786, lr = 0.300, since beginning = 2 mins, \n","batch no = 1250 / 1256, train loss = 5.271, lr = 0.300, since beginning = 2 mins, \n","Epoch : 7 || Validation set perplexity : 146.959\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.424, lr = 0.300, since beginning = 2 mins, \n","batch no = 125 / 1256, train loss = 5.036, lr = 0.300, since beginning = 2 mins, \n","batch no = 250 / 1256, train loss = 5.107, lr = 0.300, since beginning = 2 mins, \n","batch no = 375 / 1256, train loss = 5.184, lr = 0.300, since beginning = 2 mins, \n","batch no = 500 / 1256, train loss = 5.056, lr = 0.300, since beginning = 2 mins, \n","batch no = 625 / 1256, train loss = 4.909, lr = 0.300, since beginning = 2 mins, \n","batch no = 750 / 1256, train loss = 5.082, lr = 0.300, since beginning = 2 mins, \n","batch no = 875 / 1256, train loss = 5.121, lr = 0.300, since beginning = 2 mins, \n","batch no = 1000 / 1256, train loss = 5.007, lr = 0.300, since beginning = 2 mins, \n","batch no = 1125 / 1256, train loss = 4.802, lr = 0.300, since beginning = 2 mins, \n","batch no = 1250 / 1256, train loss = 5.265, lr = 0.300, since beginning = 2 mins, \n","Epoch : 8 || Validation set perplexity : 143.212\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.432, lr = 0.300, since beginning = 2 mins, \n","batch no = 125 / 1256, train loss = 4.908, lr = 0.300, since beginning = 2 mins, \n","batch no = 250 / 1256, train loss = 5.109, lr = 0.300, since beginning = 2 mins, \n","batch no = 375 / 1256, train loss = 5.189, lr = 0.300, since beginning = 2 mins, \n","batch no = 500 / 1256, train loss = 5.018, lr = 0.300, since beginning = 2 mins, \n","batch no = 625 / 1256, train loss = 4.862, lr = 0.300, since beginning = 2 mins, \n","batch no = 750 / 1256, train loss = 4.940, lr = 0.300, since beginning = 2 mins, \n","batch no = 875 / 1256, train loss = 5.084, lr = 0.300, since beginning = 2 mins, \n","batch no = 1000 / 1256, train loss = 4.939, lr = 0.300, since beginning = 2 mins, \n","batch no = 1125 / 1256, train loss = 4.822, lr = 0.300, since beginning = 2 mins, \n","batch no = 1250 / 1256, train loss = 5.211, lr = 0.300, since beginning = 2 mins, \n","Epoch : 9 || Validation set perplexity : 138.375\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.339, lr = 0.300, since beginning = 3 mins, \n","batch no = 125 / 1256, train loss = 4.888, lr = 0.300, since beginning = 3 mins, \n","batch no = 250 / 1256, train loss = 5.038, lr = 0.300, since beginning = 3 mins, \n","batch no = 375 / 1256, train loss = 5.110, lr = 0.300, since beginning = 3 mins, \n","batch no = 500 / 1256, train loss = 4.963, lr = 0.300, since beginning = 3 mins, \n","batch no = 625 / 1256, train loss = 4.826, lr = 0.300, since beginning = 3 mins, \n","batch no = 750 / 1256, train loss = 4.978, lr = 0.300, since beginning = 3 mins, \n","batch no = 875 / 1256, train loss = 5.006, lr = 0.300, since beginning = 3 mins, \n","batch no = 1000 / 1256, train loss = 4.919, lr = 0.300, since beginning = 3 mins, \n","batch no = 1125 / 1256, train loss = 4.801, lr = 0.300, since beginning = 3 mins, \n","batch no = 1250 / 1256, train loss = 5.193, lr = 0.300, since beginning = 3 mins, \n","Epoch : 10 || Validation set perplexity : 135.391\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.339, lr = 0.300, since beginning = 3 mins, \n","batch no = 125 / 1256, train loss = 4.938, lr = 0.300, since beginning = 3 mins, \n","batch no = 250 / 1256, train loss = 5.047, lr = 0.300, since beginning = 3 mins, \n","batch no = 375 / 1256, train loss = 5.122, lr = 0.300, since beginning = 3 mins, \n","batch no = 500 / 1256, train loss = 4.897, lr = 0.300, since beginning = 3 mins, \n","batch no = 625 / 1256, train loss = 4.797, lr = 0.300, since beginning = 3 mins, \n","batch no = 750 / 1256, train loss = 4.958, lr = 0.300, since beginning = 3 mins, \n","batch no = 875 / 1256, train loss = 5.013, lr = 0.300, since beginning = 3 mins, \n","batch no = 1000 / 1256, train loss = 4.926, lr = 0.300, since beginning = 3 mins, \n","batch no = 1125 / 1256, train loss = 4.719, lr = 0.300, since beginning = 3 mins, \n","batch no = 1250 / 1256, train loss = 5.134, lr = 0.300, since beginning = 3 mins, \n","Epoch : 11 || Validation set perplexity : 132.616\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.323, lr = 0.300, since beginning = 3 mins, \n","batch no = 125 / 1256, train loss = 4.852, lr = 0.300, since beginning = 3 mins, \n","batch no = 250 / 1256, train loss = 5.041, lr = 0.300, since beginning = 3 mins, \n","batch no = 375 / 1256, train loss = 5.055, lr = 0.300, since beginning = 3 mins, \n","batch no = 500 / 1256, train loss = 4.940, lr = 0.300, since beginning = 3 mins, \n","batch no = 625 / 1256, train loss = 4.781, lr = 0.300, since beginning = 3 mins, \n","batch no = 750 / 1256, train loss = 4.975, lr = 0.300, since beginning = 3 mins, \n","batch no = 875 / 1256, train loss = 4.987, lr = 0.300, since beginning = 3 mins, \n","batch no = 1000 / 1256, train loss = 4.871, lr = 0.300, since beginning = 3 mins, \n","batch no = 1125 / 1256, train loss = 4.702, lr = 0.300, since beginning = 3 mins, \n","batch no = 1250 / 1256, train loss = 5.134, lr = 0.300, since beginning = 3 mins, \n","Epoch : 12 || Validation set perplexity : 130.938\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.285, lr = 0.300, since beginning = 3 mins, \n","batch no = 125 / 1256, train loss = 4.782, lr = 0.300, since beginning = 3 mins, \n","batch no = 250 / 1256, train loss = 4.934, lr = 0.300, since beginning = 3 mins, \n","batch no = 375 / 1256, train loss = 5.152, lr = 0.300, since beginning = 3 mins, \n","batch no = 500 / 1256, train loss = 4.901, lr = 0.300, since beginning = 3 mins, \n","batch no = 625 / 1256, train loss = 4.778, lr = 0.300, since beginning = 3 mins, \n","batch no = 750 / 1256, train loss = 4.866, lr = 0.300, since beginning = 3 mins, \n","batch no = 875 / 1256, train loss = 4.985, lr = 0.300, since beginning = 3 mins, \n","batch no = 1000 / 1256, train loss = 4.891, lr = 0.300, since beginning = 4 mins, \n","batch no = 1125 / 1256, train loss = 4.647, lr = 0.300, since beginning = 4 mins, \n","batch no = 1250 / 1256, train loss = 5.042, lr = 0.300, since beginning = 4 mins, \n","Epoch : 13 || Validation set perplexity : 128.562\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.284, lr = 0.300, since beginning = 4 mins, \n","batch no = 125 / 1256, train loss = 4.777, lr = 0.300, since beginning = 4 mins, \n","batch no = 250 / 1256, train loss = 4.967, lr = 0.300, since beginning = 4 mins, \n","batch no = 375 / 1256, train loss = 5.062, lr = 0.300, since beginning = 4 mins, \n","batch no = 500 / 1256, train loss = 4.881, lr = 0.300, since beginning = 4 mins, \n","batch no = 625 / 1256, train loss = 4.705, lr = 0.300, since beginning = 4 mins, \n","batch no = 750 / 1256, train loss = 4.901, lr = 0.300, since beginning = 4 mins, \n","batch no = 875 / 1256, train loss = 4.923, lr = 0.300, since beginning = 4 mins, \n","batch no = 1000 / 1256, train loss = 4.837, lr = 0.300, since beginning = 4 mins, \n","batch no = 1125 / 1256, train loss = 4.634, lr = 0.300, since beginning = 4 mins, \n","batch no = 1250 / 1256, train loss = 5.031, lr = 0.300, since beginning = 4 mins, \n","Epoch : 14 || Validation set perplexity : 127.588\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.223, lr = 0.300, since beginning = 4 mins, \n","batch no = 125 / 1256, train loss = 4.763, lr = 0.300, since beginning = 4 mins, \n","batch no = 250 / 1256, train loss = 4.980, lr = 0.300, since beginning = 4 mins, \n","batch no = 375 / 1256, train loss = 5.096, lr = 0.300, since beginning = 4 mins, \n","batch no = 500 / 1256, train loss = 4.845, lr = 0.300, since beginning = 4 mins, \n","batch no = 625 / 1256, train loss = 4.691, lr = 0.300, since beginning = 4 mins, \n","batch no = 750 / 1256, train loss = 4.905, lr = 0.300, since beginning = 4 mins, \n","batch no = 875 / 1256, train loss = 4.941, lr = 0.300, since beginning = 4 mins, \n","batch no = 1000 / 1256, train loss = 4.852, lr = 0.300, since beginning = 4 mins, \n","batch no = 1125 / 1256, train loss = 4.591, lr = 0.300, since beginning = 4 mins, \n","batch no = 1250 / 1256, train loss = 5.019, lr = 0.300, since beginning = 4 mins, \n","Epoch : 15 || Validation set perplexity : 124.951\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.186, lr = 0.300, since beginning = 4 mins, \n","batch no = 125 / 1256, train loss = 4.738, lr = 0.300, since beginning = 4 mins, \n","batch no = 250 / 1256, train loss = 4.974, lr = 0.300, since beginning = 4 mins, \n","batch no = 375 / 1256, train loss = 5.042, lr = 0.300, since beginning = 4 mins, \n","batch no = 500 / 1256, train loss = 4.805, lr = 0.300, since beginning = 4 mins, \n","batch no = 625 / 1256, train loss = 4.706, lr = 0.300, since beginning = 4 mins, \n","batch no = 750 / 1256, train loss = 4.878, lr = 0.300, since beginning = 4 mins, \n","batch no = 875 / 1256, train loss = 4.944, lr = 0.300, since beginning = 4 mins, \n","batch no = 1000 / 1256, train loss = 4.806, lr = 0.300, since beginning = 4 mins, \n","batch no = 1125 / 1256, train loss = 4.617, lr = 0.300, since beginning = 4 mins, \n","batch no = 1250 / 1256, train loss = 5.005, lr = 0.300, since beginning = 4 mins, \n","Epoch : 16 || Validation set perplexity : 125.117\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.212, lr = 0.300, since beginning = 4 mins, \n","batch no = 125 / 1256, train loss = 4.766, lr = 0.300, since beginning = 4 mins, \n","batch no = 250 / 1256, train loss = 4.921, lr = 0.300, since beginning = 4 mins, \n","batch no = 375 / 1256, train loss = 5.063, lr = 0.300, since beginning = 4 mins, \n","batch no = 500 / 1256, train loss = 4.811, lr = 0.300, since beginning = 5 mins, \n","batch no = 625 / 1256, train loss = 4.686, lr = 0.300, since beginning = 5 mins, \n","batch no = 750 / 1256, train loss = 4.809, lr = 0.300, since beginning = 5 mins, \n","batch no = 875 / 1256, train loss = 4.907, lr = 0.300, since beginning = 5 mins, \n","batch no = 1000 / 1256, train loss = 4.797, lr = 0.300, since beginning = 5 mins, \n","batch no = 1125 / 1256, train loss = 4.536, lr = 0.300, since beginning = 5 mins, \n","batch no = 1250 / 1256, train loss = 4.972, lr = 0.300, since beginning = 5 mins, \n","Epoch : 17 || Validation set perplexity : 123.783\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.202, lr = 0.300, since beginning = 5 mins, \n","batch no = 125 / 1256, train loss = 4.769, lr = 0.300, since beginning = 5 mins, \n","batch no = 250 / 1256, train loss = 4.905, lr = 0.300, since beginning = 5 mins, \n","batch no = 375 / 1256, train loss = 4.996, lr = 0.300, since beginning = 5 mins, \n","batch no = 500 / 1256, train loss = 4.842, lr = 0.300, since beginning = 5 mins, \n","batch no = 625 / 1256, train loss = 4.632, lr = 0.300, since beginning = 5 mins, \n","batch no = 750 / 1256, train loss = 4.820, lr = 0.300, since beginning = 5 mins, \n","batch no = 875 / 1256, train loss = 4.902, lr = 0.300, since beginning = 5 mins, \n","batch no = 1000 / 1256, train loss = 4.841, lr = 0.300, since beginning = 5 mins, \n","batch no = 1125 / 1256, train loss = 4.595, lr = 0.300, since beginning = 5 mins, \n","batch no = 1250 / 1256, train loss = 4.995, lr = 0.300, since beginning = 5 mins, \n","Epoch : 18 || Validation set perplexity : 122.819\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.198, lr = 0.300, since beginning = 5 mins, \n","batch no = 125 / 1256, train loss = 4.703, lr = 0.300, since beginning = 5 mins, \n","batch no = 250 / 1256, train loss = 4.817, lr = 0.300, since beginning = 5 mins, \n","batch no = 375 / 1256, train loss = 4.989, lr = 0.300, since beginning = 5 mins, \n","batch no = 500 / 1256, train loss = 4.829, lr = 0.300, since beginning = 5 mins, \n","batch no = 625 / 1256, train loss = 4.659, lr = 0.300, since beginning = 5 mins, \n","batch no = 750 / 1256, train loss = 4.739, lr = 0.300, since beginning = 5 mins, \n","batch no = 875 / 1256, train loss = 4.819, lr = 0.300, since beginning = 5 mins, \n","batch no = 1000 / 1256, train loss = 4.729, lr = 0.300, since beginning = 5 mins, \n","batch no = 1125 / 1256, train loss = 4.544, lr = 0.300, since beginning = 5 mins, \n","batch no = 1250 / 1256, train loss = 4.970, lr = 0.300, since beginning = 5 mins, \n","Epoch : 19 || Validation set perplexity : 120.392\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.147, lr = 0.300, since beginning = 5 mins, \n","batch no = 125 / 1256, train loss = 4.693, lr = 0.300, since beginning = 5 mins, \n","batch no = 250 / 1256, train loss = 4.869, lr = 0.300, since beginning = 5 mins, \n","batch no = 375 / 1256, train loss = 5.011, lr = 0.300, since beginning = 5 mins, \n","batch no = 500 / 1256, train loss = 4.803, lr = 0.300, since beginning = 5 mins, \n","batch no = 625 / 1256, train loss = 4.606, lr = 0.300, since beginning = 5 mins, \n","batch no = 750 / 1256, train loss = 4.807, lr = 0.300, since beginning = 5 mins, \n","batch no = 875 / 1256, train loss = 4.844, lr = 0.300, since beginning = 5 mins, \n","batch no = 1000 / 1256, train loss = 4.754, lr = 0.300, since beginning = 5 mins, \n","batch no = 1125 / 1256, train loss = 4.541, lr = 0.300, since beginning = 5 mins, \n","batch no = 1250 / 1256, train loss = 5.050, lr = 0.300, since beginning = 5 mins, \n","Epoch : 20 || Validation set perplexity : 120.711\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.134, lr = 0.300, since beginning = 6 mins, \n","batch no = 125 / 1256, train loss = 4.653, lr = 0.300, since beginning = 6 mins, \n","batch no = 250 / 1256, train loss = 4.878, lr = 0.300, since beginning = 6 mins, \n","batch no = 375 / 1256, train loss = 4.965, lr = 0.300, since beginning = 6 mins, \n","batch no = 500 / 1256, train loss = 4.798, lr = 0.300, since beginning = 6 mins, \n","batch no = 625 / 1256, train loss = 4.636, lr = 0.300, since beginning = 6 mins, \n","batch no = 750 / 1256, train loss = 4.867, lr = 0.300, since beginning = 6 mins, \n","batch no = 875 / 1256, train loss = 4.835, lr = 0.300, since beginning = 6 mins, \n","batch no = 1000 / 1256, train loss = 4.730, lr = 0.300, since beginning = 6 mins, \n","batch no = 1125 / 1256, train loss = 4.589, lr = 0.300, since beginning = 6 mins, \n","batch no = 1250 / 1256, train loss = 4.894, lr = 0.300, since beginning = 6 mins, \n","Epoch : 21 || Validation set perplexity : 120.394\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.150, lr = 0.300, since beginning = 6 mins, \n","batch no = 125 / 1256, train loss = 4.693, lr = 0.300, since beginning = 6 mins, \n","batch no = 250 / 1256, train loss = 4.835, lr = 0.300, since beginning = 6 mins, \n","batch no = 375 / 1256, train loss = 5.035, lr = 0.300, since beginning = 6 mins, \n","batch no = 500 / 1256, train loss = 4.782, lr = 0.300, since beginning = 6 mins, \n","batch no = 625 / 1256, train loss = 4.576, lr = 0.300, since beginning = 6 mins, \n","batch no = 750 / 1256, train loss = 4.755, lr = 0.300, since beginning = 6 mins, \n","batch no = 875 / 1256, train loss = 4.798, lr = 0.300, since beginning = 6 mins, \n","batch no = 1000 / 1256, train loss = 4.726, lr = 0.300, since beginning = 6 mins, \n","batch no = 1125 / 1256, train loss = 4.506, lr = 0.300, since beginning = 6 mins, \n","batch no = 1250 / 1256, train loss = 4.901, lr = 0.300, since beginning = 6 mins, \n","Epoch : 22 || Validation set perplexity : 119.598\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.142, lr = 0.300, since beginning = 6 mins, \n","batch no = 125 / 1256, train loss = 4.693, lr = 0.300, since beginning = 6 mins, \n","batch no = 250 / 1256, train loss = 4.863, lr = 0.300, since beginning = 6 mins, \n","batch no = 375 / 1256, train loss = 4.993, lr = 0.300, since beginning = 6 mins, \n","batch no = 500 / 1256, train loss = 4.756, lr = 0.300, since beginning = 6 mins, \n","batch no = 625 / 1256, train loss = 4.618, lr = 0.300, since beginning = 6 mins, \n","batch no = 750 / 1256, train loss = 4.802, lr = 0.300, since beginning = 6 mins, \n","batch no = 875 / 1256, train loss = 4.848, lr = 0.300, since beginning = 6 mins, \n","batch no = 1000 / 1256, train loss = 4.769, lr = 0.300, since beginning = 6 mins, \n","batch no = 1125 / 1256, train loss = 4.546, lr = 0.300, since beginning = 6 mins, \n","batch no = 1250 / 1256, train loss = 4.917, lr = 0.300, since beginning = 6 mins, \n","Epoch : 23 || Validation set perplexity : 120.247\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.120, lr = 0.300, since beginning = 6 mins, \n","batch no = 125 / 1256, train loss = 4.676, lr = 0.300, since beginning = 6 mins, \n","batch no = 250 / 1256, train loss = 4.805, lr = 0.300, since beginning = 6 mins, \n","batch no = 375 / 1256, train loss = 4.946, lr = 0.300, since beginning = 6 mins, \n","batch no = 500 / 1256, train loss = 4.793, lr = 0.300, since beginning = 6 mins, \n","batch no = 625 / 1256, train loss = 4.537, lr = 0.300, since beginning = 6 mins, \n","batch no = 750 / 1256, train loss = 4.704, lr = 0.300, since beginning = 6 mins, \n","batch no = 875 / 1256, train loss = 4.838, lr = 0.300, since beginning = 6 mins, \n","batch no = 1000 / 1256, train loss = 4.763, lr = 0.300, since beginning = 7 mins, \n","batch no = 1125 / 1256, train loss = 4.541, lr = 0.300, since beginning = 7 mins, \n","batch no = 1250 / 1256, train loss = 4.835, lr = 0.300, since beginning = 7 mins, \n","Epoch : 24 || Validation set perplexity : 118.306\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.153, lr = 0.300, since beginning = 7 mins, \n","batch no = 125 / 1256, train loss = 4.630, lr = 0.300, since beginning = 7 mins, \n","batch no = 250 / 1256, train loss = 4.799, lr = 0.300, since beginning = 7 mins, \n","batch no = 375 / 1256, train loss = 5.016, lr = 0.300, since beginning = 7 mins, \n","batch no = 500 / 1256, train loss = 4.755, lr = 0.300, since beginning = 7 mins, \n","batch no = 625 / 1256, train loss = 4.599, lr = 0.300, since beginning = 7 mins, \n","batch no = 750 / 1256, train loss = 4.766, lr = 0.300, since beginning = 7 mins, \n","batch no = 875 / 1256, train loss = 4.808, lr = 0.300, since beginning = 7 mins, \n","batch no = 1000 / 1256, train loss = 4.723, lr = 0.300, since beginning = 7 mins, \n","batch no = 1125 / 1256, train loss = 4.557, lr = 0.300, since beginning = 7 mins, \n","batch no = 1250 / 1256, train loss = 4.885, lr = 0.300, since beginning = 7 mins, \n","Epoch : 25 || Validation set perplexity : 118.341\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.130, lr = 0.300, since beginning = 7 mins, \n","batch no = 125 / 1256, train loss = 4.686, lr = 0.300, since beginning = 7 mins, \n","batch no = 250 / 1256, train loss = 4.766, lr = 0.300, since beginning = 7 mins, \n","batch no = 375 / 1256, train loss = 4.987, lr = 0.300, since beginning = 7 mins, \n","batch no = 500 / 1256, train loss = 4.745, lr = 0.300, since beginning = 7 mins, \n","batch no = 625 / 1256, train loss = 4.609, lr = 0.300, since beginning = 7 mins, \n","batch no = 750 / 1256, train loss = 4.757, lr = 0.300, since beginning = 7 mins, \n","batch no = 875 / 1256, train loss = 4.786, lr = 0.300, since beginning = 7 mins, \n","batch no = 1000 / 1256, train loss = 4.764, lr = 0.300, since beginning = 7 mins, \n","batch no = 1125 / 1256, train loss = 4.533, lr = 0.300, since beginning = 7 mins, \n","batch no = 1250 / 1256, train loss = 4.923, lr = 0.300, since beginning = 7 mins, \n","Epoch : 26 || Validation set perplexity : 118.368\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.103, lr = 0.300, since beginning = 7 mins, \n","batch no = 125 / 1256, train loss = 4.608, lr = 0.300, since beginning = 7 mins, \n","batch no = 250 / 1256, train loss = 4.815, lr = 0.300, since beginning = 7 mins, \n","batch no = 375 / 1256, train loss = 5.017, lr = 0.300, since beginning = 7 mins, \n","batch no = 500 / 1256, train loss = 4.759, lr = 0.300, since beginning = 7 mins, \n","batch no = 625 / 1256, train loss = 4.542, lr = 0.300, since beginning = 7 mins, \n","batch no = 750 / 1256, train loss = 4.733, lr = 0.300, since beginning = 7 mins, \n","batch no = 875 / 1256, train loss = 4.849, lr = 0.300, since beginning = 7 mins, \n","batch no = 1000 / 1256, train loss = 4.665, lr = 0.300, since beginning = 7 mins, \n","batch no = 1125 / 1256, train loss = 4.448, lr = 0.300, since beginning = 7 mins, \n","batch no = 1250 / 1256, train loss = 4.908, lr = 0.300, since beginning = 7 mins, \n","Epoch : 27 || Validation set perplexity : 116.750\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.068, lr = 0.300, since beginning = 7 mins, \n","batch no = 125 / 1256, train loss = 4.570, lr = 0.300, since beginning = 7 mins, \n","batch no = 250 / 1256, train loss = 4.796, lr = 0.300, since beginning = 7 mins, \n","batch no = 375 / 1256, train loss = 4.937, lr = 0.300, since beginning = 7 mins, \n","batch no = 500 / 1256, train loss = 4.731, lr = 0.300, since beginning = 8 mins, \n","batch no = 625 / 1256, train loss = 4.564, lr = 0.300, since beginning = 8 mins, \n","batch no = 750 / 1256, train loss = 4.702, lr = 0.300, since beginning = 8 mins, \n","batch no = 875 / 1256, train loss = 4.871, lr = 0.300, since beginning = 8 mins, \n","batch no = 1000 / 1256, train loss = 4.726, lr = 0.300, since beginning = 8 mins, \n","batch no = 1125 / 1256, train loss = 4.430, lr = 0.300, since beginning = 8 mins, \n","batch no = 1250 / 1256, train loss = 4.900, lr = 0.300, since beginning = 8 mins, \n","Epoch : 28 || Validation set perplexity : 116.821\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.076, lr = 0.300, since beginning = 8 mins, \n","batch no = 125 / 1256, train loss = 4.547, lr = 0.300, since beginning = 8 mins, \n","batch no = 250 / 1256, train loss = 4.817, lr = 0.300, since beginning = 8 mins, \n","batch no = 375 / 1256, train loss = 4.962, lr = 0.300, since beginning = 8 mins, \n","batch no = 500 / 1256, train loss = 4.735, lr = 0.300, since beginning = 8 mins, \n","batch no = 625 / 1256, train loss = 4.509, lr = 0.300, since beginning = 8 mins, \n","batch no = 750 / 1256, train loss = 4.770, lr = 0.300, since beginning = 8 mins, \n","batch no = 875 / 1256, train loss = 4.763, lr = 0.300, since beginning = 8 mins, \n","batch no = 1000 / 1256, train loss = 4.718, lr = 0.300, since beginning = 8 mins, \n","batch no = 1125 / 1256, train loss = 4.505, lr = 0.300, since beginning = 8 mins, \n","batch no = 1250 / 1256, train loss = 4.900, lr = 0.300, since beginning = 8 mins, \n","Epoch : 29 || Validation set perplexity : 116.954\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.118, lr = 0.300, since beginning = 8 mins, \n","batch no = 125 / 1256, train loss = 4.606, lr = 0.300, since beginning = 8 mins, \n","batch no = 250 / 1256, train loss = 4.822, lr = 0.300, since beginning = 8 mins, \n","batch no = 375 / 1256, train loss = 4.929, lr = 0.300, since beginning = 8 mins, \n","batch no = 500 / 1256, train loss = 4.718, lr = 0.300, since beginning = 8 mins, \n","batch no = 625 / 1256, train loss = 4.572, lr = 0.300, since beginning = 8 mins, \n","batch no = 750 / 1256, train loss = 4.751, lr = 0.300, since beginning = 8 mins, \n","batch no = 875 / 1256, train loss = 4.786, lr = 0.300, since beginning = 8 mins, \n","batch no = 1000 / 1256, train loss = 4.674, lr = 0.300, since beginning = 8 mins, \n","batch no = 1125 / 1256, train loss = 4.536, lr = 0.300, since beginning = 8 mins, \n","batch no = 1250 / 1256, train loss = 4.811, lr = 0.300, since beginning = 8 mins, \n","Epoch : 30 || Validation set perplexity : 116.190\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.112, lr = 0.300, since beginning = 8 mins, \n","batch no = 125 / 1256, train loss = 4.595, lr = 0.300, since beginning = 8 mins, \n","batch no = 250 / 1256, train loss = 4.771, lr = 0.300, since beginning = 8 mins, \n","batch no = 375 / 1256, train loss = 4.939, lr = 0.300, since beginning = 8 mins, \n","batch no = 500 / 1256, train loss = 4.653, lr = 0.300, since beginning = 8 mins, \n","batch no = 625 / 1256, train loss = 4.600, lr = 0.300, since beginning = 8 mins, \n","batch no = 750 / 1256, train loss = 4.706, lr = 0.300, since beginning = 8 mins, \n","batch no = 875 / 1256, train loss = 4.730, lr = 0.300, since beginning = 8 mins, \n","batch no = 1000 / 1256, train loss = 4.677, lr = 0.300, since beginning = 8 mins, \n","batch no = 1125 / 1256, train loss = 4.572, lr = 0.300, since beginning = 8 mins, \n","batch no = 1250 / 1256, train loss = 4.855, lr = 0.300, since beginning = 8 mins, \n","Epoch : 31 || Validation set perplexity : 116.180\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.030, lr = 0.300, since beginning = 9 mins, \n","batch no = 125 / 1256, train loss = 4.588, lr = 0.300, since beginning = 9 mins, \n","batch no = 250 / 1256, train loss = 4.809, lr = 0.300, since beginning = 9 mins, \n","batch no = 375 / 1256, train loss = 4.968, lr = 0.300, since beginning = 9 mins, \n","batch no = 500 / 1256, train loss = 4.740, lr = 0.300, since beginning = 9 mins, \n","batch no = 625 / 1256, train loss = 4.558, lr = 0.300, since beginning = 9 mins, \n","batch no = 750 / 1256, train loss = 4.678, lr = 0.300, since beginning = 9 mins, \n","batch no = 875 / 1256, train loss = 4.751, lr = 0.300, since beginning = 9 mins, \n","batch no = 1000 / 1256, train loss = 4.630, lr = 0.300, since beginning = 9 mins, \n","batch no = 1125 / 1256, train loss = 4.460, lr = 0.300, since beginning = 9 mins, \n","batch no = 1250 / 1256, train loss = 4.822, lr = 0.300, since beginning = 9 mins, \n","Epoch : 32 || Validation set perplexity : 115.742\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.010, lr = 0.300, since beginning = 9 mins, \n","batch no = 125 / 1256, train loss = 4.626, lr = 0.300, since beginning = 9 mins, \n","batch no = 250 / 1256, train loss = 4.729, lr = 0.300, since beginning = 9 mins, \n","batch no = 375 / 1256, train loss = 4.872, lr = 0.300, since beginning = 9 mins, \n","batch no = 500 / 1256, train loss = 4.701, lr = 0.300, since beginning = 9 mins, \n","batch no = 625 / 1256, train loss = 4.552, lr = 0.300, since beginning = 9 mins, \n","batch no = 750 / 1256, train loss = 4.742, lr = 0.300, since beginning = 9 mins, \n","batch no = 875 / 1256, train loss = 4.658, lr = 0.300, since beginning = 9 mins, \n","batch no = 1000 / 1256, train loss = 4.671, lr = 0.300, since beginning = 9 mins, \n","batch no = 1125 / 1256, train loss = 4.425, lr = 0.300, since beginning = 9 mins, \n","batch no = 1250 / 1256, train loss = 4.774, lr = 0.300, since beginning = 9 mins, \n","Epoch : 33 || Validation set perplexity : 115.718\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.058, lr = 0.300, since beginning = 9 mins, \n","batch no = 125 / 1256, train loss = 4.535, lr = 0.300, since beginning = 9 mins, \n","batch no = 250 / 1256, train loss = 4.718, lr = 0.300, since beginning = 9 mins, \n","batch no = 375 / 1256, train loss = 4.958, lr = 0.300, since beginning = 9 mins, \n","batch no = 500 / 1256, train loss = 4.697, lr = 0.300, since beginning = 9 mins, \n","batch no = 625 / 1256, train loss = 4.535, lr = 0.300, since beginning = 9 mins, \n","batch no = 750 / 1256, train loss = 4.705, lr = 0.300, since beginning = 9 mins, \n","batch no = 875 / 1256, train loss = 4.772, lr = 0.300, since beginning = 9 mins, \n","batch no = 1000 / 1256, train loss = 4.618, lr = 0.300, since beginning = 9 mins, \n","batch no = 1125 / 1256, train loss = 4.416, lr = 0.300, since beginning = 9 mins, \n","batch no = 1250 / 1256, train loss = 4.819, lr = 0.300, since beginning = 9 mins, \n","Epoch : 34 || Validation set perplexity : 115.258\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.046, lr = 0.300, since beginning = 9 mins, \n","batch no = 125 / 1256, train loss = 4.560, lr = 0.300, since beginning = 9 mins, \n","batch no = 250 / 1256, train loss = 4.738, lr = 0.300, since beginning = 9 mins, \n","batch no = 375 / 1256, train loss = 4.902, lr = 0.300, since beginning = 9 mins, \n","batch no = 500 / 1256, train loss = 4.694, lr = 0.300, since beginning = 9 mins, \n","batch no = 625 / 1256, train loss = 4.541, lr = 0.300, since beginning = 9 mins, \n","batch no = 750 / 1256, train loss = 4.680, lr = 0.300, since beginning = 9 mins, \n","batch no = 875 / 1256, train loss = 4.702, lr = 0.300, since beginning = 9 mins, \n","batch no = 1000 / 1256, train loss = 4.602, lr = 0.300, since beginning = 10 mins, \n","batch no = 1125 / 1256, train loss = 4.458, lr = 0.300, since beginning = 10 mins, \n","batch no = 1250 / 1256, train loss = 4.862, lr = 0.300, since beginning = 10 mins, \n","Epoch : 35 || Validation set perplexity : 115.988\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.027, lr = 0.300, since beginning = 10 mins, \n","batch no = 125 / 1256, train loss = 4.579, lr = 0.300, since beginning = 10 mins, \n","batch no = 250 / 1256, train loss = 4.719, lr = 0.300, since beginning = 10 mins, \n","batch no = 375 / 1256, train loss = 4.886, lr = 0.300, since beginning = 10 mins, \n","batch no = 500 / 1256, train loss = 4.659, lr = 0.300, since beginning = 10 mins, \n","batch no = 625 / 1256, train loss = 4.544, lr = 0.300, since beginning = 10 mins, \n","batch no = 750 / 1256, train loss = 4.666, lr = 0.300, since beginning = 10 mins, \n","batch no = 875 / 1256, train loss = 4.753, lr = 0.300, since beginning = 10 mins, \n","batch no = 1000 / 1256, train loss = 4.618, lr = 0.300, since beginning = 10 mins, \n","batch no = 1125 / 1256, train loss = 4.420, lr = 0.300, since beginning = 10 mins, \n","batch no = 1250 / 1256, train loss = 4.792, lr = 0.300, since beginning = 10 mins, \n","Epoch : 36 || Validation set perplexity : 114.733\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.063, lr = 0.300, since beginning = 10 mins, \n","batch no = 125 / 1256, train loss = 4.598, lr = 0.300, since beginning = 10 mins, \n","batch no = 250 / 1256, train loss = 4.742, lr = 0.300, since beginning = 10 mins, \n","batch no = 375 / 1256, train loss = 4.880, lr = 0.300, since beginning = 10 mins, \n","batch no = 500 / 1256, train loss = 4.699, lr = 0.300, since beginning = 10 mins, \n","batch no = 625 / 1256, train loss = 4.579, lr = 0.300, since beginning = 10 mins, \n","batch no = 750 / 1256, train loss = 4.669, lr = 0.300, since beginning = 10 mins, \n","batch no = 875 / 1256, train loss = 4.656, lr = 0.300, since beginning = 10 mins, \n","batch no = 1000 / 1256, train loss = 4.702, lr = 0.300, since beginning = 10 mins, \n","batch no = 1125 / 1256, train loss = 4.474, lr = 0.300, since beginning = 10 mins, \n","batch no = 1250 / 1256, train loss = 4.777, lr = 0.300, since beginning = 10 mins, \n","Epoch : 37 || Validation set perplexity : 114.830\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.989, lr = 0.300, since beginning = 10 mins, \n","batch no = 125 / 1256, train loss = 4.562, lr = 0.300, since beginning = 10 mins, \n","batch no = 250 / 1256, train loss = 4.768, lr = 0.300, since beginning = 10 mins, \n","batch no = 375 / 1256, train loss = 4.823, lr = 0.300, since beginning = 10 mins, \n","batch no = 500 / 1256, train loss = 4.692, lr = 0.300, since beginning = 10 mins, \n","batch no = 625 / 1256, train loss = 4.486, lr = 0.300, since beginning = 10 mins, \n","batch no = 750 / 1256, train loss = 4.650, lr = 0.300, since beginning = 10 mins, \n","batch no = 875 / 1256, train loss = 4.641, lr = 0.300, since beginning = 10 mins, \n","batch no = 1000 / 1256, train loss = 4.684, lr = 0.300, since beginning = 10 mins, \n","batch no = 1125 / 1256, train loss = 4.410, lr = 0.300, since beginning = 10 mins, \n","batch no = 1250 / 1256, train loss = 4.719, lr = 0.300, since beginning = 10 mins, \n","Epoch : 38 || Validation set perplexity : 114.332\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.028, lr = 0.300, since beginning = 10 mins, \n","batch no = 125 / 1256, train loss = 4.531, lr = 0.300, since beginning = 10 mins, \n","batch no = 250 / 1256, train loss = 4.722, lr = 0.300, since beginning = 10 mins, \n","batch no = 375 / 1256, train loss = 4.866, lr = 0.300, since beginning = 10 mins, \n","batch no = 500 / 1256, train loss = 4.635, lr = 0.300, since beginning = 11 mins, \n","batch no = 625 / 1256, train loss = 4.481, lr = 0.300, since beginning = 11 mins, \n","batch no = 750 / 1256, train loss = 4.648, lr = 0.300, since beginning = 11 mins, \n","batch no = 875 / 1256, train loss = 4.749, lr = 0.300, since beginning = 11 mins, \n","batch no = 1000 / 1256, train loss = 4.627, lr = 0.300, since beginning = 11 mins, \n","batch no = 1125 / 1256, train loss = 4.420, lr = 0.300, since beginning = 11 mins, \n","batch no = 1250 / 1256, train loss = 4.822, lr = 0.300, since beginning = 11 mins, \n","Epoch : 39 || Validation set perplexity : 115.044\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.039, lr = 0.300, since beginning = 11 mins, \n","batch no = 125 / 1256, train loss = 4.510, lr = 0.300, since beginning = 11 mins, \n","batch no = 250 / 1256, train loss = 4.713, lr = 0.300, since beginning = 11 mins, \n","batch no = 375 / 1256, train loss = 4.897, lr = 0.300, since beginning = 11 mins, \n","batch no = 500 / 1256, train loss = 4.611, lr = 0.300, since beginning = 11 mins, \n","batch no = 625 / 1256, train loss = 4.563, lr = 0.300, since beginning = 11 mins, \n","batch no = 750 / 1256, train loss = 4.646, lr = 0.300, since beginning = 11 mins, \n","batch no = 875 / 1256, train loss = 4.687, lr = 0.300, since beginning = 11 mins, \n","batch no = 1000 / 1256, train loss = 4.651, lr = 0.300, since beginning = 11 mins, \n","batch no = 1125 / 1256, train loss = 4.383, lr = 0.300, since beginning = 11 mins, \n","batch no = 1250 / 1256, train loss = 4.777, lr = 0.300, since beginning = 11 mins, \n","Epoch : 40 || Validation set perplexity : 114.499\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.978, lr = 0.300, since beginning = 11 mins, \n","batch no = 125 / 1256, train loss = 4.565, lr = 0.300, since beginning = 11 mins, \n","batch no = 250 / 1256, train loss = 4.716, lr = 0.300, since beginning = 11 mins, \n","batch no = 375 / 1256, train loss = 4.946, lr = 0.300, since beginning = 11 mins, \n","batch no = 500 / 1256, train loss = 4.663, lr = 0.300, since beginning = 11 mins, \n","batch no = 625 / 1256, train loss = 4.445, lr = 0.300, since beginning = 11 mins, \n","batch no = 750 / 1256, train loss = 4.665, lr = 0.300, since beginning = 11 mins, \n","batch no = 875 / 1256, train loss = 4.700, lr = 0.300, since beginning = 11 mins, \n","batch no = 1000 / 1256, train loss = 4.565, lr = 0.300, since beginning = 11 mins, \n","batch no = 1125 / 1256, train loss = 4.385, lr = 0.300, since beginning = 11 mins, \n","batch no = 1250 / 1256, train loss = 4.829, lr = 0.300, since beginning = 11 mins, \n","Epoch : 41 || Validation set perplexity : 114.617\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.023, lr = 0.300, since beginning = 11 mins, \n","batch no = 125 / 1256, train loss = 4.504, lr = 0.300, since beginning = 11 mins, \n","batch no = 250 / 1256, train loss = 4.714, lr = 0.300, since beginning = 11 mins, \n","batch no = 375 / 1256, train loss = 4.881, lr = 0.300, since beginning = 11 mins, \n","batch no = 500 / 1256, train loss = 4.597, lr = 0.300, since beginning = 11 mins, \n","batch no = 625 / 1256, train loss = 4.611, lr = 0.300, since beginning = 11 mins, \n","batch no = 750 / 1256, train loss = 4.612, lr = 0.300, since beginning = 11 mins, \n","batch no = 875 / 1256, train loss = 4.692, lr = 0.300, since beginning = 11 mins, \n","batch no = 1000 / 1256, train loss = 4.703, lr = 0.300, since beginning = 11 mins, \n","batch no = 1125 / 1256, train loss = 4.439, lr = 0.300, since beginning = 11 mins, \n","batch no = 1250 / 1256, train loss = 4.795, lr = 0.300, since beginning = 11 mins, \n","Epoch : 42 || Validation set perplexity : 113.456\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.041, lr = 0.300, since beginning = 12 mins, \n","batch no = 125 / 1256, train loss = 4.536, lr = 0.300, since beginning = 12 mins, \n","batch no = 250 / 1256, train loss = 4.698, lr = 0.300, since beginning = 12 mins, \n","batch no = 375 / 1256, train loss = 4.865, lr = 0.300, since beginning = 12 mins, \n","batch no = 500 / 1256, train loss = 4.607, lr = 0.300, since beginning = 12 mins, \n","batch no = 625 / 1256, train loss = 4.559, lr = 0.300, since beginning = 12 mins, \n","batch no = 750 / 1256, train loss = 4.611, lr = 0.300, since beginning = 12 mins, \n","batch no = 875 / 1256, train loss = 4.648, lr = 0.300, since beginning = 12 mins, \n","batch no = 1000 / 1256, train loss = 4.641, lr = 0.300, since beginning = 12 mins, \n","batch no = 1125 / 1256, train loss = 4.453, lr = 0.300, since beginning = 12 mins, \n","batch no = 1250 / 1256, train loss = 4.766, lr = 0.300, since beginning = 12 mins, \n","Epoch : 43 || Validation set perplexity : 113.805\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.995, lr = 0.300, since beginning = 12 mins, \n","batch no = 125 / 1256, train loss = 4.486, lr = 0.300, since beginning = 12 mins, \n","batch no = 250 / 1256, train loss = 4.684, lr = 0.300, since beginning = 12 mins, \n","batch no = 375 / 1256, train loss = 4.837, lr = 0.300, since beginning = 12 mins, \n","batch no = 500 / 1256, train loss = 4.714, lr = 0.300, since beginning = 12 mins, \n","batch no = 625 / 1256, train loss = 4.461, lr = 0.300, since beginning = 12 mins, \n","batch no = 750 / 1256, train loss = 4.652, lr = 0.300, since beginning = 12 mins, \n","batch no = 875 / 1256, train loss = 4.643, lr = 0.300, since beginning = 12 mins, \n","batch no = 1000 / 1256, train loss = 4.656, lr = 0.300, since beginning = 12 mins, \n","batch no = 1125 / 1256, train loss = 4.427, lr = 0.300, since beginning = 12 mins, \n","batch no = 1250 / 1256, train loss = 4.744, lr = 0.300, since beginning = 12 mins, \n","Epoch : 44 || Validation set perplexity : 113.909\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.010, lr = 0.300, since beginning = 12 mins, \n","batch no = 125 / 1256, train loss = 4.459, lr = 0.300, since beginning = 12 mins, \n","batch no = 250 / 1256, train loss = 4.670, lr = 0.300, since beginning = 12 mins, \n","batch no = 375 / 1256, train loss = 4.885, lr = 0.300, since beginning = 12 mins, \n","batch no = 500 / 1256, train loss = 4.637, lr = 0.300, since beginning = 12 mins, \n","batch no = 625 / 1256, train loss = 4.540, lr = 0.300, since beginning = 12 mins, \n","batch no = 750 / 1256, train loss = 4.578, lr = 0.300, since beginning = 12 mins, \n","batch no = 875 / 1256, train loss = 4.675, lr = 0.300, since beginning = 12 mins, \n","batch no = 1000 / 1256, train loss = 4.598, lr = 0.300, since beginning = 12 mins, \n","batch no = 1125 / 1256, train loss = 4.381, lr = 0.300, since beginning = 12 mins, \n","batch no = 1250 / 1256, train loss = 4.771, lr = 0.300, since beginning = 12 mins, \n","Epoch : 45 || Validation set perplexity : 112.904\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.939, lr = 0.300, since beginning = 12 mins, \n","batch no = 125 / 1256, train loss = 4.567, lr = 0.300, since beginning = 12 mins, \n","batch no = 250 / 1256, train loss = 4.639, lr = 0.300, since beginning = 12 mins, \n","batch no = 375 / 1256, train loss = 4.830, lr = 0.300, since beginning = 12 mins, \n","batch no = 500 / 1256, train loss = 4.621, lr = 0.300, since beginning = 12 mins, \n","batch no = 625 / 1256, train loss = 4.478, lr = 0.300, since beginning = 12 mins, \n","batch no = 750 / 1256, train loss = 4.641, lr = 0.300, since beginning = 12 mins, \n","batch no = 875 / 1256, train loss = 4.713, lr = 0.300, since beginning = 12 mins, \n","batch no = 1000 / 1256, train loss = 4.620, lr = 0.300, since beginning = 13 mins, \n","batch no = 1125 / 1256, train loss = 4.373, lr = 0.300, since beginning = 13 mins, \n","batch no = 1250 / 1256, train loss = 4.774, lr = 0.300, since beginning = 13 mins, \n","Epoch : 46 || Validation set perplexity : 113.157\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.062, lr = 0.300, since beginning = 13 mins, \n","batch no = 125 / 1256, train loss = 4.539, lr = 0.300, since beginning = 13 mins, \n","batch no = 250 / 1256, train loss = 4.723, lr = 0.300, since beginning = 13 mins, \n","batch no = 375 / 1256, train loss = 4.862, lr = 0.300, since beginning = 13 mins, \n","batch no = 500 / 1256, train loss = 4.580, lr = 0.300, since beginning = 13 mins, \n","batch no = 625 / 1256, train loss = 4.496, lr = 0.300, since beginning = 13 mins, \n","batch no = 750 / 1256, train loss = 4.643, lr = 0.300, since beginning = 13 mins, \n","batch no = 875 / 1256, train loss = 4.625, lr = 0.300, since beginning = 13 mins, \n","batch no = 1000 / 1256, train loss = 4.558, lr = 0.300, since beginning = 13 mins, \n","batch no = 1125 / 1256, train loss = 4.398, lr = 0.300, since beginning = 13 mins, \n","batch no = 1250 / 1256, train loss = 4.661, lr = 0.300, since beginning = 13 mins, \n","Epoch : 47 || Validation set perplexity : 114.217\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.972, lr = 0.300, since beginning = 13 mins, \n","batch no = 125 / 1256, train loss = 4.534, lr = 0.300, since beginning = 13 mins, \n","batch no = 250 / 1256, train loss = 4.662, lr = 0.300, since beginning = 13 mins, \n","batch no = 375 / 1256, train loss = 4.866, lr = 0.300, since beginning = 13 mins, \n","batch no = 500 / 1256, train loss = 4.622, lr = 0.300, since beginning = 13 mins, \n","batch no = 625 / 1256, train loss = 4.488, lr = 0.300, since beginning = 13 mins, \n","batch no = 750 / 1256, train loss = 4.618, lr = 0.300, since beginning = 13 mins, \n","batch no = 875 / 1256, train loss = 4.682, lr = 0.300, since beginning = 13 mins, \n","batch no = 1000 / 1256, train loss = 4.613, lr = 0.300, since beginning = 13 mins, \n","batch no = 1125 / 1256, train loss = 4.408, lr = 0.300, since beginning = 13 mins, \n","batch no = 1250 / 1256, train loss = 4.777, lr = 0.300, since beginning = 13 mins, \n","Epoch : 48 || Validation set perplexity : 113.274\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.022, lr = 0.300, since beginning = 13 mins, \n","batch no = 125 / 1256, train loss = 4.501, lr = 0.300, since beginning = 13 mins, \n","batch no = 250 / 1256, train loss = 4.679, lr = 0.300, since beginning = 13 mins, \n","batch no = 375 / 1256, train loss = 4.892, lr = 0.300, since beginning = 13 mins, \n","batch no = 500 / 1256, train loss = 4.645, lr = 0.300, since beginning = 13 mins, \n","batch no = 625 / 1256, train loss = 4.441, lr = 0.300, since beginning = 13 mins, \n","batch no = 750 / 1256, train loss = 4.630, lr = 0.300, since beginning = 13 mins, \n","batch no = 875 / 1256, train loss = 4.685, lr = 0.300, since beginning = 13 mins, \n","batch no = 1000 / 1256, train loss = 4.619, lr = 0.300, since beginning = 13 mins, \n","batch no = 1125 / 1256, train loss = 4.323, lr = 0.300, since beginning = 13 mins, \n","batch no = 1250 / 1256, train loss = 4.724, lr = 0.300, since beginning = 13 mins, \n","Epoch : 49 || Validation set perplexity : 113.654\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.970, lr = 0.300, since beginning = 13 mins, \n","batch no = 125 / 1256, train loss = 4.524, lr = 0.300, since beginning = 13 mins, \n","batch no = 250 / 1256, train loss = 4.642, lr = 0.300, since beginning = 13 mins, \n","batch no = 375 / 1256, train loss = 4.911, lr = 0.300, since beginning = 14 mins, \n","batch no = 500 / 1256, train loss = 4.643, lr = 0.300, since beginning = 14 mins, \n","batch no = 625 / 1256, train loss = 4.453, lr = 0.300, since beginning = 14 mins, \n","batch no = 750 / 1256, train loss = 4.596, lr = 0.300, since beginning = 14 mins, \n","batch no = 875 / 1256, train loss = 4.662, lr = 0.300, since beginning = 14 mins, \n","batch no = 1000 / 1256, train loss = 4.603, lr = 0.300, since beginning = 14 mins, \n","batch no = 1125 / 1256, train loss = 4.301, lr = 0.300, since beginning = 14 mins, \n","batch no = 1250 / 1256, train loss = 4.719, lr = 0.300, since beginning = 14 mins, \n","Epoch : 50 || Validation set perplexity : 112.986\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.987, lr = 0.300, since beginning = 14 mins, \n","batch no = 125 / 1256, train loss = 4.513, lr = 0.300, since beginning = 14 mins, \n","batch no = 250 / 1256, train loss = 4.676, lr = 0.300, since beginning = 14 mins, \n","batch no = 375 / 1256, train loss = 4.788, lr = 0.300, since beginning = 14 mins, \n","batch no = 500 / 1256, train loss = 4.600, lr = 0.300, since beginning = 14 mins, \n","batch no = 625 / 1256, train loss = 4.489, lr = 0.300, since beginning = 14 mins, \n","batch no = 750 / 1256, train loss = 4.605, lr = 0.300, since beginning = 14 mins, \n","batch no = 875 / 1256, train loss = 4.726, lr = 0.300, since beginning = 14 mins, \n","batch no = 1000 / 1256, train loss = 4.625, lr = 0.300, since beginning = 14 mins, \n","batch no = 1125 / 1256, train loss = 4.424, lr = 0.300, since beginning = 14 mins, \n","batch no = 1250 / 1256, train loss = 4.712, lr = 0.300, since beginning = 14 mins, \n","Epoch : 51 || Validation set perplexity : 112.210\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.919, lr = 0.300, since beginning = 14 mins, \n","batch no = 125 / 1256, train loss = 4.498, lr = 0.300, since beginning = 14 mins, \n","batch no = 250 / 1256, train loss = 4.723, lr = 0.300, since beginning = 14 mins, \n","batch no = 375 / 1256, train loss = 4.860, lr = 0.300, since beginning = 14 mins, \n","batch no = 500 / 1256, train loss = 4.651, lr = 0.300, since beginning = 14 mins, \n","batch no = 625 / 1256, train loss = 4.487, lr = 0.300, since beginning = 14 mins, \n","batch no = 750 / 1256, train loss = 4.584, lr = 0.300, since beginning = 14 mins, \n","batch no = 875 / 1256, train loss = 4.670, lr = 0.300, since beginning = 14 mins, \n","batch no = 1000 / 1256, train loss = 4.633, lr = 0.300, since beginning = 14 mins, \n","batch no = 1125 / 1256, train loss = 4.425, lr = 0.300, since beginning = 14 mins, \n","batch no = 1250 / 1256, train loss = 4.729, lr = 0.300, since beginning = 14 mins, \n","Epoch : 52 || Validation set perplexity : 113.481\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.978, lr = 0.300, since beginning = 14 mins, \n","batch no = 125 / 1256, train loss = 4.482, lr = 0.300, since beginning = 14 mins, \n","batch no = 250 / 1256, train loss = 4.620, lr = 0.300, since beginning = 14 mins, \n","batch no = 375 / 1256, train loss = 4.824, lr = 0.300, since beginning = 14 mins, \n","batch no = 500 / 1256, train loss = 4.577, lr = 0.300, since beginning = 14 mins, \n","batch no = 625 / 1256, train loss = 4.414, lr = 0.300, since beginning = 14 mins, \n","batch no = 750 / 1256, train loss = 4.638, lr = 0.300, since beginning = 14 mins, \n","batch no = 875 / 1256, train loss = 4.720, lr = 0.300, since beginning = 14 mins, \n","batch no = 1000 / 1256, train loss = 4.555, lr = 0.300, since beginning = 14 mins, \n","batch no = 1125 / 1256, train loss = 4.362, lr = 0.300, since beginning = 14 mins, \n","batch no = 1250 / 1256, train loss = 4.766, lr = 0.300, since beginning = 14 mins, \n","Epoch : 53 || Validation set perplexity : 112.429\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 5.003, lr = 0.300, since beginning = 15 mins, \n","batch no = 125 / 1256, train loss = 4.454, lr = 0.300, since beginning = 15 mins, \n","batch no = 250 / 1256, train loss = 4.694, lr = 0.300, since beginning = 15 mins, \n","batch no = 375 / 1256, train loss = 4.807, lr = 0.300, since beginning = 15 mins, \n","batch no = 500 / 1256, train loss = 4.671, lr = 0.300, since beginning = 15 mins, \n","batch no = 625 / 1256, train loss = 4.428, lr = 0.300, since beginning = 15 mins, \n","batch no = 750 / 1256, train loss = 4.534, lr = 0.300, since beginning = 15 mins, \n","batch no = 875 / 1256, train loss = 4.686, lr = 0.300, since beginning = 15 mins, \n","batch no = 1000 / 1256, train loss = 4.560, lr = 0.300, since beginning = 15 mins, \n","batch no = 1125 / 1256, train loss = 4.348, lr = 0.300, since beginning = 15 mins, \n","batch no = 1250 / 1256, train loss = 4.656, lr = 0.300, since beginning = 15 mins, \n","Epoch : 54 || Validation set perplexity : 113.129\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.960, lr = 0.300, since beginning = 15 mins, \n","batch no = 125 / 1256, train loss = 4.477, lr = 0.300, since beginning = 15 mins, \n","batch no = 250 / 1256, train loss = 4.654, lr = 0.300, since beginning = 15 mins, \n","batch no = 375 / 1256, train loss = 4.860, lr = 0.300, since beginning = 15 mins, \n","batch no = 500 / 1256, train loss = 4.616, lr = 0.300, since beginning = 15 mins, \n","batch no = 625 / 1256, train loss = 4.495, lr = 0.300, since beginning = 15 mins, \n","batch no = 750 / 1256, train loss = 4.612, lr = 0.300, since beginning = 15 mins, \n","batch no = 875 / 1256, train loss = 4.688, lr = 0.300, since beginning = 15 mins, \n","batch no = 1000 / 1256, train loss = 4.624, lr = 0.300, since beginning = 15 mins, \n","batch no = 1125 / 1256, train loss = 4.336, lr = 0.300, since beginning = 15 mins, \n","batch no = 1250 / 1256, train loss = 4.758, lr = 0.300, since beginning = 15 mins, \n","Epoch : 55 || Validation set perplexity : 112.807\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.957, lr = 0.300, since beginning = 15 mins, \n","batch no = 125 / 1256, train loss = 4.560, lr = 0.300, since beginning = 15 mins, \n","batch no = 250 / 1256, train loss = 4.634, lr = 0.300, since beginning = 15 mins, \n","batch no = 375 / 1256, train loss = 4.869, lr = 0.300, since beginning = 15 mins, \n","batch no = 500 / 1256, train loss = 4.601, lr = 0.300, since beginning = 15 mins, \n","batch no = 625 / 1256, train loss = 4.410, lr = 0.300, since beginning = 15 mins, \n","batch no = 750 / 1256, train loss = 4.656, lr = 0.300, since beginning = 15 mins, \n","batch no = 875 / 1256, train loss = 4.688, lr = 0.300, since beginning = 15 mins, \n","batch no = 1000 / 1256, train loss = 4.580, lr = 0.300, since beginning = 15 mins, \n","batch no = 1125 / 1256, train loss = 4.317, lr = 0.300, since beginning = 15 mins, \n","batch no = 1250 / 1256, train loss = 4.718, lr = 0.300, since beginning = 15 mins, \n","Epoch : 56 || Validation set perplexity : 113.215\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.976, lr = 0.300, since beginning = 15 mins, \n","batch no = 125 / 1256, train loss = 4.468, lr = 0.300, since beginning = 15 mins, \n","batch no = 250 / 1256, train loss = 4.727, lr = 0.300, since beginning = 15 mins, \n","batch no = 375 / 1256, train loss = 4.868, lr = 0.300, since beginning = 15 mins, \n","batch no = 500 / 1256, train loss = 4.602, lr = 0.300, since beginning = 15 mins, \n","batch no = 625 / 1256, train loss = 4.460, lr = 0.300, since beginning = 15 mins, \n","batch no = 750 / 1256, train loss = 4.562, lr = 0.300, since beginning = 15 mins, \n","batch no = 875 / 1256, train loss = 4.611, lr = 0.300, since beginning = 16 mins, \n","batch no = 1000 / 1256, train loss = 4.603, lr = 0.300, since beginning = 16 mins, \n","batch no = 1125 / 1256, train loss = 4.384, lr = 0.300, since beginning = 16 mins, \n","batch no = 1250 / 1256, train loss = 4.736, lr = 0.300, since beginning = 16 mins, \n","Epoch : 57 || Validation set perplexity : 113.736\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.938, lr = 0.300, since beginning = 16 mins, \n","batch no = 125 / 1256, train loss = 4.432, lr = 0.300, since beginning = 16 mins, \n","batch no = 250 / 1256, train loss = 4.627, lr = 0.300, since beginning = 16 mins, \n","batch no = 375 / 1256, train loss = 4.826, lr = 0.300, since beginning = 16 mins, \n","batch no = 500 / 1256, train loss = 4.643, lr = 0.300, since beginning = 16 mins, \n","batch no = 625 / 1256, train loss = 4.497, lr = 0.300, since beginning = 16 mins, \n","batch no = 750 / 1256, train loss = 4.527, lr = 0.300, since beginning = 16 mins, \n","batch no = 875 / 1256, train loss = 4.629, lr = 0.300, since beginning = 16 mins, \n","batch no = 1000 / 1256, train loss = 4.606, lr = 0.300, since beginning = 16 mins, \n","batch no = 1125 / 1256, train loss = 4.361, lr = 0.300, since beginning = 16 mins, \n","batch no = 1250 / 1256, train loss = 4.680, lr = 0.300, since beginning = 16 mins, \n","Epoch : 58 || Validation set perplexity : 112.567\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.910, lr = 0.300, since beginning = 16 mins, \n","batch no = 125 / 1256, train loss = 4.458, lr = 0.300, since beginning = 16 mins, \n","batch no = 250 / 1256, train loss = 4.651, lr = 0.300, since beginning = 16 mins, \n","batch no = 375 / 1256, train loss = 4.856, lr = 0.300, since beginning = 16 mins, \n","batch no = 500 / 1256, train loss = 4.618, lr = 0.300, since beginning = 16 mins, \n","batch no = 625 / 1256, train loss = 4.453, lr = 0.300, since beginning = 16 mins, \n","batch no = 750 / 1256, train loss = 4.564, lr = 0.300, since beginning = 16 mins, \n","batch no = 875 / 1256, train loss = 4.662, lr = 0.300, since beginning = 16 mins, \n","batch no = 1000 / 1256, train loss = 4.562, lr = 0.300, since beginning = 16 mins, \n","batch no = 1125 / 1256, train loss = 4.347, lr = 0.300, since beginning = 16 mins, \n","batch no = 1250 / 1256, train loss = 4.753, lr = 0.300, since beginning = 16 mins, \n","Epoch : 59 || Validation set perplexity : 112.804\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.906, lr = 0.300, since beginning = 16 mins, \n","batch no = 125 / 1256, train loss = 4.487, lr = 0.300, since beginning = 16 mins, \n","batch no = 250 / 1256, train loss = 4.639, lr = 0.300, since beginning = 16 mins, \n","batch no = 375 / 1256, train loss = 4.857, lr = 0.300, since beginning = 16 mins, \n","batch no = 500 / 1256, train loss = 4.573, lr = 0.300, since beginning = 16 mins, \n","batch no = 625 / 1256, train loss = 4.533, lr = 0.300, since beginning = 16 mins, \n","batch no = 750 / 1256, train loss = 4.609, lr = 0.300, since beginning = 16 mins, \n","batch no = 875 / 1256, train loss = 4.595, lr = 0.300, since beginning = 16 mins, \n","batch no = 1000 / 1256, train loss = 4.616, lr = 0.300, since beginning = 16 mins, \n","batch no = 1125 / 1256, train loss = 4.361, lr = 0.300, since beginning = 16 mins, \n","batch no = 1250 / 1256, train loss = 4.668, lr = 0.300, since beginning = 16 mins, \n","Epoch : 60 || Validation set perplexity : 112.739\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.915, lr = 0.300, since beginning = 16 mins, \n","batch no = 125 / 1256, train loss = 4.460, lr = 0.300, since beginning = 16 mins, \n","batch no = 250 / 1256, train loss = 4.592, lr = 0.300, since beginning = 17 mins, \n","batch no = 375 / 1256, train loss = 4.809, lr = 0.300, since beginning = 17 mins, \n","batch no = 500 / 1256, train loss = 4.636, lr = 0.300, since beginning = 17 mins, \n","batch no = 625 / 1256, train loss = 4.482, lr = 0.300, since beginning = 17 mins, \n","batch no = 750 / 1256, train loss = 4.518, lr = 0.300, since beginning = 17 mins, \n","batch no = 875 / 1256, train loss = 4.633, lr = 0.300, since beginning = 17 mins, \n","batch no = 1000 / 1256, train loss = 4.592, lr = 0.300, since beginning = 17 mins, \n","batch no = 1125 / 1256, train loss = 4.421, lr = 0.300, since beginning = 17 mins, \n","batch no = 1250 / 1256, train loss = 4.689, lr = 0.300, since beginning = 17 mins, \n","Epoch : 61 || Validation set perplexity : 111.834\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.876, lr = 0.300, since beginning = 17 mins, \n","batch no = 125 / 1256, train loss = 4.419, lr = 0.300, since beginning = 17 mins, \n","batch no = 250 / 1256, train loss = 4.647, lr = 0.300, since beginning = 17 mins, \n","batch no = 375 / 1256, train loss = 4.843, lr = 0.300, since beginning = 17 mins, \n","batch no = 500 / 1256, train loss = 4.627, lr = 0.300, since beginning = 17 mins, \n","batch no = 625 / 1256, train loss = 4.437, lr = 0.300, since beginning = 17 mins, \n","batch no = 750 / 1256, train loss = 4.575, lr = 0.300, since beginning = 17 mins, \n","batch no = 875 / 1256, train loss = 4.655, lr = 0.300, since beginning = 17 mins, \n","batch no = 1000 / 1256, train loss = 4.576, lr = 0.300, since beginning = 17 mins, \n","batch no = 1125 / 1256, train loss = 4.336, lr = 0.300, since beginning = 17 mins, \n","batch no = 1250 / 1256, train loss = 4.704, lr = 0.300, since beginning = 17 mins, \n","Epoch : 62 || Validation set perplexity : 110.978\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.881, lr = 0.300, since beginning = 17 mins, \n","batch no = 125 / 1256, train loss = 4.510, lr = 0.300, since beginning = 17 mins, \n","batch no = 250 / 1256, train loss = 4.629, lr = 0.300, since beginning = 17 mins, \n","batch no = 375 / 1256, train loss = 4.822, lr = 0.300, since beginning = 17 mins, \n","batch no = 500 / 1256, train loss = 4.579, lr = 0.300, since beginning = 17 mins, \n","batch no = 625 / 1256, train loss = 4.446, lr = 0.300, since beginning = 17 mins, \n","batch no = 750 / 1256, train loss = 4.604, lr = 0.300, since beginning = 17 mins, \n","batch no = 875 / 1256, train loss = 4.627, lr = 0.300, since beginning = 17 mins, \n","batch no = 1000 / 1256, train loss = 4.517, lr = 0.300, since beginning = 17 mins, \n","batch no = 1125 / 1256, train loss = 4.390, lr = 0.300, since beginning = 17 mins, \n","batch no = 1250 / 1256, train loss = 4.671, lr = 0.300, since beginning = 17 mins, \n","Epoch : 63 || Validation set perplexity : 111.707\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.914, lr = 0.300, since beginning = 17 mins, \n","batch no = 125 / 1256, train loss = 4.486, lr = 0.300, since beginning = 17 mins, \n","batch no = 250 / 1256, train loss = 4.632, lr = 0.300, since beginning = 17 mins, \n","batch no = 375 / 1256, train loss = 4.863, lr = 0.300, since beginning = 17 mins, \n","batch no = 500 / 1256, train loss = 4.653, lr = 0.300, since beginning = 17 mins, \n","batch no = 625 / 1256, train loss = 4.428, lr = 0.300, since beginning = 17 mins, \n","batch no = 750 / 1256, train loss = 4.588, lr = 0.300, since beginning = 17 mins, \n","batch no = 875 / 1256, train loss = 4.678, lr = 0.300, since beginning = 17 mins, \n","batch no = 1000 / 1256, train loss = 4.640, lr = 0.300, since beginning = 17 mins, \n","batch no = 1125 / 1256, train loss = 4.326, lr = 0.300, since beginning = 17 mins, \n","batch no = 1250 / 1256, train loss = 4.700, lr = 0.300, since beginning = 17 mins, \n","Epoch : 64 || Validation set perplexity : 110.847\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.900, lr = 0.300, since beginning = 18 mins, \n","batch no = 125 / 1256, train loss = 4.467, lr = 0.300, since beginning = 18 mins, \n","batch no = 250 / 1256, train loss = 4.627, lr = 0.300, since beginning = 18 mins, \n","batch no = 375 / 1256, train loss = 4.825, lr = 0.300, since beginning = 18 mins, \n","batch no = 500 / 1256, train loss = 4.540, lr = 0.300, since beginning = 18 mins, \n","batch no = 625 / 1256, train loss = 4.417, lr = 0.300, since beginning = 18 mins, \n","batch no = 750 / 1256, train loss = 4.508, lr = 0.300, since beginning = 18 mins, \n","batch no = 875 / 1256, train loss = 4.699, lr = 0.300, since beginning = 18 mins, \n","batch no = 1000 / 1256, train loss = 4.571, lr = 0.300, since beginning = 18 mins, \n","batch no = 1125 / 1256, train loss = 4.340, lr = 0.300, since beginning = 18 mins, \n","batch no = 1250 / 1256, train loss = 4.655, lr = 0.300, since beginning = 18 mins, \n","Epoch : 65 || Validation set perplexity : 112.494\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.908, lr = 0.300, since beginning = 18 mins, \n","batch no = 125 / 1256, train loss = 4.444, lr = 0.300, since beginning = 18 mins, \n","batch no = 250 / 1256, train loss = 4.648, lr = 0.300, since beginning = 18 mins, \n","batch no = 375 / 1256, train loss = 4.826, lr = 0.300, since beginning = 18 mins, \n","batch no = 500 / 1256, train loss = 4.613, lr = 0.300, since beginning = 18 mins, \n","batch no = 625 / 1256, train loss = 4.397, lr = 0.300, since beginning = 18 mins, \n","batch no = 750 / 1256, train loss = 4.553, lr = 0.300, since beginning = 18 mins, \n","batch no = 875 / 1256, train loss = 4.654, lr = 0.300, since beginning = 18 mins, \n","batch no = 1000 / 1256, train loss = 4.567, lr = 0.300, since beginning = 18 mins, \n","batch no = 1125 / 1256, train loss = 4.394, lr = 0.300, since beginning = 18 mins, \n","batch no = 1250 / 1256, train loss = 4.694, lr = 0.300, since beginning = 18 mins, \n","Epoch : 66 || Validation set perplexity : 111.066\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.841, lr = 0.248, since beginning = 18 mins, \n","batch no = 125 / 1256, train loss = 4.344, lr = 0.248, since beginning = 18 mins, \n","batch no = 250 / 1256, train loss = 4.591, lr = 0.248, since beginning = 18 mins, \n","batch no = 375 / 1256, train loss = 4.762, lr = 0.248, since beginning = 18 mins, \n","batch no = 500 / 1256, train loss = 4.562, lr = 0.248, since beginning = 18 mins, \n","batch no = 625 / 1256, train loss = 4.396, lr = 0.248, since beginning = 18 mins, \n","batch no = 750 / 1256, train loss = 4.555, lr = 0.248, since beginning = 18 mins, \n","batch no = 875 / 1256, train loss = 4.647, lr = 0.248, since beginning = 18 mins, \n","batch no = 1000 / 1256, train loss = 4.485, lr = 0.248, since beginning = 18 mins, \n","batch no = 1125 / 1256, train loss = 4.391, lr = 0.248, since beginning = 18 mins, \n","batch no = 1250 / 1256, train loss = 4.716, lr = 0.248, since beginning = 18 mins, \n","Epoch : 67 || Validation set perplexity : 110.039\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.848, lr = 0.205, since beginning = 18 mins, \n","batch no = 125 / 1256, train loss = 4.406, lr = 0.205, since beginning = 18 mins, \n","batch no = 250 / 1256, train loss = 4.525, lr = 0.205, since beginning = 18 mins, \n","batch no = 375 / 1256, train loss = 4.771, lr = 0.205, since beginning = 18 mins, \n","batch no = 500 / 1256, train loss = 4.534, lr = 0.205, since beginning = 18 mins, \n","batch no = 625 / 1256, train loss = 4.425, lr = 0.205, since beginning = 18 mins, \n","batch no = 750 / 1256, train loss = 4.436, lr = 0.205, since beginning = 19 mins, \n","batch no = 875 / 1256, train loss = 4.638, lr = 0.205, since beginning = 19 mins, \n","batch no = 1000 / 1256, train loss = 4.499, lr = 0.205, since beginning = 19 mins, \n","batch no = 1125 / 1256, train loss = 4.251, lr = 0.205, since beginning = 19 mins, \n","batch no = 1250 / 1256, train loss = 4.631, lr = 0.205, since beginning = 19 mins, \n","Epoch : 68 || Validation set perplexity : 109.194\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.886, lr = 0.169, since beginning = 19 mins, \n","batch no = 125 / 1256, train loss = 4.391, lr = 0.169, since beginning = 19 mins, \n","batch no = 250 / 1256, train loss = 4.585, lr = 0.169, since beginning = 19 mins, \n","batch no = 375 / 1256, train loss = 4.823, lr = 0.169, since beginning = 19 mins, \n","batch no = 500 / 1256, train loss = 4.482, lr = 0.169, since beginning = 19 mins, \n","batch no = 625 / 1256, train loss = 4.258, lr = 0.169, since beginning = 19 mins, \n","batch no = 750 / 1256, train loss = 4.447, lr = 0.169, since beginning = 19 mins, \n","batch no = 875 / 1256, train loss = 4.563, lr = 0.169, since beginning = 19 mins, \n","batch no = 1000 / 1256, train loss = 4.466, lr = 0.169, since beginning = 19 mins, \n","batch no = 1125 / 1256, train loss = 4.296, lr = 0.169, since beginning = 19 mins, \n","batch no = 1250 / 1256, train loss = 4.583, lr = 0.169, since beginning = 19 mins, \n","Epoch : 69 || Validation set perplexity : 107.367\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.798, lr = 0.140, since beginning = 19 mins, \n","batch no = 125 / 1256, train loss = 4.388, lr = 0.140, since beginning = 19 mins, \n","batch no = 250 / 1256, train loss = 4.538, lr = 0.140, since beginning = 19 mins, \n","batch no = 375 / 1256, train loss = 4.702, lr = 0.140, since beginning = 19 mins, \n","batch no = 500 / 1256, train loss = 4.507, lr = 0.140, since beginning = 19 mins, \n","batch no = 625 / 1256, train loss = 4.369, lr = 0.140, since beginning = 19 mins, \n","batch no = 750 / 1256, train loss = 4.409, lr = 0.140, since beginning = 19 mins, \n","batch no = 875 / 1256, train loss = 4.534, lr = 0.140, since beginning = 19 mins, \n","batch no = 1000 / 1256, train loss = 4.425, lr = 0.140, since beginning = 19 mins, \n","batch no = 1125 / 1256, train loss = 4.250, lr = 0.140, since beginning = 19 mins, \n","batch no = 1250 / 1256, train loss = 4.607, lr = 0.140, since beginning = 19 mins, \n","Epoch : 70 || Validation set perplexity : 106.054\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.782, lr = 0.116, since beginning = 19 mins, \n","batch no = 125 / 1256, train loss = 4.401, lr = 0.116, since beginning = 19 mins, \n","batch no = 250 / 1256, train loss = 4.584, lr = 0.116, since beginning = 19 mins, \n","batch no = 375 / 1256, train loss = 4.750, lr = 0.116, since beginning = 19 mins, \n","batch no = 500 / 1256, train loss = 4.478, lr = 0.116, since beginning = 19 mins, \n","batch no = 625 / 1256, train loss = 4.301, lr = 0.116, since beginning = 19 mins, \n","batch no = 750 / 1256, train loss = 4.464, lr = 0.116, since beginning = 19 mins, \n","batch no = 875 / 1256, train loss = 4.529, lr = 0.116, since beginning = 19 mins, \n","batch no = 1000 / 1256, train loss = 4.425, lr = 0.116, since beginning = 19 mins, \n","batch no = 1125 / 1256, train loss = 4.175, lr = 0.116, since beginning = 19 mins, \n","batch no = 1250 / 1256, train loss = 4.548, lr = 0.116, since beginning = 19 mins, \n","Epoch : 71 || Validation set perplexity : 105.139\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.807, lr = 0.096, since beginning = 19 mins, \n","batch no = 125 / 1256, train loss = 4.380, lr = 0.096, since beginning = 19 mins, \n","batch no = 250 / 1256, train loss = 4.514, lr = 0.096, since beginning = 20 mins, \n","batch no = 375 / 1256, train loss = 4.675, lr = 0.096, since beginning = 20 mins, \n","batch no = 500 / 1256, train loss = 4.419, lr = 0.096, since beginning = 20 mins, \n","batch no = 625 / 1256, train loss = 4.357, lr = 0.096, since beginning = 20 mins, \n","batch no = 750 / 1256, train loss = 4.473, lr = 0.096, since beginning = 20 mins, \n","batch no = 875 / 1256, train loss = 4.483, lr = 0.096, since beginning = 20 mins, \n","batch no = 1000 / 1256, train loss = 4.453, lr = 0.096, since beginning = 20 mins, \n","batch no = 1125 / 1256, train loss = 4.186, lr = 0.096, since beginning = 20 mins, \n","batch no = 1250 / 1256, train loss = 4.562, lr = 0.096, since beginning = 20 mins, \n","Epoch : 72 || Validation set perplexity : 104.364\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.870, lr = 0.079, since beginning = 20 mins, \n","batch no = 125 / 1256, train loss = 4.269, lr = 0.079, since beginning = 20 mins, \n","batch no = 250 / 1256, train loss = 4.541, lr = 0.079, since beginning = 20 mins, \n","batch no = 375 / 1256, train loss = 4.671, lr = 0.079, since beginning = 20 mins, \n","batch no = 500 / 1256, train loss = 4.410, lr = 0.079, since beginning = 20 mins, \n","batch no = 625 / 1256, train loss = 4.286, lr = 0.079, since beginning = 20 mins, \n","batch no = 750 / 1256, train loss = 4.496, lr = 0.079, since beginning = 20 mins, \n","batch no = 875 / 1256, train loss = 4.502, lr = 0.079, since beginning = 20 mins, \n","batch no = 1000 / 1256, train loss = 4.499, lr = 0.079, since beginning = 20 mins, \n","batch no = 1125 / 1256, train loss = 4.201, lr = 0.079, since beginning = 20 mins, \n","batch no = 1250 / 1256, train loss = 4.662, lr = 0.079, since beginning = 20 mins, \n","Epoch : 73 || Validation set perplexity : 103.691\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.769, lr = 0.065, since beginning = 20 mins, \n","batch no = 125 / 1256, train loss = 4.336, lr = 0.065, since beginning = 20 mins, \n","batch no = 250 / 1256, train loss = 4.528, lr = 0.065, since beginning = 20 mins, \n","batch no = 375 / 1256, train loss = 4.694, lr = 0.065, since beginning = 20 mins, \n","batch no = 500 / 1256, train loss = 4.457, lr = 0.065, since beginning = 20 mins, \n","batch no = 625 / 1256, train loss = 4.300, lr = 0.065, since beginning = 20 mins, \n","batch no = 750 / 1256, train loss = 4.375, lr = 0.065, since beginning = 20 mins, \n","batch no = 875 / 1256, train loss = 4.538, lr = 0.065, since beginning = 20 mins, \n","batch no = 1000 / 1256, train loss = 4.408, lr = 0.065, since beginning = 20 mins, \n","batch no = 1125 / 1256, train loss = 4.134, lr = 0.065, since beginning = 20 mins, \n","batch no = 1250 / 1256, train loss = 4.463, lr = 0.065, since beginning = 20 mins, \n","Epoch : 74 || Validation set perplexity : 103.160\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.703, lr = 0.054, since beginning = 20 mins, \n","batch no = 125 / 1256, train loss = 4.257, lr = 0.054, since beginning = 20 mins, \n","batch no = 250 / 1256, train loss = 4.482, lr = 0.054, since beginning = 20 mins, \n","batch no = 375 / 1256, train loss = 4.680, lr = 0.054, since beginning = 20 mins, \n","batch no = 500 / 1256, train loss = 4.525, lr = 0.054, since beginning = 20 mins, \n","batch no = 625 / 1256, train loss = 4.269, lr = 0.054, since beginning = 20 mins, \n","batch no = 750 / 1256, train loss = 4.414, lr = 0.054, since beginning = 20 mins, \n","batch no = 875 / 1256, train loss = 4.496, lr = 0.054, since beginning = 20 mins, \n","batch no = 1000 / 1256, train loss = 4.386, lr = 0.054, since beginning = 20 mins, \n","batch no = 1125 / 1256, train loss = 4.219, lr = 0.054, since beginning = 20 mins, \n","batch no = 1250 / 1256, train loss = 4.522, lr = 0.054, since beginning = 21 mins, \n","Epoch : 75 || Validation set perplexity : 102.358\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.807, lr = 0.045, since beginning = 21 mins, \n","batch no = 125 / 1256, train loss = 4.275, lr = 0.045, since beginning = 21 mins, \n","batch no = 250 / 1256, train loss = 4.544, lr = 0.045, since beginning = 21 mins, \n","batch no = 375 / 1256, train loss = 4.698, lr = 0.045, since beginning = 21 mins, \n","batch no = 500 / 1256, train loss = 4.444, lr = 0.045, since beginning = 21 mins, \n","batch no = 625 / 1256, train loss = 4.258, lr = 0.045, since beginning = 21 mins, \n","batch no = 750 / 1256, train loss = 4.406, lr = 0.045, since beginning = 21 mins, \n","batch no = 875 / 1256, train loss = 4.500, lr = 0.045, since beginning = 21 mins, \n","batch no = 1000 / 1256, train loss = 4.369, lr = 0.045, since beginning = 21 mins, \n","batch no = 1125 / 1256, train loss = 4.198, lr = 0.045, since beginning = 21 mins, \n","batch no = 1250 / 1256, train loss = 4.500, lr = 0.045, since beginning = 21 mins, \n","Epoch : 76 || Validation set perplexity : 102.064\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.729, lr = 0.037, since beginning = 21 mins, \n","batch no = 125 / 1256, train loss = 4.301, lr = 0.037, since beginning = 21 mins, \n","batch no = 250 / 1256, train loss = 4.480, lr = 0.037, since beginning = 21 mins, \n","batch no = 375 / 1256, train loss = 4.667, lr = 0.037, since beginning = 21 mins, \n","batch no = 500 / 1256, train loss = 4.437, lr = 0.037, since beginning = 21 mins, \n","batch no = 625 / 1256, train loss = 4.292, lr = 0.037, since beginning = 21 mins, \n","batch no = 750 / 1256, train loss = 4.419, lr = 0.037, since beginning = 21 mins, \n","batch no = 875 / 1256, train loss = 4.512, lr = 0.037, since beginning = 21 mins, \n","batch no = 1000 / 1256, train loss = 4.397, lr = 0.037, since beginning = 21 mins, \n","batch no = 1125 / 1256, train loss = 4.198, lr = 0.037, since beginning = 21 mins, \n","batch no = 1250 / 1256, train loss = 4.458, lr = 0.037, since beginning = 21 mins, \n","Epoch : 77 || Validation set perplexity : 101.809\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.762, lr = 0.030, since beginning = 21 mins, \n","batch no = 125 / 1256, train loss = 4.295, lr = 0.030, since beginning = 21 mins, \n","batch no = 250 / 1256, train loss = 4.476, lr = 0.030, since beginning = 21 mins, \n","batch no = 375 / 1256, train loss = 4.719, lr = 0.030, since beginning = 21 mins, \n","batch no = 500 / 1256, train loss = 4.475, lr = 0.030, since beginning = 21 mins, \n","batch no = 625 / 1256, train loss = 4.325, lr = 0.030, since beginning = 21 mins, \n","batch no = 750 / 1256, train loss = 4.317, lr = 0.030, since beginning = 21 mins, \n","batch no = 875 / 1256, train loss = 4.456, lr = 0.030, since beginning = 21 mins, \n","batch no = 1000 / 1256, train loss = 4.463, lr = 0.030, since beginning = 21 mins, \n","batch no = 1125 / 1256, train loss = 4.219, lr = 0.030, since beginning = 21 mins, \n","batch no = 1250 / 1256, train loss = 4.535, lr = 0.030, since beginning = 21 mins, \n","Epoch : 78 || Validation set perplexity : 101.408\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.780, lr = 0.025, since beginning = 21 mins, \n","batch no = 125 / 1256, train loss = 4.325, lr = 0.025, since beginning = 21 mins, \n","batch no = 250 / 1256, train loss = 4.428, lr = 0.025, since beginning = 21 mins, \n","batch no = 375 / 1256, train loss = 4.728, lr = 0.025, since beginning = 21 mins, \n","batch no = 500 / 1256, train loss = 4.530, lr = 0.025, since beginning = 21 mins, \n","batch no = 625 / 1256, train loss = 4.269, lr = 0.025, since beginning = 22 mins, \n","batch no = 750 / 1256, train loss = 4.351, lr = 0.025, since beginning = 22 mins, \n","batch no = 875 / 1256, train loss = 4.525, lr = 0.025, since beginning = 22 mins, \n","batch no = 1000 / 1256, train loss = 4.344, lr = 0.025, since beginning = 22 mins, \n","batch no = 1125 / 1256, train loss = 4.218, lr = 0.025, since beginning = 22 mins, \n","batch no = 1250 / 1256, train loss = 4.452, lr = 0.025, since beginning = 22 mins, \n","Epoch : 79 || Validation set perplexity : 101.136\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.757, lr = 0.021, since beginning = 22 mins, \n","batch no = 125 / 1256, train loss = 4.268, lr = 0.021, since beginning = 22 mins, \n","batch no = 250 / 1256, train loss = 4.501, lr = 0.021, since beginning = 22 mins, \n","batch no = 375 / 1256, train loss = 4.687, lr = 0.021, since beginning = 22 mins, \n","batch no = 500 / 1256, train loss = 4.415, lr = 0.021, since beginning = 22 mins, \n","batch no = 625 / 1256, train loss = 4.245, lr = 0.021, since beginning = 22 mins, \n","batch no = 750 / 1256, train loss = 4.331, lr = 0.021, since beginning = 22 mins, \n","batch no = 875 / 1256, train loss = 4.489, lr = 0.021, since beginning = 22 mins, \n","batch no = 1000 / 1256, train loss = 4.437, lr = 0.021, since beginning = 22 mins, \n","batch no = 1125 / 1256, train loss = 4.166, lr = 0.021, since beginning = 22 mins, \n","batch no = 1250 / 1256, train loss = 4.538, lr = 0.021, since beginning = 22 mins, \n","Epoch : 80 || Validation set perplexity : 100.744\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.776, lr = 0.017, since beginning = 22 mins, \n","batch no = 125 / 1256, train loss = 4.321, lr = 0.017, since beginning = 22 mins, \n","batch no = 250 / 1256, train loss = 4.469, lr = 0.017, since beginning = 22 mins, \n","batch no = 375 / 1256, train loss = 4.703, lr = 0.017, since beginning = 22 mins, \n","batch no = 500 / 1256, train loss = 4.424, lr = 0.017, since beginning = 22 mins, \n","batch no = 625 / 1256, train loss = 4.254, lr = 0.017, since beginning = 22 mins, \n","batch no = 750 / 1256, train loss = 4.384, lr = 0.017, since beginning = 22 mins, \n","batch no = 875 / 1256, train loss = 4.461, lr = 0.017, since beginning = 22 mins, \n","batch no = 1000 / 1256, train loss = 4.336, lr = 0.017, since beginning = 22 mins, \n","batch no = 1125 / 1256, train loss = 4.170, lr = 0.017, since beginning = 22 mins, \n","batch no = 1250 / 1256, train loss = 4.535, lr = 0.017, since beginning = 22 mins, \n","Epoch : 81 || Validation set perplexity : 100.688\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.741, lr = 0.014, since beginning = 22 mins, \n","batch no = 125 / 1256, train loss = 4.290, lr = 0.014, since beginning = 22 mins, \n","batch no = 250 / 1256, train loss = 4.483, lr = 0.014, since beginning = 22 mins, \n","batch no = 375 / 1256, train loss = 4.675, lr = 0.014, since beginning = 22 mins, \n","batch no = 500 / 1256, train loss = 4.454, lr = 0.014, since beginning = 22 mins, \n","batch no = 625 / 1256, train loss = 4.300, lr = 0.014, since beginning = 22 mins, \n","batch no = 750 / 1256, train loss = 4.423, lr = 0.014, since beginning = 22 mins, \n","batch no = 875 / 1256, train loss = 4.453, lr = 0.014, since beginning = 22 mins, \n","batch no = 1000 / 1256, train loss = 4.360, lr = 0.014, since beginning = 22 mins, \n","batch no = 1125 / 1256, train loss = 4.139, lr = 0.014, since beginning = 22 mins, \n","batch no = 1250 / 1256, train loss = 4.480, lr = 0.014, since beginning = 22 mins, \n","Epoch : 82 || Validation set perplexity : 100.611\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.787, lr = 0.012, since beginning = 22 mins, \n","batch no = 125 / 1256, train loss = 4.337, lr = 0.012, since beginning = 23 mins, \n","batch no = 250 / 1256, train loss = 4.480, lr = 0.012, since beginning = 23 mins, \n","batch no = 375 / 1256, train loss = 4.684, lr = 0.012, since beginning = 23 mins, \n","batch no = 500 / 1256, train loss = 4.418, lr = 0.012, since beginning = 23 mins, \n","batch no = 625 / 1256, train loss = 4.274, lr = 0.012, since beginning = 23 mins, \n","batch no = 750 / 1256, train loss = 4.339, lr = 0.012, since beginning = 23 mins, \n","batch no = 875 / 1256, train loss = 4.485, lr = 0.012, since beginning = 23 mins, \n","batch no = 1000 / 1256, train loss = 4.352, lr = 0.012, since beginning = 23 mins, \n","batch no = 1125 / 1256, train loss = 4.059, lr = 0.012, since beginning = 23 mins, \n","batch no = 1250 / 1256, train loss = 4.532, lr = 0.012, since beginning = 23 mins, \n","Epoch : 83 || Validation set perplexity : 100.383\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.821, lr = 0.010, since beginning = 23 mins, \n","batch no = 125 / 1256, train loss = 4.269, lr = 0.010, since beginning = 23 mins, \n","batch no = 250 / 1256, train loss = 4.474, lr = 0.010, since beginning = 23 mins, \n","batch no = 375 / 1256, train loss = 4.691, lr = 0.010, since beginning = 23 mins, \n","batch no = 500 / 1256, train loss = 4.432, lr = 0.010, since beginning = 23 mins, \n","batch no = 625 / 1256, train loss = 4.240, lr = 0.010, since beginning = 23 mins, \n","batch no = 750 / 1256, train loss = 4.344, lr = 0.010, since beginning = 23 mins, \n","batch no = 875 / 1256, train loss = 4.550, lr = 0.010, since beginning = 23 mins, \n","batch no = 1000 / 1256, train loss = 4.371, lr = 0.010, since beginning = 23 mins, \n","batch no = 1125 / 1256, train loss = 4.118, lr = 0.010, since beginning = 23 mins, \n","batch no = 1250 / 1256, train loss = 4.544, lr = 0.010, since beginning = 23 mins, \n","Epoch : 84 || Validation set perplexity : 100.311\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.743, lr = 0.008, since beginning = 23 mins, \n","batch no = 125 / 1256, train loss = 4.310, lr = 0.008, since beginning = 23 mins, \n","batch no = 250 / 1256, train loss = 4.535, lr = 0.008, since beginning = 23 mins, \n","batch no = 375 / 1256, train loss = 4.697, lr = 0.008, since beginning = 23 mins, \n","batch no = 500 / 1256, train loss = 4.447, lr = 0.008, since beginning = 23 mins, \n","batch no = 625 / 1256, train loss = 4.255, lr = 0.008, since beginning = 23 mins, \n","batch no = 750 / 1256, train loss = 4.349, lr = 0.008, since beginning = 23 mins, \n","batch no = 875 / 1256, train loss = 4.482, lr = 0.008, since beginning = 23 mins, \n","batch no = 1000 / 1256, train loss = 4.392, lr = 0.008, since beginning = 23 mins, \n","batch no = 1125 / 1256, train loss = 4.150, lr = 0.008, since beginning = 23 mins, \n","batch no = 1250 / 1256, train loss = 4.517, lr = 0.008, since beginning = 23 mins, \n","Epoch : 85 || Validation set perplexity : 100.204\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.721, lr = 0.007, since beginning = 23 mins, \n","batch no = 125 / 1256, train loss = 4.318, lr = 0.007, since beginning = 23 mins, \n","batch no = 250 / 1256, train loss = 4.518, lr = 0.007, since beginning = 23 mins, \n","batch no = 375 / 1256, train loss = 4.678, lr = 0.007, since beginning = 23 mins, \n","batch no = 500 / 1256, train loss = 4.461, lr = 0.007, since beginning = 23 mins, \n","batch no = 625 / 1256, train loss = 4.254, lr = 0.007, since beginning = 23 mins, \n","batch no = 750 / 1256, train loss = 4.333, lr = 0.007, since beginning = 23 mins, \n","batch no = 875 / 1256, train loss = 4.486, lr = 0.007, since beginning = 23 mins, \n","batch no = 1000 / 1256, train loss = 4.403, lr = 0.007, since beginning = 23 mins, \n","batch no = 1125 / 1256, train loss = 4.137, lr = 0.007, since beginning = 24 mins, \n","batch no = 1250 / 1256, train loss = 4.553, lr = 0.007, since beginning = 24 mins, \n","Epoch : 86 || Validation set perplexity : 100.181\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.760, lr = 0.005, since beginning = 24 mins, \n","batch no = 125 / 1256, train loss = 4.362, lr = 0.005, since beginning = 24 mins, \n","batch no = 250 / 1256, train loss = 4.501, lr = 0.005, since beginning = 24 mins, \n","batch no = 375 / 1256, train loss = 4.698, lr = 0.005, since beginning = 24 mins, \n","batch no = 500 / 1256, train loss = 4.438, lr = 0.005, since beginning = 24 mins, \n","batch no = 625 / 1256, train loss = 4.196, lr = 0.005, since beginning = 24 mins, \n","batch no = 750 / 1256, train loss = 4.362, lr = 0.005, since beginning = 24 mins, \n","batch no = 875 / 1256, train loss = 4.455, lr = 0.005, since beginning = 24 mins, \n","batch no = 1000 / 1256, train loss = 4.375, lr = 0.005, since beginning = 24 mins, \n","batch no = 1125 / 1256, train loss = 4.154, lr = 0.005, since beginning = 24 mins, \n","batch no = 1250 / 1256, train loss = 4.459, lr = 0.005, since beginning = 24 mins, \n","Epoch : 87 || Validation set perplexity : 100.141\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.806, lr = 0.005, since beginning = 24 mins, \n","batch no = 125 / 1256, train loss = 4.312, lr = 0.005, since beginning = 24 mins, \n","batch no = 250 / 1256, train loss = 4.507, lr = 0.005, since beginning = 24 mins, \n","batch no = 375 / 1256, train loss = 4.709, lr = 0.005, since beginning = 24 mins, \n","batch no = 500 / 1256, train loss = 4.434, lr = 0.005, since beginning = 24 mins, \n","batch no = 625 / 1256, train loss = 4.270, lr = 0.005, since beginning = 24 mins, \n","batch no = 750 / 1256, train loss = 4.347, lr = 0.005, since beginning = 24 mins, \n","batch no = 875 / 1256, train loss = 4.479, lr = 0.005, since beginning = 24 mins, \n","batch no = 1000 / 1256, train loss = 4.421, lr = 0.005, since beginning = 24 mins, \n","batch no = 1125 / 1256, train loss = 4.108, lr = 0.005, since beginning = 24 mins, \n","batch no = 1250 / 1256, train loss = 4.486, lr = 0.005, since beginning = 24 mins, \n","Epoch : 88 || Validation set perplexity : 100.092\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.743, lr = 0.004, since beginning = 24 mins, \n","batch no = 125 / 1256, train loss = 4.320, lr = 0.004, since beginning = 24 mins, \n","batch no = 250 / 1256, train loss = 4.499, lr = 0.004, since beginning = 24 mins, \n","batch no = 375 / 1256, train loss = 4.699, lr = 0.004, since beginning = 24 mins, \n","batch no = 500 / 1256, train loss = 4.439, lr = 0.004, since beginning = 24 mins, \n","batch no = 625 / 1256, train loss = 4.286, lr = 0.004, since beginning = 24 mins, \n","batch no = 750 / 1256, train loss = 4.413, lr = 0.004, since beginning = 24 mins, \n","batch no = 875 / 1256, train loss = 4.504, lr = 0.004, since beginning = 24 mins, \n","batch no = 1000 / 1256, train loss = 4.357, lr = 0.004, since beginning = 24 mins, \n","batch no = 1125 / 1256, train loss = 4.139, lr = 0.004, since beginning = 24 mins, \n","batch no = 1250 / 1256, train loss = 4.516, lr = 0.004, since beginning = 24 mins, \n","Epoch : 89 || Validation set perplexity : 100.042\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.760, lr = 0.003, since beginning = 24 mins, \n","batch no = 125 / 1256, train loss = 4.334, lr = 0.003, since beginning = 24 mins, \n","batch no = 250 / 1256, train loss = 4.469, lr = 0.003, since beginning = 24 mins, \n","batch no = 375 / 1256, train loss = 4.716, lr = 0.003, since beginning = 24 mins, \n","batch no = 500 / 1256, train loss = 4.434, lr = 0.003, since beginning = 24 mins, \n","batch no = 625 / 1256, train loss = 4.292, lr = 0.003, since beginning = 25 mins, \n","batch no = 750 / 1256, train loss = 4.384, lr = 0.003, since beginning = 25 mins, \n","batch no = 875 / 1256, train loss = 4.464, lr = 0.003, since beginning = 25 mins, \n","batch no = 1000 / 1256, train loss = 4.318, lr = 0.003, since beginning = 25 mins, \n","batch no = 1125 / 1256, train loss = 4.128, lr = 0.003, since beginning = 25 mins, \n","batch no = 1250 / 1256, train loss = 4.509, lr = 0.003, since beginning = 25 mins, \n","Epoch : 90 || Validation set perplexity : 100.084\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.779, lr = 0.003, since beginning = 25 mins, \n","batch no = 125 / 1256, train loss = 4.333, lr = 0.003, since beginning = 25 mins, \n","batch no = 250 / 1256, train loss = 4.450, lr = 0.003, since beginning = 25 mins, \n","batch no = 375 / 1256, train loss = 4.708, lr = 0.003, since beginning = 25 mins, \n","batch no = 500 / 1256, train loss = 4.476, lr = 0.003, since beginning = 25 mins, \n","batch no = 625 / 1256, train loss = 4.301, lr = 0.003, since beginning = 25 mins, \n","batch no = 750 / 1256, train loss = 4.340, lr = 0.003, since beginning = 25 mins, \n","batch no = 875 / 1256, train loss = 4.503, lr = 0.003, since beginning = 25 mins, \n","batch no = 1000 / 1256, train loss = 4.321, lr = 0.003, since beginning = 25 mins, \n","batch no = 1125 / 1256, train loss = 4.129, lr = 0.003, since beginning = 25 mins, \n","batch no = 1250 / 1256, train loss = 4.503, lr = 0.003, since beginning = 25 mins, \n","Epoch : 91 || Validation set perplexity : 100.010\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.717, lr = 0.002, since beginning = 25 mins, \n","batch no = 125 / 1256, train loss = 4.355, lr = 0.002, since beginning = 25 mins, \n","batch no = 250 / 1256, train loss = 4.471, lr = 0.002, since beginning = 25 mins, \n","batch no = 375 / 1256, train loss = 4.693, lr = 0.002, since beginning = 25 mins, \n","batch no = 500 / 1256, train loss = 4.403, lr = 0.002, since beginning = 25 mins, \n","batch no = 625 / 1256, train loss = 4.302, lr = 0.002, since beginning = 25 mins, \n","batch no = 750 / 1256, train loss = 4.371, lr = 0.002, since beginning = 25 mins, \n","batch no = 875 / 1256, train loss = 4.488, lr = 0.002, since beginning = 25 mins, \n","batch no = 1000 / 1256, train loss = 4.401, lr = 0.002, since beginning = 25 mins, \n","batch no = 1125 / 1256, train loss = 4.174, lr = 0.002, since beginning = 25 mins, \n","batch no = 1250 / 1256, train loss = 4.498, lr = 0.002, since beginning = 25 mins, \n","Epoch : 92 || Validation set perplexity : 100.003\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.725, lr = 0.002, since beginning = 25 mins, \n","batch no = 125 / 1256, train loss = 4.280, lr = 0.002, since beginning = 25 mins, \n","batch no = 250 / 1256, train loss = 4.464, lr = 0.002, since beginning = 25 mins, \n","batch no = 375 / 1256, train loss = 4.699, lr = 0.002, since beginning = 25 mins, \n","batch no = 500 / 1256, train loss = 4.454, lr = 0.002, since beginning = 25 mins, \n","batch no = 625 / 1256, train loss = 4.245, lr = 0.002, since beginning = 25 mins, \n","batch no = 750 / 1256, train loss = 4.345, lr = 0.002, since beginning = 25 mins, \n","batch no = 875 / 1256, train loss = 4.475, lr = 0.002, since beginning = 25 mins, \n","batch no = 1000 / 1256, train loss = 4.430, lr = 0.002, since beginning = 25 mins, \n","batch no = 1125 / 1256, train loss = 4.114, lr = 0.002, since beginning = 25 mins, \n","batch no = 1250 / 1256, train loss = 4.469, lr = 0.002, since beginning = 25 mins, \n","Epoch : 93 || Validation set perplexity : 99.980\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.729, lr = 0.001, since beginning = 26 mins, \n","batch no = 125 / 1256, train loss = 4.316, lr = 0.001, since beginning = 26 mins, \n","batch no = 250 / 1256, train loss = 4.530, lr = 0.001, since beginning = 26 mins, \n","batch no = 375 / 1256, train loss = 4.708, lr = 0.001, since beginning = 26 mins, \n","batch no = 500 / 1256, train loss = 4.406, lr = 0.001, since beginning = 26 mins, \n","batch no = 625 / 1256, train loss = 4.266, lr = 0.001, since beginning = 26 mins, \n","batch no = 750 / 1256, train loss = 4.351, lr = 0.001, since beginning = 26 mins, \n","batch no = 875 / 1256, train loss = 4.491, lr = 0.001, since beginning = 26 mins, \n","batch no = 1000 / 1256, train loss = 4.345, lr = 0.001, since beginning = 26 mins, \n","batch no = 1125 / 1256, train loss = 4.158, lr = 0.001, since beginning = 26 mins, \n","batch no = 1250 / 1256, train loss = 4.518, lr = 0.001, since beginning = 26 mins, \n","Epoch : 94 || Validation set perplexity : 99.981\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.761, lr = 0.001, since beginning = 26 mins, \n","batch no = 125 / 1256, train loss = 4.279, lr = 0.001, since beginning = 26 mins, \n","batch no = 250 / 1256, train loss = 4.511, lr = 0.001, since beginning = 26 mins, \n","batch no = 375 / 1256, train loss = 4.708, lr = 0.001, since beginning = 26 mins, \n","batch no = 500 / 1256, train loss = 4.433, lr = 0.001, since beginning = 26 mins, \n","batch no = 625 / 1256, train loss = 4.299, lr = 0.001, since beginning = 26 mins, \n","batch no = 750 / 1256, train loss = 4.379, lr = 0.001, since beginning = 26 mins, \n","batch no = 875 / 1256, train loss = 4.541, lr = 0.001, since beginning = 26 mins, \n","batch no = 1000 / 1256, train loss = 4.360, lr = 0.001, since beginning = 26 mins, \n","batch no = 1125 / 1256, train loss = 4.164, lr = 0.001, since beginning = 26 mins, \n","batch no = 1250 / 1256, train loss = 4.524, lr = 0.001, since beginning = 26 mins, \n","Epoch : 95 || Validation set perplexity : 99.998\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.735, lr = 0.001, since beginning = 26 mins, \n","batch no = 125 / 1256, train loss = 4.275, lr = 0.001, since beginning = 26 mins, \n","batch no = 250 / 1256, train loss = 4.441, lr = 0.001, since beginning = 26 mins, \n","batch no = 375 / 1256, train loss = 4.828, lr = 0.001, since beginning = 26 mins, \n","batch no = 500 / 1256, train loss = 4.441, lr = 0.001, since beginning = 26 mins, \n","batch no = 625 / 1256, train loss = 4.248, lr = 0.001, since beginning = 26 mins, \n","batch no = 750 / 1256, train loss = 4.355, lr = 0.001, since beginning = 26 mins, \n","batch no = 875 / 1256, train loss = 4.473, lr = 0.001, since beginning = 26 mins, \n","batch no = 1000 / 1256, train loss = 4.380, lr = 0.001, since beginning = 26 mins, \n","batch no = 1125 / 1256, train loss = 4.189, lr = 0.001, since beginning = 26 mins, \n","batch no = 1250 / 1256, train loss = 4.504, lr = 0.001, since beginning = 26 mins, \n","Epoch : 96 || Validation set perplexity : 99.987\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.776, lr = 0.001, since beginning = 26 mins, \n","batch no = 125 / 1256, train loss = 4.290, lr = 0.001, since beginning = 26 mins, \n","batch no = 250 / 1256, train loss = 4.547, lr = 0.001, since beginning = 26 mins, \n","batch no = 375 / 1256, train loss = 4.718, lr = 0.001, since beginning = 26 mins, \n","batch no = 500 / 1256, train loss = 4.433, lr = 0.001, since beginning = 26 mins, \n","batch no = 625 / 1256, train loss = 4.227, lr = 0.001, since beginning = 26 mins, \n","batch no = 750 / 1256, train loss = 4.352, lr = 0.001, since beginning = 26 mins, \n","batch no = 875 / 1256, train loss = 4.490, lr = 0.001, since beginning = 26 mins, \n","batch no = 1000 / 1256, train loss = 4.379, lr = 0.001, since beginning = 26 mins, \n","batch no = 1125 / 1256, train loss = 4.091, lr = 0.001, since beginning = 27 mins, \n","batch no = 1250 / 1256, train loss = 4.509, lr = 0.001, since beginning = 27 mins, \n","Epoch : 97 || Validation set perplexity : 99.979\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.786, lr = 0.001, since beginning = 27 mins, \n","batch no = 125 / 1256, train loss = 4.313, lr = 0.001, since beginning = 27 mins, \n","batch no = 250 / 1256, train loss = 4.473, lr = 0.001, since beginning = 27 mins, \n","batch no = 375 / 1256, train loss = 4.648, lr = 0.001, since beginning = 27 mins, \n","batch no = 500 / 1256, train loss = 4.443, lr = 0.001, since beginning = 27 mins, \n","batch no = 625 / 1256, train loss = 4.232, lr = 0.001, since beginning = 27 mins, \n","batch no = 750 / 1256, train loss = 4.340, lr = 0.001, since beginning = 27 mins, \n","batch no = 875 / 1256, train loss = 4.472, lr = 0.001, since beginning = 27 mins, \n","batch no = 1000 / 1256, train loss = 4.404, lr = 0.001, since beginning = 27 mins, \n","batch no = 1125 / 1256, train loss = 4.100, lr = 0.001, since beginning = 27 mins, \n","batch no = 1250 / 1256, train loss = 4.532, lr = 0.001, since beginning = 27 mins, \n","Epoch : 98 || Validation set perplexity : 99.977\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.791, lr = 0.001, since beginning = 27 mins, \n","batch no = 125 / 1256, train loss = 4.284, lr = 0.001, since beginning = 27 mins, \n","batch no = 250 / 1256, train loss = 4.491, lr = 0.001, since beginning = 27 mins, \n","batch no = 375 / 1256, train loss = 4.700, lr = 0.001, since beginning = 27 mins, \n","batch no = 500 / 1256, train loss = 4.376, lr = 0.001, since beginning = 27 mins, \n","batch no = 625 / 1256, train loss = 4.228, lr = 0.001, since beginning = 27 mins, \n","batch no = 750 / 1256, train loss = 4.385, lr = 0.001, since beginning = 27 mins, \n","batch no = 875 / 1256, train loss = 4.446, lr = 0.001, since beginning = 27 mins, \n","batch no = 1000 / 1256, train loss = 4.421, lr = 0.001, since beginning = 27 mins, \n","batch no = 1125 / 1256, train loss = 4.143, lr = 0.001, since beginning = 27 mins, \n","batch no = 1250 / 1256, train loss = 4.466, lr = 0.001, since beginning = 27 mins, \n","Epoch : 99 || Validation set perplexity : 99.970\n","*************************************************\n","\n","batch no = 0 / 1256, train loss = 4.769, lr = 0.000, since beginning = 27 mins, \n","batch no = 125 / 1256, train loss = 4.254, lr = 0.000, since beginning = 27 mins, \n","batch no = 250 / 1256, train loss = 4.458, lr = 0.000, since beginning = 27 mins, \n","batch no = 375 / 1256, train loss = 4.708, lr = 0.000, since beginning = 27 mins, \n","batch no = 500 / 1256, train loss = 4.453, lr = 0.000, since beginning = 27 mins, \n","batch no = 625 / 1256, train loss = 4.247, lr = 0.000, since beginning = 27 mins, \n","batch no = 750 / 1256, train loss = 4.364, lr = 0.000, since beginning = 27 mins, \n","batch no = 875 / 1256, train loss = 4.517, lr = 0.000, since beginning = 27 mins, \n","batch no = 1000 / 1256, train loss = 4.383, lr = 0.000, since beginning = 27 mins, \n","batch no = 1125 / 1256, train loss = 4.129, lr = 0.000, since beginning = 27 mins, \n","batch no = 1250 / 1256, train loss = 4.497, lr = 0.000, since beginning = 27 mins, \n","Epoch : 100 || Validation set perplexity : 99.981\n","*************************************************\n","\n","validation preplexity : 99.981\n","Training is over.\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["GRU_Drop = test_model(dropout=0.5, rnn_type='GRU', total_epochs=100, learning_rate=0.29995,winit=0.05,seq_length=37,factor_epoch=65,factor=1.21,max_grad_norm=6, title=\"with dropout GRU\")"]},{"cell_type":"code","source":["data = {'Test Perplexity': [LSTM_NoDrop[0][0],LSTM_Drop[0][0],GRU_NoDrop[0][0],GRU_Drop[0][0]],\n","        'Train Perplexity': [LSTM_NoDrop[0][1],LSTM_Drop[0][1],GRU_NoDrop[0][1],GRU_Drop[0][1]],\n","        'Validation Perplexity': [LSTM_NoDrop[0][2],LSTM_Drop[0][2],GRU_NoDrop[0][2],GRU_Drop[0][2]]}\n","df_summary = pd.DataFrame(data, index=['LSTM no dropout','LSTM with dropout','GRU no dropout','GRU with dropout'])\n","df_summary"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"id":"kIgWllfJhOtc","executionInfo":{"status":"ok","timestamp":1684322119964,"user_tz":-180,"elapsed":312,"user":{"displayName":"nadav marciano","userId":"12525209232604832576"}},"outputId":"70b875fa-9712-45d0-a75e-7b5cbed8d9d7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                   Test Perplexity  Train Perplexity  Validation Perplexity\n","LSTM no dropout         115.855228         46.708482             120.067959\n","LSTM with dropout        95.384378         52.967995              99.107639\n","GRU no dropout          121.869505         55.048303             124.936015\n","GRU with dropout         96.172653         47.474728              99.981398"],"text/html":["\n","  <div id=\"df-4dcc5bae-6b02-45e7-a997-c3df98ad4be9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Test Perplexity</th>\n","      <th>Train Perplexity</th>\n","      <th>Validation Perplexity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>LSTM no dropout</th>\n","      <td>115.855228</td>\n","      <td>46.708482</td>\n","      <td>120.067959</td>\n","    </tr>\n","    <tr>\n","      <th>LSTM with dropout</th>\n","      <td>95.384378</td>\n","      <td>52.967995</td>\n","      <td>99.107639</td>\n","    </tr>\n","    <tr>\n","      <th>GRU no dropout</th>\n","      <td>121.869505</td>\n","      <td>55.048303</td>\n","      <td>124.936015</td>\n","    </tr>\n","    <tr>\n","      <th>GRU with dropout</th>\n","      <td>96.172653</td>\n","      <td>47.474728</td>\n","      <td>99.981398</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4dcc5bae-6b02-45e7-a997-c3df98ad4be9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4dcc5bae-6b02-45e7-a997-c3df98ad4be9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4dcc5bae-6b02-45e7-a997-c3df98ad4be9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":[],"metadata":{"id":"izKPoNCxqNtQ"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1VBq5bU4kBKvQZJ4qdHoGeHIGN_GNRITP","timestamp":1684067353920}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}